{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"m1.ipynb","provenance":[],"collapsed_sections":["reTCDNq-5AQB"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JEw7F-tXOIxK","colab_type":"code","outputId":"82f5958e-ab89-4d2b-e36b-7e689a1162ea","executionInfo":{"status":"ok","timestamp":1582990556300,"user_tz":300,"elapsed":23299,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["######## >>>>>>>>>>> For the google colab to be able to access the meta files you must add the APS360 team shared folder to your drive by right clicking on it <<<<<<<<<<< ##############\n","#mount googledrive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7vXXu3P1mcaJ","colab_type":"code","colab":{}},"source":["import pandas as pd\n","# Prints how many nulls there are in max and min temp\n","def test_null_csv_daily(station, start_year, end_year, out_name =  None):\n","    \"\"\"\n","      Args:\n","          station (string): eg. \"ON_6158355\"\n","          start_year (int): Starting year\n","          end_year (int)  : Ending year\n","          start_date (int): start_date = 0 is day 1 of starting year (Where we want the sampling to start)\n","          out_name (optional string) : change the name of the output file\n","    \"\"\"\n","    if out_name == None:\n","      out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","    master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","    src_path = master_path + 'datasets/'\n","    newdf = pd.read_csv(src_path + out_name + \".csv\")\n","    print(newdf['Max Temp (°C)'].isnull().sum())\n","    print(newdf['Min Temp (°C)'].isnull().sum())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrKxromGkQne","colab_type":"code","colab":{}},"source":["import pandas as pd\n","# Interpolates null values in min and max temp cols\n","def inter_nulls_csv_daily(station, start_year, end_year, out_name =  None):\n","    \"\"\"\n","      Args:\n","          station (string): eg. \"ON_6158355\"\n","          start_year (int): Starting year\n","          end_year (int)  : Ending year\n","          start_date (int): start_date = 0 is day 1 of starting year (Where we want the sampling to start)\n","          out_name (optional string) : change the name of the output file\n","    \"\"\"\n","    if out_name == None:\n","      out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","    master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","    src_path = master_path + 'datasets/'\n","    newdf = pd.read_csv(src_path + out_name + \".csv\")\n","    newdf['Max Temp (°C)'] = newdf['Max Temp (°C)'].interpolate()\n","    newdf['Min Temp (°C)']= newdf['Min Temp (°C)'].interpolate()\n","    newdf.to_csv( src_path +  out_name + \".csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iQDDqvI3QncR","colab_type":"code","colab":{}},"source":["# Raw csv downloaded must be place in /raw folder\n","# Merged csv will be stored at /datasets folder\n","# Also interpolates the null max and min temp\n","def make_csv_daily(station, start_year, end_year, out_name =  None):\n","  \"\"\"\n","    Args:\n","        station (string): eg. \"ON_6158355\"\n","        start_year (int): Starting year\n","        end_year (int)  : Ending year\n","        start_date (int): start_date = 0 is day 1 of starting year (Where we want the sampling to start)\n","        out_name (optional string) : change the name of the output file\n","    \"\"\"\n","  if out_name == None:\n","    out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","  master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","  src_path = master_path + 'raw/'\n","  dest_path = master_path + 'datasets/'\n","  fout= open(dest_path + out_name + \".csv\",\"w+\")\n","  in_base = \"en_climate_daily_\" + station + '_' #eg: 'en_climate_daily_ON_6158355_'\n","  in_end = '_P1D.csv'\n","  # first file:\n","  for line in open(src_path + in_base + str(start_year) + in_end):\n","      fout.write(line)\n","  # now the rest:    \n","  for num in range(start_year + 1, end_year + 1):\n","      f = open(src_path + in_base + str(num) + in_end)\n","      f.__next__() # skip the header\n","      for line in f:\n","          fout.write(line)\n","      f.close() # not really needed\n","  fout.close()\n","  inter_nulls_csv_daily(station, start_year, end_year, out_name)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UzvoBC2MYdpn","colab_type":"code","colab":{}},"source":["####### run once #######\n","make_csv_daily(\"ON_6158355\", 2007, 2016) # New version interpolates"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nzvxRMN5mtFb","colab_type":"code","outputId":"60dd6ea3-ee56-4c05-dfff-14f656cbd5ad","executionInfo":{"status":"ok","timestamp":1582990820504,"user_tz":300,"elapsed":1873,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["####### run once #######\n","test_null_csv_daily(\"ON_6158355\", 2007, 2016)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["28\n","14\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3fo3YWFXmzEx","colab_type":"code","colab":{}},"source":["####### run once #######\n","inter_nulls_csv_daily(\"ON_6158355\", 2007, 2016)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JQ0XkmLm1w6","colab_type":"code","outputId":"4506c2d7-9a9f-4784-8c4c-d2054aee4eb6","executionInfo":{"status":"ok","timestamp":1582990858676,"user_tz":300,"elapsed":507,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["####### run once #######\n","test_null_csv_daily(\"ON_6158355\", 2007, 2016)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9KHJU3Fl6KsP","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","class WeatherDataset(Dataset):\n","    \"\"\"Weather dataset.\"\"\"\n","\n","    def __init__(self, station, start_year, end_year, start_date = 0, end_date = None, num_days = 7, make_csv = False, out_name = None):\n","        \"\"\"\n","        Args:\n","            station (string): eg. \"ON_6158355\"\n","            start_year (int): Starting year\n","            end_year (int)  : Ending year\n","            start_date (optional int): start_date = 0 is day 1 of starting year (Where we want the sampling to start)\n","            end_date (optional int) : end_date = 7 is day 8 of starting year(min = 7 because of LABEL!). If provided changes the end date from last day of last year.\n","            num_days (optional int) : num_days is the interval of days before the label.\n","            make_csv (optional bool): If true it will call make_csv_daily function to create the csv from /raw datasets into /datasets\n","            out_name (optional string) : change the name of the output file which it reads from\n","        \"\"\"\n","        self.num_days = num_days\n","        if(out_name == None):\n","          self.out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","        else:\n","          self.out_name = out_name\n","        master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","        dest_path = master_path + 'datasets/'\n","        if (make_csv):\n","          make_csv_daily(station, start_year, end_year, out_name =  out_name)\n","\n","        self.cur_csv = pd.read_csv(dest_path + self.out_name +'.csv')\n","\n","        self.start_date = start_date\n","        if( end_date == None):\n","          self.end_date = len(self.cur_csv) - start_date\n","        else:\n","          self.end_date = end_date\n","\n","    def __len__(self):\n","        return self.end_date - self.start_date + 1 - self.num_days - 1\n","\n","    def __getitem__(self, idx):\n","        data = self.cur_csv.loc[ idx + self.start_date : idx + self.start_date + self.num_days - 1 , ['Max Temp (°C)', 'Min Temp (°C)'] ]\n","        data = np.asarray(data)\n","        data = data.astype('float')\n","\n","        label = self.cur_csv.loc[ idx + self.start_date + self.num_days, ['Max Temp (°C)', 'Min Temp (°C)'] ]\n","        label = np.asarray(label)\n","        label = label.astype('float')\n","\n","        data = data.flatten()\n","\n","        #print('Data: {}'.format(data))\n","        #print('Data shape: {}'.format(data.shape))\n","        #print('Labels shape: {}'.format(label.shape))\n","        #print('Labels: {}'.format(label[:2]))\n","        sample = [data, label]\n","\n","        return sample"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNpX1JNmzDpU","colab_type":"code","colab":{}},"source":["start_year = 2007\n","end_year = 2019\n","start_date = 0\n","end_date = 20\n","num_days = 7\n","station = \"ON_6158355\"\n","trainingSet = WeatherDataset(station, start_year, end_year, start_date, end_date, num_days, make_csv = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Thz_7ckZzhNZ","colab_type":"code","outputId":"ebc100c0-7d48-4de1-caae-eb5e75768758","executionInfo":{"status":"ok","timestamp":1582944693067,"user_tz":300,"elapsed":302,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["trainingSet[2]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([ 8.1,  2.4, 10.1,  4.8, 11.9,  7.7, 10. ,  4.1,  4.8,  3.3,  5.4,\n","         0.5,  2.5, -3.7]), array([-1.9, -5.7])]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"cARd7jW80Lwj","colab_type":"code","outputId":"2da49592-cefb-494e-83f0-bf8144e46d9e","executionInfo":{"status":"ok","timestamp":1582944706071,"user_tz":300,"elapsed":531,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import torch\n","train_loader = torch.utils.data.DataLoader(trainingSet, batch_size=2, \n","                                            num_workers=1, shuffle=True)\n","for i, data in enumerate(train_loader, 0):\n","  input, label = data\n","  print(\"input:\")\n","  print(input)\n","  print(\"label:\")\n","  print(label)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["input:\n","tensor([[10.1000,  2.6000,  6.4000,  0.7000,  8.1000,  2.4000, 10.1000,  4.8000,\n","         11.9000,  7.7000, 10.0000,  4.1000,  4.8000,  3.3000],\n","        [ 2.5000, -3.7000, -1.9000, -5.7000,  7.1000, -4.8000,  8.2000,  2.8000,\n","          4.9000, -2.2000, -0.2000, -2.1000, -0.3000, -5.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  5.4000,   0.5000],\n","        [ -5.3000, -11.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 5.4000,  0.5000,  2.5000, -3.7000, -1.9000, -5.7000,  7.1000, -4.8000,\n","          8.2000,  2.8000,  4.9000, -2.2000, -0.2000, -2.1000],\n","        [10.1000,  4.8000, 11.9000,  7.7000, 10.0000,  4.1000,  4.8000,  3.3000,\n","          5.4000,  0.5000,  2.5000, -3.7000, -1.9000, -5.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.3000, -5.3000],\n","        [ 7.1000, -4.8000]], dtype=torch.float64)\n","input:\n","tensor([[  7.1000,  -4.8000,   8.2000,   2.8000,   4.9000,  -2.2000,  -0.2000,\n","          -2.1000,  -0.3000,  -5.3000,  -5.3000, -11.1000,  -2.1000, -10.3000],\n","        [  4.9000,  -2.2000,  -0.2000,  -2.1000,  -0.3000,  -5.3000,  -5.3000,\n","         -11.1000,  -2.1000, -10.3000,   1.8000,  -2.5000,   1.4000,  -4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  1.8000,  -2.5000],\n","        [ -4.7000, -11.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.4000,  0.7000,  8.1000,  2.4000, 10.1000,  4.8000, 11.9000,  7.7000,\n","         10.0000,  4.1000,  4.8000,  3.3000,  5.4000,  0.5000],\n","        [10.0000,  4.1000,  4.8000,  3.3000,  5.4000,  0.5000,  2.5000, -3.7000,\n","         -1.9000, -5.7000,  7.1000, -4.8000,  8.2000,  2.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.5000, -3.7000],\n","        [ 4.9000, -2.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.8000,  3.3000,  5.4000,  0.5000,  2.5000, -3.7000, -1.9000, -5.7000,\n","          7.1000, -4.8000,  8.2000,  2.8000,  4.9000, -2.2000],\n","        [11.9000,  7.7000, 10.0000,  4.1000,  4.8000,  3.3000,  5.4000,  0.5000,\n","          2.5000, -3.7000, -1.9000, -5.7000,  7.1000, -4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.2000, -2.1000],\n","        [ 8.2000,  2.8000]], dtype=torch.float64)\n","input:\n","tensor([[  8.2000,   2.8000,   4.9000,  -2.2000,  -0.2000,  -2.1000,  -0.3000,\n","          -5.3000,  -5.3000, -11.1000,  -2.1000, -10.3000,   1.8000,  -2.5000],\n","        [  8.1000,   2.4000,  10.1000,   4.8000,  11.9000,   7.7000,  10.0000,\n","           4.1000,   4.8000,   3.3000,   5.4000,   0.5000,   2.5000,  -3.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.4000, -4.8000],\n","        [-1.9000, -5.7000]], dtype=torch.float64)\n","input:\n","tensor([[ -1.9000,  -5.7000,   7.1000,  -4.8000,   8.2000,   2.8000,   4.9000,\n","          -2.2000,  -0.2000,  -2.1000,  -0.3000,  -5.3000,  -5.3000, -11.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -2.1000, -10.3000]], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Es6LtFF80dH","colab_type":"code","outputId":"934ff8c8-adb6-474d-e8ae-f5cf80a435f7","executionInfo":{"status":"ok","timestamp":1582944722165,"user_tz":300,"elapsed":273,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["for i, data in enumerate(train_loader, 0):\n","  if(i == 1):\n","    break\n","  input, label = data\n","  print(\"input:\")\n","  print(input)\n","  print(\"label:\")\n","  print(label)\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["input:\n","tensor([[11.9000,  7.7000, 10.0000,  4.1000,  4.8000,  3.3000,  5.4000,  0.5000,\n","          2.5000, -3.7000, -1.9000, -5.7000,  7.1000, -4.8000],\n","        [ 4.8000,  3.3000,  5.4000,  0.5000,  2.5000, -3.7000, -1.9000, -5.7000,\n","          7.1000, -4.8000,  8.2000,  2.8000,  4.9000, -2.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.2000,  2.8000],\n","        [-0.2000, -2.1000]], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"reTCDNq-5AQB","colab_type":"text"},"source":["# Graveyard of codes"]},{"cell_type":"markdown","metadata":{"id":"PtYL3goE5GdY","colab_type":"text"},"source":["c######################################################################\n","c######################################################################\n","a##########OOOOOOO#####################################OOOOOOO##########\n","a##########OOOOOOO#####################################OOOOOOO##########\n","a##########OOOOOOO#####################################OOOOOOO##########\n","a##########OOOOOOO#####################################OOOOOOO##########\n","c#######################################################################\n","c###############################^^^^^^^^^^^^^^##############################\n","c################################^^^^^^^^^^^###############################\n","c#################################^^^^^^^^^##############################\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"M3Rr0q-Axexz","colab_type":"code","outputId":"ba0f79db-024e-4298-f246-13ffea0e9faf","executionInfo":{"status":"ok","timestamp":1582240290305,"user_tz":300,"elapsed":357,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["import pandas as pd\n","import numpy as np\n","\n","start_date = 0\n","num_days = 7\n","station = \"ON_6158355\"\n","out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","dest_path = master_path + 'datasets/'\n","landmarks_frame = pd.read_csv(dest_path + out_name +'.csv')\n","\n","n = 65\n","img_name = landmarks_frame.iloc[ start_date : start_date + num_days, [9, 11] ]\n","img_name = np.asarray(img_name)\n","landmarks = landmarks_frame.iloc[ start_date + num_days + 1, [9, 11] ]\n","landmarks = np.asarray(landmarks)\n","#landmarks = landmarks.astype('float').reshape(-1, 2)\n","\n","print('Image name: {}'.format(img_name))\n","print('Landmarks shape: {}'.format(landmarks.shape))\n","print('First 4 Landmarks: {}'.format(landmarks[:2]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Image name: [[10.1  2.6]\n"," [ 6.4  0.7]\n"," [ 8.1  2.4]\n"," [10.1  4.8]\n"," [11.9  7.7]\n"," [10.   4.1]\n"," [ 4.8  3.3]]\n","Landmarks shape: (2,)\n","First 4 Landmarks: [2.5 -3.7]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HAJi4ivqzwr1","colab_type":"code","outputId":"6d02965b-ed64-4abc-d634-0b980f07658f","executionInfo":{"status":"ok","timestamp":1582222483801,"user_tz":300,"elapsed":521,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(landmarks_frame)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4748"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"nHz46oFk15U5","colab_type":"code","outputId":"a44be0d4-c667-40f9-a3af-d5b8bd6907b8","executionInfo":{"status":"ok","timestamp":1582240448006,"user_tz":300,"elapsed":353,"user":{"displayName":"Alireza Nownahal","photoUrl":"","userId":"03726710023061376253"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["import pandas as pd\n","import numpy as np\n","start_year = 2007\n","end_year = 2019\n","start_date = 0\n","num_days = 7\n","station = \"ON_6158355\"\n","out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","dest_path = master_path + 'datasets/'\n","cur_csv = pd.read_csv(dest_path + out_name +'.csv')\n","\n","n = 65\n","data = cur_csv.loc[ :6 , ['Max Temp (°C)', 'Min Temp (°C)'] ]\n","data = np.asarray(data)\n","data = data.astype('float')\n","label = cur_csv.loc[ 6, ['Max Temp (°C)', 'Min Temp (°C)'] ]\n","label = np.asarray(label)\n","label = label.astype('float')\n","\n","data = data.flatten()\n","#data = np.expand_dims(data, axis=0)\n","#data = data.reshape((2,7))\n","label = np.asarray(label)\n","data = np.asarray(data)\n","\n","print('Image name: {}'.format(data))\n","print('Image shape: {}'.format(data.shape))\n","print('Landmarks shape: {}'.format(label.shape))\n","print('First 4 Landmarks: {}'.format(label[:2]))\n","\n","sample = [data, label]\n","sample"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Image name: [10.1  2.6  6.4  0.7  8.1  2.4 10.1  4.8 11.9  7.7 10.   4.1  4.8  3.3]\n","Image shape: (14,)\n","Landmarks shape: (2,)\n","First 4 Landmarks: [4.8 3.3]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[array([10.1,  2.6,  6.4,  0.7,  8.1,  2.4, 10.1,  4.8, 11.9,  7.7, 10. ,\n","         4.1,  4.8,  3.3]), array([4.8, 3.3])]"]},"metadata":{"tags":[]},"execution_count":16}]}]}