{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sahar's Copy of Aisling's Copy de Ali's Milestone 2 - RNN.ipynb","provenance":[{"file_id":"1NoyGCxosnIa96HfoAuR9wfK8zId9L6sT","timestamp":1584326076783},{"file_id":"15mjesQ4xKXkjNlYmfQMBRUXhApRBzjMV","timestamp":1584315128883}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"w8JrcA89SspW","colab_type":"text"},"source":["# Data loading"]},{"cell_type":"code","metadata":{"id":"JEw7F-tXOIxK","colab_type":"code","outputId":"b5d4711e-b835-48c3-ff47-82e4329cc735","executionInfo":{"status":"ok","timestamp":1584439611137,"user_tz":240,"elapsed":22120,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["######## >>>>>>>>>>> For the google colab to be able to access the meta files you must add the APS360 team shared folder to your drive by right clicking on it <<<<<<<<<<< ##############\n","#mount googledrive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lspDOm8LoGVd","colab_type":"code","colab":{}},"source":["import pandas as pd\n","# Prints how many nulls there are in max and min temp\n","def test_null_csv_daily(station, start_year, end_year, out_name =  None):\n","    \"\"\"\n","      Args:\n","          station (string): eg. \"ON_6158355\"\n","          start_year (int): Starting year\n","          end_year (int)  : Ending year\n","          start_date (int): start_date = 0 is day 1 of starting year (Where we want the sampling to start)\n","          out_name (optional string) : change the name of the output file\n","    \"\"\"\n","    if out_name == None:\n","      out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","    master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","    src_path = master_path + 'datasets/'\n","    newdf = pd.read_csv(src_path + out_name + \".csv\")\n","    print(\"Max temp nulls: \" + str(newdf['Max Temp (°C)'].isnull().sum()))\n","    print(\"Min temp nulls: \" + str(newdf['Min Temp (°C)'].isnull().sum()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w6rwyspyoJbF","colab_type":"code","colab":{}},"source":["import pandas as pd\n","# Interpolates null values in min and max temp cols\n","def inter_nulls_csv_daily(station, start_year, end_year, out_name =  None):\n","    \"\"\"\n","      Args:\n","          station (string): eg. \"ON_6158355\"\n","          start_year (int): Starting year\n","          end_year (int)  : Ending year\n","          start_date (int): start_date = 0 is day 1 of starting year (Where we want the sampling to start)\n","          out_name (optional string) : change the name of the output file\n","    \"\"\"\n","    if out_name == None:\n","      out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","    master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","    src_path = master_path + 'datasets/'\n","    newdf = pd.read_csv(src_path + out_name + \".csv\")\n","    newdf['Max Temp (°C)'] = newdf['Max Temp (°C)'].interpolate()\n","    newdf['Min Temp (°C)']= newdf['Min Temp (°C)'].interpolate()\n","    newdf.to_csv( src_path +  out_name + \".csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iQDDqvI3QncR","colab_type":"code","colab":{}},"source":["#Raw csv downloaded must be place in /raw folder\n","#Merged csv will be stored at /datasets folder\n","# Also interpolates the null max and min temp\n","def make_csv_daily(station, start_year, end_year, out_name =  None):\n","  \"\"\"\n","    Args:\n","        station (string): eg. \"ON_6158355\"\n","        start_year (int): Starting year\n","        end_year (int)  : Ending year\n","        start_date (int): start_date = 0 is day 1 of starting year (Where we want the sampling to start)\n","        out_name (optional string) : change the name of the output file\n","    \"\"\"\n","  if out_name == None:\n","    out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","  master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","  src_path = master_path + 'raw/'\n","  dest_path = master_path + 'datasets/'\n","  fout = open(dest_path + out_name + \".csv\",\"w+\")\n","  in_base = \"en_climate_daily_\" + station + '_' #eg: 'en_climate_daily_ON_6158355_'\n","  in_end = '_P1D.csv'\n","  # first file:\n","  for line in open(src_path + in_base + str(start_year) + in_end):\n","      fout.write(line)\n","  # now the rest:    \n","  for num in range(start_year + 1, end_year + 1):\n","      f = open(src_path + in_base + str(num) + in_end)\n","      f.__next__() # skip the header\n","      for line in f:\n","          fout.write(line)\n","      f.close() # not really needed\n","  fout.close()\n","  inter_nulls_csv_daily(station, start_year, end_year, out_name)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UzvoBC2MYdpn","colab_type":"code","outputId":"40f3aef1-1c1e-4122-d220-e97f66b8ae22","executionInfo":{"status":"ok","timestamp":1584439619640,"user_tz":240,"elapsed":30609,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["####### run once #######\n","make_csv_daily(\"ON_6158355\", 2007, 2016) # run once\n","make_csv_daily(\"ON_6158355\", 2017, 2018) # run once\n","test_null_csv_daily(\"ON_6158355\", 2007, 2016)\n","test_null_csv_daily(\"ON_6158355\", 2017, 2018)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Max temp nulls: 0\n","Min temp nulls: 0\n","Max temp nulls: 0\n","Min temp nulls: 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9KHJU3Fl6KsP","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","class WeatherDataset(Dataset):\n","    \"\"\"Weather dataset.\"\"\"\n","\n","    def __init__(self, station, start_year, end_year, start_date = 0, end_date = None, num_days = 7, make_csv = False, out_name = None):\n","        \"\"\"\n","        Args:\n","            station (string): eg. \"ON_6158355\"\n","            start_year (int): Starting year\n","            end_year (int)  : Ending year\n","            start_date (int): start_date = 0 is day 1 of starting year (Where we want the sampling to start)\n","            end_date (optional int) : end_date = 7 is day 8 of starting year(min = 7 because of LABEL!). If provided changes the end date from last day of last year.\n","            num_days (optional int) : num_days is the interval of days before the label.\n","            make_csv (optional bool): If true it will call make_csv_daily function to create the csv from /raw datasets into /datasets\n","            out_name (optional string) : change the name of the output file which it reads from\n","        \"\"\"\n","        self.num_days = num_days\n","        if(out_name == None):\n","          self.out_name = station + '_' + str(start_year) + '-' + str(end_year)\n","        else:\n","          self.out_name = out_name\n","        master_path = '/content/gdrive/My Drive/APS360 Team/milestone 1/'\n","        dest_path = master_path + 'datasets/'\n","        if (make_csv):\n","          make_csv_daily(station, start_year, end_year, out_name =  out_name)\n","\n","        self.cur_csv = pd.read_csv(dest_path + self.out_name +'.csv')\n","\n","        self.start_date = start_date\n","        if( end_date == None):\n","          self.end_date = len(self.cur_csv) - start_date\n","        else:\n","          self.end_date = end_date\n","\n","    def __len__(self):\n","        return self.end_date - self.start_date + 1 - self.num_days - 1\n","\n","    def __getitem__(self, idx):\n","        data = self.cur_csv.loc[ idx + self.start_date : idx + self.start_date + self.num_days - 1 , ['Max Temp (°C)', 'Min Temp (°C)'] ]\n","        data = np.asarray(data)\n","        data = data.astype('float')\n","\n","        label = self.cur_csv.loc[ idx + self.start_date + self.num_days, ['Max Temp (°C)', 'Min Temp (°C)'] ]\n","        label = np.asarray(label)\n","        label = label.astype('float')\n","\n","        data = data.flatten()\n","\n","        #print('Data: {}'.format(data))\n","        #print('Data shape: {}'.format(data.shape))\n","        #print('Labels shape: {}'.format(label.shape))\n","        #print('Labels: {}'.format(label[:2]))\n","        sample = [data, label]\n","\n","        return sample"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNpX1JNmzDpU","colab_type":"code","colab":{}},"source":["start_year_train = 2007\n","end_year_train = 2016 #changed from 2019 because in our proposal we said 07-16 is train\n","start_date_train = 0\n","end_date_train = None\n","num_days_train = 7\n","station = \"ON_6158355\"\n","trainingSet = WeatherDataset(station, start_year_train, end_year_train, start_date_train, end_date_train, num_days=num_days_train, make_csv = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Thz_7ckZzhNZ","colab_type":"code","outputId":"a2cce00e-304c-4046-9caa-be9866bbae32","executionInfo":{"status":"ok","timestamp":1584439622481,"user_tz":240,"elapsed":33437,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["trainingSet[2]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([ 8.1,  2.4, 10.1,  4.8, 11.9,  7.7, 10. ,  4.1,  4.8,  3.3,  5.4,\n","         0.5,  2.5, -3.7]), array([-1.9, -5.7])]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"3qeosfvbhree","colab_type":"code","colab":{}},"source":["start_year_val = 2017\n","end_year_val = 2018\n","start_date_val = 0\n","end_date_val = None\n","num_days_val = 7\n","# station stays the same\n","validationSet = WeatherDataset(station, start_year_val, end_year_val, start_date_val, end_date_val, num_days_val, make_csv = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAfmM4iBpx0J","colab_type":"code","outputId":"d37b1dd4-e8fa-47b4-be6e-021b150db774","executionInfo":{"status":"ok","timestamp":1584439632701,"user_tz":240,"elapsed":43645,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import torch\n","train_loader = torch.utils.data.DataLoader(trainingSet, batch_size=2, \n","                                            num_workers=1, shuffle=True)\n","for i, data in enumerate(train_loader, 0):\n","  input, label = data\n","  print(\"input:\")\n","  print(input)\n","  print(\"label:\")\n","  print(label)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.0000, -7.0000],\n","        [14.4000,  9.1000]], dtype=torch.float64)\n","input:\n","tensor([[ -1.0000,  -9.3000,  -9.1000, -15.4000,  -4.6000, -15.8000,  -0.7000,\n","          -4.8000,  -1.5000, -11.1000,  -4.7000, -13.3000,  -5.3000, -10.3000],\n","        [ 10.6000,   3.0000,  14.8000,   8.7000,  14.0000,   4.8000,   9.8000,\n","           3.6000,   7.1000,   1.6000,  11.1000,   3.6000,  10.8000,   8.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-2.9000, -9.4000],\n","        [10.7000,  6.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 14.7000,   5.2000,   5.4000,  -2.2000,   1.4000,  -3.2000,   3.4000,\n","          -1.4000,   2.0000, -10.3000,   1.9000, -10.4000,   8.3000,   1.9000],\n","        [  2.4000, -15.8000, -15.8000, -22.2000,  -7.7000, -16.2000,  -2.9000,\n","         -11.8000,   4.1000,  -4.0000,   7.3000,   2.9000,   3.4000,   1.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.9000, -7.6000],\n","        [ 7.4000,  1.9000]], dtype=torch.float64)\n","input:\n","tensor([[25.9000, 16.8000, 17.3000, 12.5000, 19.8000, 11.5000, 19.7000, 12.7000,\n","         26.8000, 15.9000, 19.8000, 14.7000, 17.2000, 13.1000],\n","        [28.2000, 18.8000, 26.2000, 17.5000, 24.8000, 18.9000, 28.7000, 18.2000,\n","         27.7000, 18.8000, 26.2000, 16.3000, 21.6000, 17.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.4000, 12.5000],\n","        [23.9000, 17.8000]], dtype=torch.float64)\n","input:\n","tensor([[ -4.6000,  -9.3000,  -3.5000,  -9.4000,  -4.8000, -10.3000,  -2.8000,\n","         -10.4000,  -2.3000,  -6.7000,  -1.6000,  -6.8000,  -4.9000,  -8.9000],\n","        [  7.8000,   0.4000,  10.2000,   6.6000,   9.1000,   1.3000,   3.7000,\n","           0.7000,   2.2000,  -0.2000,   4.3000,   0.6000,   3.5000,  -2.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -2.4000, -11.7000],\n","        [ -0.7000,  -4.8000]], dtype=torch.float64)\n","input:\n","tensor([[28.3000, 19.7000, 22.8000, 12.4000, 19.2000,  9.7000, 15.4000, 12.0000,\n","         16.4000, 11.9000, 19.0000, 12.4000, 16.6000, 10.8000],\n","        [20.2000, 11.4000, 24.5000, 17.5000, 22.3000, 19.9000, 28.0000, 17.8000,\n","         18.0000, 10.3000, 18.9000,  9.0000, 24.8000, 11.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.4000, 11.2000],\n","        [17.3000, 11.9000]], dtype=torch.float64)\n","input:\n","tensor([[32.0000, 19.6000, 25.6000, 17.6000, 24.1000, 16.5000, 23.8000, 16.7000,\n","         25.3000, 19.1000, 27.2000, 19.1000, 30.5000, 21.3000],\n","        [ 6.3000,  0.8000,  7.0000, -1.1000, 10.1000,  3.0000,  9.2000,  6.5000,\n","         16.8000,  9.1000, 18.1000,  3.9000,  4.3000,  2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[31.6000, 22.0000],\n","        [ 7.1000,  2.3000]], dtype=torch.float64)\n","input:\n","tensor([[32.1000, 20.5000, 24.4000, 17.3000, 25.2000, 14.8000, 21.6000, 15.2000,\n","         25.5000, 14.4000, 30.4000, 17.1000, 20.7000, 16.7000],\n","        [21.9000, 19.6000, 24.4000, 19.5000, 24.6000, 18.5000, 22.9000, 18.0000,\n","         26.2000, 16.7000, 27.7000, 16.3000, 27.5000, 19.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.9000, 16.9000],\n","        [27.6000, 16.6000]], dtype=torch.float64)\n","input:\n","tensor([[ -7.4000, -13.3000,  -3.0000, -10.7000,  -2.0000,  -6.1000,  -2.3000,\n","          -8.2000,  -2.3000,  -9.0000,  -2.5000, -13.4000,   6.5000,  -2.5000],\n","        [ 18.4000,  10.0000,  16.6000,  10.6000,  20.1000,  11.5000,  20.0000,\n","          13.8000,  18.5000,  16.0000,  22.9000,  14.9000,  19.4000,   9.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.5000, -2.9000],\n","        [12.2000,  7.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 26.6000,  16.4000,  19.3000,  12.1000,  19.7000,  12.0000,  21.3000,\n","          10.0000,  16.1000,  12.8000,  21.6000,  13.0000,  23.7000,  13.8000],\n","        [  3.4000,  -1.4000,   2.0000, -10.3000,   1.9000, -10.4000,   8.3000,\n","           1.9000,   7.9000,  -7.6000,  -5.1000, -11.1000, -11.1000, -15.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 18.6000,  15.7000],\n","        [ -9.1000, -18.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -2.7000, -10.6000,   1.3000,  -8.0000,   6.1000,  -1.1000,   5.7000,\n","           1.1000,   2.1000,  -7.1000,  -0.5000, -10.0000,   4.7000,  -6.2000],\n","        [ 15.4000,  10.1000,  15.7000,   8.2000,  10.5000,   6.3000,  11.0000,\n","           5.9000,   9.9000,   2.9000,   6.6000,   1.8000,   8.6000,   1.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.4000,  0.0000],\n","        [ 5.8000, -0.7000]], dtype=torch.float64)\n","input:\n","tensor([[30.2000, 21.3000, 32.8000, 21.5000, 29.3000, 22.5000, 25.1000, 17.1000,\n","         23.5000, 14.3000, 23.6000, 13.1000, 16.4000, 11.4000],\n","        [20.5000,  7.1000, 15.9000, 10.0000, 27.3000, 15.9000, 28.9000, 19.0000,\n","         29.0000, 18.1000, 26.9000, 17.7000, 22.8000, 10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.7000, 10.4000],\n","        [18.5000,  8.2000]], dtype=torch.float64)\n","input:\n","tensor([[20.2000, 16.3000, 20.9000, 16.3000, 24.7000, 15.5000, 27.2000, 16.6000,\n","         29.1000, 17.0000, 30.6000, 19.6000, 29.7000, 20.2000],\n","        [26.1000, 15.2000, 26.1000, 16.2000, 22.3000, 16.2000, 25.9000, 15.0000,\n","         20.6000, 11.0000, 14.8000,  8.2000, 20.8000,  8.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.9000, 19.2000],\n","        [22.6000, 10.1000]], dtype=torch.float64)\n","input:\n","tensor([[10.4000,  4.5000, 11.9000,  2.9000, 12.6000,  6.0000,  8.1000,  5.9000,\n","          6.7000,  5.1000, 15.0000,  6.2000, 12.6000,  8.0000],\n","        [20.4000,  9.4000, 12.2000,  4.6000, 15.2000,  4.7000, 11.3000,  4.7000,\n","          9.2000,  1.1000,  3.6000,  0.0000,  8.4000, -1.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.8000,  7.7000],\n","        [10.2000, -0.1000]], dtype=torch.float64)\n","input:\n","tensor([[ -6.7000, -12.0000,  -3.6000, -10.4000,  -1.9000,  -8.9000,  -2.6000,\n","          -6.0000,  -6.0000, -11.4000,  -8.6000, -14.0000,  -1.7000, -12.1000],\n","        [ 21.1000,  10.6000,  14.1000,   9.3000,  16.8000,   7.5000,  14.6000,\n","           6.7000,  22.6000,  11.6000,  21.5000,  14.8000,  18.0000,  11.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-3.3000, -6.5000],\n","        [13.0000,  7.2000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.7000, -10.9000,  -8.8000, -13.9000,  -4.2000, -14.8000,   1.7000,\n","          -9.0000,   9.0000,  -3.5000,  17.4000,   4.0000,   6.4000,   1.8000],\n","        [ 25.2000,  14.8000,  21.6000,  15.2000,  25.5000,  14.4000,  30.4000,\n","          17.1000,  20.7000,  16.7000,  21.9000,  16.9000,  31.0000,  17.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.7000,  1.3000],\n","        [30.1000, 22.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.7000, -0.8000,  0.0000, -5.6000, -3.0000, -6.6000, -2.3000, -5.8000,\n","         -2.6000, -3.9000, -0.4000, -6.8000,  1.5000, -4.0000],\n","        [15.3000, 11.1000, 12.4000,  4.7000,  8.1000,  2.9000,  4.9000,  1.7000,\n","          6.6000,  2.5000,  7.2000,  3.5000, 11.1000,  6.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-1.1000, -7.2000],\n","        [14.2000,  9.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 11.3000,  -6.3000,  -6.1000, -10.3000,  -3.8000, -10.3000,  -3.0000,\n","          -9.1000,   0.9000,  -4.7000,   0.8000,  -2.9000,   2.3000,  -4.5000],\n","        [ 14.5000,   6.0000,  11.3000,   3.3000,  21.2000,   5.3000,  18.6000,\n","           5.3000,   5.7000,  -0.6000,   5.4000,  -1.1000,  12.0000,   2.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.3000,  1.8000],\n","        [11.3000,  6.2000]], dtype=torch.float64)\n","input:\n","tensor([[  7.7000,   3.1000,  16.6000,  -0.2000,   5.8000,  -2.7000,   9.6000,\n","          -0.8000,   6.5000,   2.5000,  11.7000,   2.0000,  12.3000,   4.2000],\n","        [  5.7000,   3.2000,   5.7000,   2.1000,   5.9000,   2.0000,   5.1000,\n","          -6.8000,  -6.8000, -13.4000,  -4.7000, -14.5000,   5.0000,  -4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.0000,  5.8000],\n","        [10.3000, -2.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 8.4000,  5.4000, 13.4000,  6.9000, 13.9000,  6.7000, 14.4000,  6.5000,\n","         10.2000,  2.8000,  4.9000,  1.8000,  4.1000, -0.6000],\n","        [ 0.8000, -6.0000,  5.4000, -1.3000,  5.2000,  1.4000,  6.4000,  1.0000,\n","          7.0000, -0.6000, 13.3000,  3.5000, 11.3000,  6.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.7000, -5.4000],\n","        [ 6.0000,  1.3000]], dtype=torch.float64)\n","input:\n","tensor([[15.5000, 11.8000, 16.4000, 12.7000, 19.8000, 14.7000, 22.8000, 12.4000,\n","         17.6000, 15.0000, 24.3000, 15.9000, 22.7000, 14.5000],\n","        [-0.2000, -3.1000,  5.7000, -3.5000,  9.9000,  5.3000, 10.7000,  1.1000,\n","          1.1000, -4.3000,  0.9000, -4.7000,  1.9000, -1.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.0000, 14.9000],\n","        [ 0.7000, -6.3000]], dtype=torch.float64)\n","input:\n","tensor([[22.1000, 17.5000, 24.5500, 18.5000, 27.0000, 20.4000, 25.0000, 20.4000,\n","         28.9000, 19.8000, 26.8000, 21.3000, 29.5000, 20.5000],\n","        [24.8000, 17.4000, 29.7000, 16.6000, 28.3000, 19.7000, 22.8000, 12.4000,\n","         19.2000,  9.7000, 15.4000, 12.0000, 16.4000, 11.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.2000, 20.7000],\n","        [19.0000, 12.4000]], dtype=torch.float64)\n","input:\n","tensor([[24.9000, 13.3000, 26.9000, 14.4000, 25.4000, 15.4000, 18.1000, 12.5000,\n","         17.1000,  7.8000, 14.2000,  6.7000, 17.6000,  5.5000],\n","        [19.3000, 16.0000, 16.6000, 14.9000, 18.4000, 15.2000, 22.2000, 15.0000,\n","         15.2000,  5.9000, 13.9000,  4.6000, 17.0000, 10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.1000, 10.1000],\n","        [17.7000, 11.4000]], dtype=torch.float64)\n","input:\n","tensor([[16.6000,  8.0000, 10.5000,  3.1000, 10.1000,  2.1000, 12.8000,  3.5000,\n","         11.4000,  4.0000, 10.4000,  2.5000,  6.6000,  2.7000],\n","        [10.7000,  1.1000, 11.7000,  5.2000,  6.9000, -3.6000,  3.2000, -4.4000,\n","          4.2000, -3.9000,  8.4000, -1.8000,  6.4000, -1.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.9000,  1.2000],\n","        [ 5.5000, -2.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 28.8000,  17.7000,  28.9000,  17.8000,  32.0000,  19.6000,  25.6000,\n","          17.6000,  24.1000,  16.5000,  23.8000,  16.7000,  25.3000,  19.1000],\n","        [  3.0000,  -3.2000,   2.5000,  -3.9000,   2.7000, -10.0000,  -2.8000,\n","         -11.9000,  -2.1000,  -9.6000,  -2.1000,  -8.1000,   2.4000,  -6.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.2000, 19.1000],\n","        [ 3.8000,  1.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 3.0000,  0.4000,  4.2000,  0.5000,  2.1000,  0.5000,  4.0000, -0.5000,\n","         -0.5000, -5.7000, -2.3000, -7.9000, -2.8000, -7.3000],\n","        [19.1000, 12.2000, 21.4000, 15.0000, 21.5000, 18.1000, 21.3000, 13.6000,\n","         18.8000,  9.0000, 15.1000,  5.8000, 12.3000,  5.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.4000, -6.8000],\n","        [12.5000,  7.6000]], dtype=torch.float64)\n","input:\n","tensor([[23.8000, 20.8000, 30.9000, 21.8000, 30.4000, 19.8000, 32.3000, 20.5000,\n","         32.4000, 20.6000, 30.6000, 20.4000, 24.6000, 18.1000],\n","        [23.6000, 13.1000, 16.4000, 11.4000, 15.7000, 10.4000, 23.7000,  9.4000,\n","         26.8000, 13.5000, 27.7000, 16.4000, 27.5000, 16.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.4000, 18.2000],\n","        [26.3000, 17.3000]], dtype=torch.float64)\n","input:\n","tensor([[  4.6000,  -1.0000,   6.3000,  -1.5000,  13.8000,   2.5000,  13.0000,\n","           2.7000,   6.7000,  -0.2000,   2.1000,  -0.9000,   7.8000,   1.5000],\n","        [  0.0000,  -3.8500,   5.5000,   0.7000,   1.1000,  -7.7000,  -4.8000,\n","         -11.7000,  -2.7000, -10.5000,   0.5000,  -7.0000,   1.3000,  -3.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.2000,  2.4000],\n","        [ 1.2000, -4.2000]], dtype=torch.float64)\n","input:\n","tensor([[29.4000, 22.7000, 29.4000, 20.8000, 21.9000, 19.6000, 24.4000, 19.5000,\n","         24.6000, 18.5000, 22.9000, 18.0000, 26.2000, 16.7000],\n","        [16.5000,  5.8000, 26.5000, 11.7000, 16.7000,  8.1000, 26.8000,  7.9000,\n","         18.7000,  7.7000, 11.7000,  7.4000, 15.7000,  8.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.7000, 16.3000],\n","        [20.7000,  7.5000]], dtype=torch.float64)\n","input:\n","tensor([[31.1000, 18.8000, 29.4000, 16.8000, 28.9000, 16.9000, 30.0000, 20.2000,\n","         24.9000, 18.7000, 27.8000, 18.3000, 25.7000, 18.7000],\n","        [22.3000, 17.3000, 23.6000, 17.3000, 27.4000, 16.8000, 21.5000, 13.7000,\n","         23.3000, 13.6000, 23.2000, 15.3000, 22.7000, 19.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[31.3000, 20.6000],\n","        [22.7000, 15.8000]], dtype=torch.float64)\n","input:\n","tensor([[17.0000, 10.0000, 18.2000, 13.6000, 21.2000, 10.7000, 22.4000, 14.6000,\n","         18.2000, 14.2000, 19.1000, 13.9000, 16.5000, 13.4000],\n","        [19.5000, 14.7000, 22.7000, 15.2000, 22.6000, 12.5000, 21.1000, 11.8000,\n","         20.8000, 10.6000, 27.0000, 12.0000, 14.0000,  7.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.8000, 14.9000],\n","        [17.9000,  6.6000]], dtype=torch.float64)\n","input:\n","tensor([[27.4000, 19.7000, 27.3000, 19.1000, 30.9000, 19.9000, 28.2000, 19.7000,\n","         30.8000, 18.2000, 26.8000, 21.0000, 26.6000, 19.6000],\n","        [27.3000, 16.3000, 19.4000, 13.5000, 27.3000, 16.3000, 26.1000, 15.2000,\n","         26.1000, 16.2000, 22.3000, 16.2000, 25.9000, 15.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.8000, 17.7000],\n","        [20.6000, 11.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 3.1000, -2.5000,  0.2000, -9.7000,  6.6000, -4.6000, 13.4000,  3.6000,\n","         10.3000,  1.7000,  7.1000,  3.7000,  4.4000,  1.0000],\n","        [ 7.8000,  1.5000,  7.2000,  2.4000,  4.3000,  1.5000, 10.7000,  2.2000,\n","         17.2000,  4.8000, 11.7000,  3.4000, 17.0000,  4.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.9000,  3.3000],\n","        [20.6000,  7.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 26.8000,  13.5000,  27.7000,  16.4000,  27.5000,  16.8000,  26.3000,\n","          17.3000,  24.2000,  13.0000,  18.1000,  10.5000,  20.6000,  12.5000],\n","        [  1.4000,  -9.2000,   6.9000,   1.2000,  10.6000,   3.9000,   4.9000,\n","         -14.0000,  -6.1000, -16.5000,  10.5000,  -6.1000,   6.1000,  -7.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 22.4000,  12.0000],\n","        [ -7.1000, -12.6000]], dtype=torch.float64)\n","input:\n","tensor([[18.1000, 10.1000, 19.7000, 12.9000, 17.8000, 11.5000, 15.0000,  7.9000,\n","         10.3000,  5.8000, 12.8000,  6.0000,  6.1000,  0.4000],\n","        [13.9000,  4.6000, 17.0000, 10.1000, 17.7000, 11.4000, 14.2000,  7.4000,\n","         14.6000,  5.5000, 13.8000,  5.8000, 14.8000,  4.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.5000, -0.3000],\n","        [12.3000,  4.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.1000, -5.0000, -0.2000, -4.7000,  3.1000, -1.6000,  2.1000,  0.1500,\n","          7.0000,  1.9000, 10.6000,  5.6000,  5.7000,  4.0000],\n","        [31.4000, 22.5000, 31.7000, 23.5000, 35.4000, 24.7000, 33.9000, 25.2000,\n","         34.7000, 21.3000, 29.8000, 20.7000, 22.3000, 17.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.7000,  2.1000],\n","        [23.6000, 17.3000]], dtype=torch.float64)\n","input:\n","tensor([[26.9000, 14.7000, 26.0000, 18.7000, 26.7000, 18.8000, 23.6000, 18.1000,\n","         26.0000, 16.9000, 22.2000, 14.8000, 25.8000, 13.2000],\n","        [30.6000, 20.4000, 24.6000, 18.1000, 26.4000, 18.2000, 27.0000, 19.2000,\n","         29.6000, 21.5000, 28.7000, 21.4000, 27.8000, 20.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.5000, 15.0000],\n","        [23.6000, 19.0000]], dtype=torch.float64)\n","input:\n","tensor([[30.7000, 23.3000, 29.6000, 20.6000, 27.2000, 17.8000, 27.4000, 19.7000,\n","         27.3000, 19.1000, 30.9000, 19.9000, 28.2000, 19.7000],\n","        [ 2.5000, -3.9000,  7.2000,  2.1000,  9.1000, -8.5000, -1.5000, -9.2000,\n","          0.2000, -2.9000,  0.4000, -2.9000,  2.0000, -0.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[30.8000, 18.2000],\n","        [ 3.8000,  0.1000]], dtype=torch.float64)\n","input:\n","tensor([[14.3000,  5.0000, 19.7000,  5.7000, 19.5000, 12.2000, 22.2000, 13.0000,\n","         24.2000, 14.6000, 25.4000, 15.0000, 21.9000, 14.4000],\n","        [24.5000, 14.1000, 18.1000, 13.3000, 17.7000, 10.9000, 19.2000, 11.0000,\n","         24.4000, 13.0000, 23.7000, 14.4000, 19.6000, 15.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.6000, 12.3000],\n","        [18.0000, 16.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 7.5000, -1.0000,  6.3000, -0.6000, 11.4000,  4.3000, 12.8000,  7.6000,\n","         13.5000,  6.4000, 21.1000,  6.7000, 20.6000,  7.6000],\n","        [25.8000, 20.9000, 27.9000, 19.8000, 28.4000, 18.2000, 26.6000, 19.6000,\n","         27.0000, 17.9000, 26.8000, 17.3000, 26.4000, 19.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.4000,  5.9000],\n","        [28.7000, 18.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 5.7000,  1.3000,  6.7000,  4.2000, 11.5000,  5.9000, 11.1000,  5.1000,\n","         14.0000,  5.8000,  9.3000,  4.3000,  8.2000,  5.2000],\n","        [20.6000,  9.1000, 24.0000,  9.1000, 17.6000,  8.7000, 21.0000,  6.4000,\n","         14.4000,  9.9000, 13.5000,  6.7000, 15.6000,  5.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.5000,  7.0000],\n","        [12.0000,  6.4000]], dtype=torch.float64)\n","input:\n","tensor([[15.1000,  5.8000, 12.3000,  5.8000, 12.5000,  7.6000, 14.2000, 10.5000,\n","         14.8000, 11.2000, 16.9000, 11.5000, 21.1000, 10.6000],\n","        [ 6.6000, -3.0000,  4.6000, -3.3000,  7.5000,  3.5000,  6.5000, -0.1000,\n","          4.9000, -2.7000,  6.1000, -1.1000,  1.6000, -4.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.1000,  9.3000],\n","        [ 4.7000, -1.1000]], dtype=torch.float64)\n","input:\n","tensor([[23.3000, 14.5000, 23.7000, 12.9000, 24.2000, 16.5000, 26.8000, 19.5000,\n","         27.3000, 20.5000, 27.1000, 19.4000, 23.2000, 15.5000],\n","        [28.8000, 17.4000, 23.2000, 14.7000, 28.0000, 16.4000, 20.8000, 13.3000,\n","         22.3000, 11.7000, 28.4000, 15.3000, 30.9000, 17.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.0000, 12.7000],\n","        [33.2000, 20.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.4000,  2.3000,  7.9000,  3.7000,  7.3000,  3.2000,  8.3000,  3.5000,\n","          8.1000,  4.8000, 13.2000,  6.4000, 12.5000,  8.0000],\n","        [ 9.3000,  3.5000, 10.7000,  2.1000, 13.8000,  8.3000, 10.7000,  7.9000,\n","         18.1000, 10.1000, 19.7000, 12.9000, 17.8000, 11.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.4000,  4.8000],\n","        [15.0000,  7.9000]], dtype=torch.float64)\n","input:\n","tensor([[11.3000,  3.1000, 11.8000,  1.4000, 16.7000,  4.4000, 21.4000,  7.0000,\n","         23.7000, 11.2000, 24.2000, 12.8000, 21.7000, 10.5000],\n","        [31.1000, 19.5000, 30.4000, 17.2000, 28.2000, 19.2000, 34.5000, 20.3000,\n","         26.8000, 21.9000, 36.0000, 21.7000, 27.8000, 21.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.0000, 12.9000],\n","        [28.0000, 18.6000]], dtype=torch.float64)\n","input:\n","tensor([[26.8000, 21.3000, 29.5000, 20.5000, 25.2000, 20.7000, 31.6000, 18.3000,\n","         24.8000, 16.5000, 24.2000, 17.8000, 27.1000, 18.0000],\n","        [ 6.1000, -1.1000,  1.6000, -4.2000,  4.7000, -1.1000,  6.9000,  0.0000,\n","          7.8000,  1.3000,  3.0000,  1.1000, 10.0000,  2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[30.0000, 20.2000],\n","        [ 9.3000,  6.4000]], dtype=torch.float64)\n","input:\n","tensor([[21.5000, 12.8000, 16.2000, 10.4000, 21.1000, 10.0000, 23.1000, 12.1000,\n","         24.9000, 13.3000, 26.9000, 14.4000, 25.4000, 15.4000],\n","        [12.1000,  7.4000, 12.3000,  7.5000, 10.3000,  2.3000,  6.5000,  1.6000,\n","         15.2000,  4.6000, 11.6000,  5.3000,  9.2000,  3.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.1000, 12.5000],\n","        [14.1000,  8.9000]], dtype=torch.float64)\n","input:\n","tensor([[  7.6000,  -1.0000,   1.0000,  -3.8000,   0.8000,  -2.7000,   2.7000,\n","          -0.4000,   2.1000,  -5.9000,  -2.3000, -10.0000,   5.9000,  -4.0000],\n","        [ 25.6000,  16.2000,  27.5000,  18.4000,  27.1000,  13.4000,  22.0000,\n","          10.6000,  16.7000,   9.2000,  17.2000,   7.2000,  17.8000,   9.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.4000,  3.2000],\n","        [19.5000, 10.7000]], dtype=torch.float64)\n","input:\n","tensor([[18.1000, 10.9000, 23.3000, 11.7000, 30.1000, 14.0000, 29.2000, 16.2000,\n","         19.1000, 13.8000, 18.9000, 11.3000, 22.4000, 10.5000],\n","        [13.2000,  5.6000, 13.8000,  6.1000, 14.5000,  6.3000, 13.8000,  6.6000,\n","         14.4000,  6.3000, 16.8000, 10.7000, 20.6000, 10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.5000, 11.0000],\n","        [18.6000,  8.2000]], dtype=torch.float64)\n","input:\n","tensor([[12.0000, 10.6000, 11.3000,  9.6000, 15.4000, 10.1000, 15.7000,  8.2000,\n","         10.5000,  6.3000, 11.0000,  5.9000,  9.9000,  2.9000],\n","        [29.0000, 19.9000, 24.4000, 19.6000, 21.2000, 17.5000, 23.8000, 17.0000,\n","         24.5000, 16.5000, 24.1000, 18.1000, 22.1000, 17.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.6000,  1.8000],\n","        [24.5500, 18.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 8.0000,  2.7000, 10.1000,  5.7000, 14.4000,  5.2000, 10.7000,  7.0000,\n","         12.2000,  6.6000, 14.5000,  6.0000, 15.2000,  7.0000],\n","        [ 1.3000, -2.9000,  1.6000, -0.6000,  0.9000, -2.1000, -1.3000, -6.9000,\n","          2.1000, -6.4000,  3.6000,  0.8000,  5.4000,  1.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.9000,  9.3000],\n","        [ 4.2000, -0.2000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.7000, -16.0000, -11.6000, -18.6000,  -9.2000, -16.5000,  -0.4000,\n","         -10.6000,   1.5000,  -2.5000,   1.4000,  -1.1000,   0.9000,  -6.1000],\n","        [ 21.5000,  17.5000,  20.1000,  15.6000,  24.9000,  13.2000,  19.7000,\n","          11.4000,  16.3000,  11.3000,  11.7000,   6.0000,   8.8000,   4.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-2.4000, -9.7000],\n","        [13.9000,  4.7000]], dtype=torch.float64)\n","input:\n","tensor([[  4.0000,  -0.1000,   7.4000,  -1.1000,  13.7000,   3.7000,  13.2000,\n","           9.1000,  10.5000,   6.0000,   9.4000,   5.1000,   5.0000,  -0.7000],\n","        [  2.4000,  -3.5000,  -0.4000,  -3.6000,   2.3000,  -1.2000,  -0.8000,\n","          -6.9000,  -1.9000,  -7.2000,  -1.8000, -16.5000, -14.2000, -19.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  7.3000,   0.0000],\n","        [-12.1000, -20.5000]], dtype=torch.float64)\n","input:\n","tensor([[ -5.5000,  -9.7000,  -2.6000, -12.3000,   4.5000,  -3.7000,   6.8000,\n","           2.9000,   9.3000, -11.1000,  -6.6000, -15.3000,  -3.7000, -10.9000],\n","        [ 22.2000,  14.0000,  23.8000,  12.0000,  28.3000,  15.6000,  30.0000,\n","          16.7000,  32.6000,  20.5000,  31.1000,  22.2000,  31.2000,  22.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -8.8000, -13.9000],\n","        [ 29.6000,  22.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.6000,  2.7000,  3.9000,  1.2000,  5.8000,  1.7000,  7.8000,  2.9000,\n","          6.7000,  1.7000,  8.1000,  1.9000, 12.3000,  6.5000],\n","        [16.3000,  6.2000,  8.7000,  2.1000, 14.9000,  7.7000, 13.9000,  5.4000,\n","         10.4000,  5.2000, 11.3000,  5.6000, 14.8000,  9.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.1000,  4.7000],\n","        [12.8000,  5.6000]], dtype=torch.float64)\n","input:\n","tensor([[27.4000, 13.7000, 22.4000, 11.8000, 21.8000, 14.3000, 18.3000, 16.4000,\n","         18.0000, 16.2000, 22.5000, 17.2000, 26.7000, 19.0000],\n","        [27.0000, 15.3000, 28.5000, 16.2000, 20.4000, 12.4000, 19.7000, 10.9000,\n","         20.3000,  9.2000, 24.0000, 13.4000, 20.4000,  8.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[30.9000, 22.1000],\n","        [16.4000,  7.8000]], dtype=torch.float64)\n","input:\n","tensor([[25.5000, 16.5000, 26.1000, 16.8000, 26.7000, 17.1000, 24.7250, 20.0000,\n","         22.7500, 17.7333, 20.7750, 15.4667, 18.8000, 13.2000],\n","        [ 3.5000, -0.2000,  9.0000,  2.4000,  7.9000,  2.9000,  7.0000,  3.2000,\n","          6.4000,  4.8000,  7.3000,  1.9000,  5.1000,  0.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.4000, 13.2000],\n","        [ 5.7000,  1.3000]], dtype=torch.float64)\n","input:\n","tensor([[ -2.7000, -12.3000,  -9.7000, -16.3000,  -6.3000, -10.8000,  -7.3000,\n","         -10.8000,  -1.9000, -12.8000,  -3.5000,  -8.4000,   0.6000,  -5.5000],\n","        [  7.8000,   2.2000,  14.4000,   3.1000,  10.6000,   2.8000,   9.2000,\n","           0.9000,   8.6000,  -0.3000,  14.8000,   0.2000,   9.0000,   5.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.1000, -2.1000],\n","        [14.5000,  6.8000]], dtype=torch.float64)\n","input:\n","tensor([[25.1000, 16.1000, 27.3000, 16.9000, 23.9000, 14.6000, 26.3000, 13.3000,\n","         26.4000, 14.6000, 26.8000, 18.4000, 31.1000, 18.8000],\n","        [30.6000, 19.1000, 27.3000, 20.5000, 27.3000, 18.9000, 28.2000, 17.6000,\n","         20.6000, 17.0000, 23.7000, 15.5000, 22.4000, 16.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.4000, 16.8000],\n","        [23.9000, 16.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.5000,  -8.4000,   0.6000,  -5.5000,   1.1000,  -2.1000,   1.5000,\n","          -8.8000,  -8.5000, -14.5000,  -3.6000, -11.5000,  -6.8000, -13.1000],\n","        [ -1.9000,  -6.4000,   1.4000,  -3.2000,  -0.9000,  -5.5000,  -3.0000,\n","         -13.8000,  -8.7000, -16.0000,  -1.7000, -12.5000,  -6.7000, -12.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -3.1000, -14.3000],\n","        [  0.1000,  -9.6000]], dtype=torch.float64)\n","input:\n","tensor([[17.3000, 12.5000, 19.8000, 11.5000, 19.7000, 12.7000, 26.8000, 15.9000,\n","         19.8000, 14.7000, 17.2000, 13.1000, 19.4000, 12.5000],\n","        [28.8000, 17.6000, 26.2000, 20.8000, 28.5000, 21.4000, 27.4000, 21.8000,\n","         28.9000, 20.9000, 30.7000, 23.3000, 29.6000, 20.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.1000, 11.7000],\n","        [27.2000, 17.8000]], dtype=torch.float64)\n","input:\n","tensor([[  6.7000,  -0.2000,   2.1000,  -0.9000,   7.8000,   1.5000,   7.2000,\n","           2.4000,   4.3000,   1.5000,  10.7000,   2.2000,  17.2000,   4.8000],\n","        [  1.1000,  -6.0000,   4.2000,  -2.4000,   1.0000,  -5.0000,  -4.5000,\n","          -8.1000,  -1.3000, -10.2000,   0.0000, -11.0000,   1.9000,  -7.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.7000,  3.4000],\n","        [ 1.0000, -5.5000]], dtype=torch.float64)\n","input:\n","tensor([[19.0000, 12.4000, 16.6000, 10.8000, 20.4000, 11.2000, 25.2000, 14.1000,\n","         24.5000, 13.2000, 28.2000, 15.1000, 23.1000, 18.3000],\n","        [ 9.9000,  1.8000,  2.7000,  0.8000, 15.6000,  2.3000,  4.5000, -0.3000,\n","          2.2000, -2.0000,  4.6000,  0.0000,  6.0000, -0.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[30.5000, 16.5000],\n","        [ 4.4000, -1.4000]], dtype=torch.float64)\n","input:\n","tensor([[  7.5000,   0.6000,  11.5000,   3.0000,  11.9000,   1.3000,  11.7000,\n","           3.9000,  19.2000,   6.9000,  15.1000,   5.0000,   9.3000,   3.1000],\n","        [  2.6000,  -1.0000,   5.1000,   0.7000,   4.3000,  -0.6000,   1.4000,\n","          -4.7000,  -4.3000,  -8.8000,  -5.2000, -10.4000,  -8.2000, -14.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 12.2000,   1.8000],\n","        [ -8.3000, -16.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 5.5000,  0.1000,  6.8000, -0.3000, 11.6000,  5.9000, 14.8000,  2.0000,\n","          2.6000, -1.2000,  1.8000, -1.0000,  8.2000,  1.7000],\n","        [15.2000,  9.4000, 22.1000,  9.0000, 23.0000, 12.1000, 21.2000, 13.5000,\n","         22.7000, 12.4000, 24.4000, 12.6000, 24.8000, 14.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.5000,  1.8000],\n","        [24.2000, 15.2000]], dtype=torch.float64)\n","input:\n","tensor([[  8.3000,   3.5000,   8.1000,   4.8000,  13.2000,   6.4000,  12.5000,\n","           8.0000,   8.4000,   4.8000,   6.7000,   2.7000,   6.7000,   1.3000],\n","        [  1.8000,  -2.5000,   1.4000,  -4.8000,  -4.7000, -11.2000,  -2.9000,\n","          -9.6000,  -2.5000,  -7.3000,   0.3000,  -5.0000,  -1.0000,  -9.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  3.9000,   0.7000],\n","        [ -9.1000, -15.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -7.0000, -14.3000,   2.0000, -14.0000,   5.9000,  -1.3000,   4.2000,\n","          -3.1000,   4.8000,  -6.1000,  -6.1000, -11.3000,  -2.3000, -11.7000],\n","        [ 10.6000,   4.5000,   5.6000,   0.8000,   4.2000,   0.6000,   9.3000,\n","          -0.9000,  18.3000,   7.8000,  10.9000,   1.9000,   6.2000,   0.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.8000, -5.8000],\n","        [15.0000,  5.4000]], dtype=torch.float64)\n","input:\n","tensor([[33.2000, 20.2000, 32.9000, 22.4000, 27.1000, 15.7000, 22.8000, 14.8000,\n","         24.7000, 15.3000, 20.9000, 12.9000, 22.7000, 11.7000],\n","        [29.8000, 20.3000, 31.2000, 20.9000, 27.2000, 17.3000, 24.5000, 14.1000,\n","         27.7000, 15.8000, 29.1000, 17.6000, 31.2000, 21.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.6000, 14.0000],\n","        [29.9000, 19.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 26.8000,  21.9000,  36.0000,  21.7000,  27.8000,  21.2000,  28.0000,\n","          18.6000,  27.1000,  17.3000,  28.0000,  18.4000,  28.9000,  18.8000],\n","        [ -4.5000, -11.3000,  -0.7000, -11.8000,   1.1000,  -3.9000,  -0.8000,\n","         -13.7000,  -1.9000, -13.8000,  -1.7000, -13.9000, -10.7000, -14.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 31.3000,  18.2000],\n","        [ -4.4000, -14.0000]], dtype=torch.float64)\n","input:\n","tensor([[32.2000, 20.5000, 31.3000, 23.4000, 30.2000, 19.4000, 28.8000, 18.6000,\n","         28.7000, 18.5000, 31.5000, 19.0000, 33.9000, 22.5000],\n","        [27.3000, 13.3000, 25.1000, 16.8000, 24.9000, 17.1000, 27.7000, 16.5000,\n","         21.1000, 16.3000, 23.8000, 15.2000, 25.5000, 19.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[32.8000, 22.6000],\n","        [21.8000, 17.8000]], dtype=torch.float64)\n","input:\n","tensor([[12.8000,  5.0000, 13.8000,  6.5000, 11.5000,  4.7000, 17.6000,  7.3000,\n","         15.2000,  1.2000,  2.7000, -2.6000,  1.4000, -2.5000],\n","        [ 9.4000,  2.3000, 10.6000,  3.1000,  7.2000,  4.3000,  9.1000,  2.4000,\n","          9.6667,  6.1000, 10.2333,  5.6000, 10.8000,  5.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.9000, -2.0000],\n","        [15.8000,  7.6000]], dtype=torch.float64)\n","input:\n","tensor([[12.4000,  6.3000, 15.6000,  5.3000, 15.8000,  6.5000, 16.1500,  7.0000,\n","         16.5000,  1.9000, 13.0000,  0.6000, 10.1000, -0.7000],\n","        [30.4000, 17.1000, 20.7000, 16.7000, 21.9000, 16.9000, 31.0000, 17.0000,\n","         30.1000, 22.3000, 25.5000, 19.2000, 19.5000, 14.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.5000,  3.1000],\n","        [22.7000, 15.2000]], dtype=torch.float64)\n","input:\n","tensor([[26.7000, 14.6000, 19.3000,  4.9000, 15.9000,  4.1000, 19.2000,  9.3000,\n","         16.4000,  5.3000, 18.7000,  4.1000, 25.4000, 10.5000],\n","        [18.5000,  2.4000, 15.1000,  6.6000, 16.1000,  7.7000, 19.8000, 11.3000,\n","         22.5000,  9.1000, 23.7000, 14.7000, 23.5000, 13.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.1000, 16.4000],\n","        [24.9000, 13.1000]], dtype=torch.float64)\n","input:\n","tensor([[20.9000, 17.5000, 24.4000, 17.8000, 27.7000, 17.2000, 30.0000, 19.2000,\n","         24.6000, 17.0000, 22.6000, 15.0000, 25.0000, 13.9000],\n","        [12.4000,  8.7000, 12.5000,  7.1000, 12.2000,  5.6000, 14.2000,  9.5000,\n","         16.3000,  9.5000, 20.6000,  9.1000, 24.0000,  9.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.8000, 17.1000],\n","        [17.6000,  8.7000]], dtype=torch.float64)\n","input:\n","tensor([[12.3000,  5.8000, 12.5000,  7.6000, 14.2000, 10.5000, 14.8000, 11.2000,\n","         16.9000, 11.5000, 21.1000, 10.6000, 14.1000,  9.3000],\n","        [22.4000, 10.4000, 24.3000, 11.7000, 16.7000, 11.3000, 11.3000,  6.7000,\n","         18.4000,  5.5000,  5.8000, -1.4000,  5.1000, -2.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.8000,  7.5000],\n","        [20.0000,  4.6000]], dtype=torch.float64)\n","input:\n","tensor([[12.8000,  3.5000, 11.4000,  4.0000, 10.4000,  2.5000,  6.6000,  2.7000,\n","          3.9000,  1.2000,  5.8000,  1.7000,  7.8000,  2.9000],\n","        [27.9000, 19.8000, 28.4000, 18.2000, 26.6000, 19.6000, 27.0000, 17.9000,\n","         26.8000, 17.3000, 26.4000, 19.7000, 28.7000, 18.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.7000,  1.7000],\n","        [25.4000, 17.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 25.0000,  13.9000,  25.8000,  17.1000,  29.4000,  18.4000,  21.8000,\n","          15.4000,  21.6000,  14.0000,  23.6000,  14.8000,  25.1000,  15.1000],\n","        [ -2.9000,  -7.7000,  -3.7000,  -9.0000,  -6.9000, -10.0000,  -3.9000,\n","         -12.2000,  -9.4000, -13.9000,  -3.7000, -11.8000,  -7.1000, -14.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 27.5000,  17.1000],\n","        [ -2.8000, -10.0000]], dtype=torch.float64)\n","input:\n","tensor([[27.0000, 18.2000, 26.7000, 16.3000, 26.2000, 17.2000, 25.6000, 14.9000,\n","         26.4000, 16.7000, 24.9000, 13.8000, 24.7000, 16.5000],\n","        [25.8000, 13.6000, 28.0000, 16.8000, 28.1000, 19.0000, 28.1000, 19.3000,\n","         25.3000, 16.0000, 22.1000, 12.6000, 22.6000, 14.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.3000, 15.1000],\n","        [20.7000, 17.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 16.7000,  10.9000,  22.0000,  11.6000,  18.7000,   8.5000,  11.1000,\n","           3.2000,  10.0000,   1.1000,  11.0000,   0.4000,  11.9000,   3.5000],\n","        [  1.5000,  -0.7000,  -0.6000,  -4.3000,  -3.0000, -13.7000,  -9.6000,\n","         -17.0000,  -8.8000, -18.0000,  -3.9000, -10.7000,  -2.2000,  -8.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.3000,  6.1000],\n","        [-1.3000, -7.0000]], dtype=torch.float64)\n","input:\n","tensor([[20.8000, 15.8000, 30.8000, 16.6000, 21.7000, 15.3000, 17.4000, 10.9000,\n","         16.7000, 10.5000, 12.6000,  5.1000, 11.9000,  5.8000],\n","        [ 5.9000,  2.1000,  7.4000,  1.7000, 10.3000,  5.4000,  8.3000,  2.6000,\n","          4.0000, -1.3000,  1.4000, -2.7000,  2.8000, -2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.8000,  8.7000],\n","        [ 2.6000, -0.2000]], dtype=torch.float64)\n","input:\n","tensor([[23.8000, 14.4000, 26.9000, 14.7000, 26.0000, 18.7000, 26.7000, 18.8000,\n","         23.6000, 18.1000, 26.0000, 16.9000, 22.2000, 14.8000],\n","        [11.0000,  5.8000, 16.0000,  6.5000, 19.2000,  6.6000, 10.3000,  3.3000,\n","          6.4000,  2.4000,  8.5000,  3.4000,  7.7000,  2.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.8000, 13.2000],\n","        [11.3000,  3.1000]], dtype=torch.float64)\n","input:\n","tensor([[20.2000, 11.3000, 18.4000,  9.8000, 16.6000,  8.4000, 18.1000, 10.3000,\n","         18.4000, 10.0000, 16.6000, 10.6000, 20.1000, 11.5000],\n","        [20.4000, 13.6000, 22.7000, 14.5000, 20.5000, 14.1000, 21.7000, 13.4000,\n","         24.2000, 17.6000, 26.1000, 18.0000, 24.9000, 17.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.0000, 13.8000],\n","        [21.7000, 19.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 13.1000,   8.0000,  13.9000,  10.1000,  12.5000,   2.0000,   4.1000,\n","           0.6000,   7.9000,   2.9000,   4.8000,   2.6000,   3.1000,   1.1000],\n","        [ -0.9000,  -6.9000,  -0.5000,  -4.0000,   2.8000,  -3.5000,   5.1000,\n","          -4.7000,  -4.6000, -12.5000,  -7.7000, -12.1000,  -8.4000, -17.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  4.4000,   0.1000],\n","        [ -7.7000, -14.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 11.8000,   2.6000,   3.9000,  -1.6000,   3.8000,  -2.5000,   7.1000,\n","           2.9000,   9.0000,  -1.0000,   1.4000, -10.6000,  -4.2000, -11.2000],\n","        [ 21.3000,  12.7000,  22.4000,  16.0000,  23.2000,  18.4000,  23.1000,\n","          18.1000,  22.0000,  15.8000,  18.9000,  14.7000,  17.3000,   9.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.3000, -6.5000],\n","        [12.2000,  6.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 10.2000,   2.9000,   6.1000,   0.3000,   0.3000,  -4.7000,   0.3000,\n","          -6.8000,   0.9000,  -7.9000,  -0.4000,  -8.8000,  -0.3000,  -7.5000],\n","        [ -4.1000, -11.6000,  -7.7000, -12.7000, -10.3000, -18.3000,  -4.3000,\n","         -18.5000,   0.7000,  -4.3000,  -0.5000,  -1.6000,   0.5000,  -2.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.2000, -6.4000],\n","        [-0.2000, -3.8000]], dtype=torch.float64)\n","input:\n","tensor([[11.6000,  8.5000, 11.2000,  7.6000, 10.7000,  6.0000, 14.2000,  5.0000,\n","         15.6000,  7.4000, 12.7000,  5.2000,  7.6000,  4.1000],\n","        [27.6000, 18.5000, 30.2000, 17.7000, 19.8000, 13.5000, 21.3000, 13.7000,\n","         23.6000, 14.9000, 27.9000, 18.6000, 27.6000, 19.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.3000,  0.5000],\n","        [27.3000, 16.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.8000, -3.3000, -1.8000, -5.5000, -2.8000, -4.3000, -0.4000, -4.5000,\n","         -1.6000, -7.5000, -2.6000, -6.3000, -2.2000, -4.7000],\n","        [ 3.2000, -0.7000,  3.7000, -0.6000,  3.6000, -0.7000,  4.0000, -0.6000,\n","          7.6000, -0.4000,  0.7000, -5.0000,  6.0000, -4.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-2.2000, -5.7000],\n","        [11.8000,  5.9000]], dtype=torch.float64)\n","input:\n","tensor([[31.3000, 18.0000, 30.5000, 20.1000, 24.1000, 15.5000, 15.5000, 10.6000,\n","         17.2000,  6.3000, 19.3000, 10.8000, 15.0000,  8.8000],\n","        [21.4000, 14.9000, 22.1000, 15.5000, 19.8000, 10.5000, 14.9000, 10.1000,\n","         21.7000, 10.9000, 14.3000, 11.5000, 20.1000, 11.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.0000,  7.5000],\n","        [22.9000, 13.3000]], dtype=torch.float64)\n","input:\n","tensor([[-0.3000, -5.6000,  3.3000, -3.1000,  6.9000, -0.9000,  5.4000, -0.3000,\n","          8.8000,  1.9000,  3.8000, -1.0000,  4.4000,  0.0000],\n","        [22.0000, 16.5000, 20.7000, 14.6000, 19.1000, 12.2000, 21.4000, 15.0000,\n","         21.5000, 18.1000, 21.3000, 13.6000, 18.8000,  9.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.1000,  2.5000],\n","        [15.1000,  5.8000]], dtype=torch.float64)\n","input:\n","tensor([[21.5000,  8.4000, 16.2000,  7.2000, 14.9000,  7.7000, 11.9000,  4.6000,\n","         12.6000,  5.1000, 13.8000,  3.3000, 14.5000,  6.8000],\n","        [ 9.0000,  0.5000, 13.8000,  7.4000, 13.8000,  1.6000,  2.3000, -0.5000,\n","          3.8000, -3.0000,  3.5000, -0.2000,  9.0000,  2.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.1000,  1.3000],\n","        [ 7.9000,  2.9000]], dtype=torch.float64)\n","input:\n","tensor([[12.2000,  5.0000, 11.8000,  4.9000, 18.3000,  5.7000, 10.5000,  4.7000,\n","         17.1000,  6.9000, 18.9000,  8.1000, 19.3000,  9.6000],\n","        [21.5000, 12.4000, 24.2000, 12.1000, 22.2000, 15.9000, 22.9000, 14.5000,\n","         15.5000, 10.0000, 14.9000,  6.1000,  9.7000,  3.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.6000, 10.1000],\n","        [11.8000,  2.2000]], dtype=torch.float64)\n","input:\n","tensor([[  4.7000,   1.5000,   5.4000,   0.7000,   3.8000,   0.6000,   4.3000,\n","           0.3000,   1.5000,  -0.4000,   6.7000,   0.5000,   5.7000,  -2.9000],\n","        [  1.4000,  -4.8000,  -4.7000, -11.2000,  -2.9000,  -9.6000,  -2.5000,\n","          -7.3000,   0.3000,  -5.0000,  -1.0000,  -9.3000,  -9.1000, -15.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -1.7000,  -5.4000],\n","        [ -4.6000, -15.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 22.7000,  18.5000,  22.6000,  10.5000,  15.9000,  10.3000,  14.8000,\n","           7.8000,  15.8000,   7.1000,  18.2000,  10.2000,  18.9000,   9.9000],\n","        [ -1.9000,  -4.1000,   2.5000,  -2.3000,   3.0000,  -1.6000,   3.0000,\n","          -3.2000,   2.5000,  -3.9000,   2.7000, -10.0000,  -2.8000, -11.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.4000,  9.0000],\n","        [-2.1000, -9.6000]], dtype=torch.float64)\n","input:\n","tensor([[  1.5000,  -0.4000,   6.7000,   0.5000,   5.7000,  -2.9000,  -1.7000,\n","          -5.4000,  -0.1000,  -5.1000,  -1.2000, -10.6000,  -1.6000, -10.1000],\n","        [ 18.0000,  11.8000,  13.0000,   7.2000,  18.3000,   6.9000,  13.3000,\n","           2.8000,   7.0000,   0.5000,   6.8000,   0.2000,  15.7000,   0.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.0000, -2.4000],\n","        [17.9000, 12.7000]], dtype=torch.float64)\n","input:\n","tensor([[17.6000,  9.0000, 15.3000, 11.1000, 12.4000,  4.7000,  8.1000,  2.9000,\n","          4.9000,  1.7000,  6.6000,  2.5000,  7.2000,  3.5000],\n","        [18.2000, 13.6000, 21.2000, 10.7000, 22.4000, 14.6000, 18.2000, 14.2000,\n","         19.1000, 13.9000, 16.5000, 13.4000, 19.8000, 14.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.1000,  6.6000],\n","        [18.3000, 13.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 23.1000,  18.1000,  22.0000,  15.8000,  18.9000,  14.7000,  17.3000,\n","           9.2000,  12.2000,   6.5000,  10.5000,   5.0000,  14.5000,  10.1000],\n","        [ -3.0000, -13.8000,  -8.7000, -16.0000,  -1.7000, -12.5000,  -6.7000,\n","         -12.5000,   0.1000,  -9.6000,   7.3000,   0.1000,   2.3000,  -2.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.6000, 10.7000],\n","        [ 3.5000, -3.3000]], dtype=torch.float64)\n","input:\n","tensor([[  6.2000,   3.7000,  13.1000,   2.1000,  11.4000,   2.7000,  12.3000,\n","           4.1000,   9.2000,   1.7000,  12.7000,   1.4000,  15.8000,   3.8000],\n","        [ -3.2000,  -7.8000,  -4.8000, -10.9000,  -3.0000, -11.2000,  -0.8000,\n","          -4.8000,   0.6000,  -7.0000,   2.6000,  -6.3000,   2.7000,  -4.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.5000,  5.3000],\n","        [ 1.4000, -7.0000]], dtype=torch.float64)\n","input:\n","tensor([[27.4000, 13.5000, 23.7000, 13.3000, 18.6000, 14.9000, 22.3000, 15.2000,\n","         19.0000, 15.7000, 24.8000, 15.8000, 27.2000, 17.6000],\n","        [17.0000, 10.2000, 19.4000,  9.4000, 18.7000,  9.0000, 20.6000, 10.3000,\n","         23.4000, 11.4000, 17.9000, 10.9000, 15.7000, 11.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.9000, 15.7000],\n","        [19.2000, 11.8000]], dtype=torch.float64)\n","input:\n","tensor([[24.7000, 15.5000, 27.2000, 16.6000, 29.1000, 17.0000, 30.6000, 19.6000,\n","         29.7000, 20.2000, 25.9000, 19.2000, 27.3000, 18.1000],\n","        [13.9000,  3.4000, 16.8000,  6.1000, 18.8000,  8.5000, 22.5000, 11.3000,\n","         16.2000,  8.3000, 19.6000,  5.8000, 17.3500,  6.1333]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.6000, 15.5000],\n","        [15.1000,  6.4667]], dtype=torch.float64)\n","input:\n","tensor([[ 30.9000,  22.1000,  25.9000,  17.4000,  23.9000,  16.6000,  25.4000,\n","          17.1000,  28.6000,  17.3000,  32.1000,  20.5000,  24.4000,  17.3000],\n","        [  2.0000, -10.3000,   1.9000, -10.4000,   8.3000,   1.9000,   7.9000,\n","          -7.6000,  -5.1000, -11.1000, -11.1000, -15.0000,  -9.1000, -18.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 25.2000,  14.8000],\n","        [ -9.9000, -14.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.8000, -6.3000,  0.6000, -6.0000,  2.1000, -4.9000,  2.0000,  0.5000,\n","          1.9000, -6.9000, -1.3000, -8.4000,  1.0000, -7.5000],\n","        [17.1000,  6.9000, 18.9000,  8.1000, 19.3000,  9.6000, 22.6000, 10.1000,\n","         28.0000, 12.9000, 19.2000,  6.7000, 16.8000,  5.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.4000, -6.4000],\n","        [25.6000,  8.7000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.9000, -10.5000,  -5.2000, -11.7000,  -6.5000, -13.2000,  -8.5000,\n","         -13.9000,  -8.6000, -14.2000,  -7.2000, -12.1000,  -5.7000, -12.0000],\n","        [ 24.4000,  13.0000,  23.7000,  14.4000,  19.6000,  15.3000,  18.0000,\n","          16.3000,  22.5000,  13.4000,  14.9000,  12.1000,  18.7000,  13.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -8.8000, -13.6000],\n","        [ 16.0000,   9.2000]], dtype=torch.float64)\n","input:\n","tensor([[27.7000, 15.8000, 29.1000, 17.6000, 31.2000, 21.2000, 29.9000, 19.7000,\n","         26.6000, 18.1000, 30.7000, 20.7000, 26.5000, 17.9000],\n","        [18.3000, 11.4000, 19.7000, 13.1000, 21.1000, 16.1000, 18.3000, 13.9000,\n","         22.2000, 11.5000, 23.3000, 13.4000, 17.5000,  8.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.8000, 18.0000],\n","        [15.6000,  7.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.1000, -4.0000,  7.3000,  2.9000,  3.4000,  1.3000,  7.4000,  1.9000,\n","          5.3000,  1.3000,  2.4000, -3.5000, -0.4000, -3.6000],\n","        [ 9.9000,  7.9000, 14.5000,  7.9000, 18.5000, 11.5000, 18.9000,  9.6000,\n","         24.5000, 13.7000, 26.3000, 14.8000, 21.4000, 14.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.3000, -1.2000],\n","        [22.1000, 15.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.0000, -0.5000, -0.5000, -5.7000, -2.3000, -7.9000, -2.8000, -7.3000,\n","          0.4000, -6.8000,  0.8000, -6.0000,  5.4000, -1.3000],\n","        [16.8000,  7.5000, 14.6000,  6.7000, 22.6000, 11.6000, 21.5000, 14.8000,\n","         18.0000, 11.8000, 13.0000,  7.2000, 18.3000,  6.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.2000,  1.4000],\n","        [13.3000,  2.8000]], dtype=torch.float64)\n","input:\n","tensor([[20.2000, 15.8000, 19.9000, 14.3000, 19.3000, 12.6000, 19.7000, 13.2000,\n","         27.3000, 13.3000, 25.1000, 16.8000, 24.9000, 17.1000],\n","        [ 3.0000,  1.1000, 10.0000,  2.3000,  9.3000,  6.4000,  8.3000,  2.0000,\n","          7.7000,  1.3000,  7.1000,  0.3500,  6.5000, -0.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.7000, 16.5000],\n","        [ 1.4000, -2.3000]], dtype=torch.float64)\n","input:\n","tensor([[  0.3000,  -5.0000,  -1.0000,  -9.3000,  -9.1000, -15.4000,  -4.6000,\n","         -15.8000,  -0.7000,  -4.8000,  -1.5000, -11.1000,  -4.7000, -13.3000],\n","        [ 26.1000,  15.9000,  28.7000,  16.4000,  30.9000,  16.9000,  28.0000,\n","          19.5000,  34.7000,  21.2000,  30.0000,  22.2000,  26.1000,  16.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -5.3000, -10.3000],\n","        [ 27.7000,  14.1000]], dtype=torch.float64)\n","input:\n","tensor([[25.0000, 20.4000, 28.9000, 19.8000, 26.8000, 21.3000, 29.5000, 20.5000,\n","         25.2000, 20.7000, 31.6000, 18.3000, 24.8000, 16.5000],\n","        [ 7.9000,  3.7000,  7.3000,  3.2000,  8.3000,  3.5000,  8.1000,  4.8000,\n","         13.2000,  6.4000, 12.5000,  8.0000,  8.4000,  4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.2000, 17.8000],\n","        [ 6.7000,  2.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.9000, -3.1000,  2.5000, -3.9000,  7.2000,  2.1000,  9.1000, -8.5000,\n","         -1.5000, -9.2000,  0.2000, -2.9000,  0.4000, -2.9000],\n","        [19.0000,  7.5000, 15.7000,  8.6000, 20.9000, 10.7000, 21.7000, 10.1000,\n","         24.4000, 11.3000, 21.5000, 12.8000, 16.2000, 10.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.0000, -0.6000],\n","        [21.1000, 10.0000]], dtype=torch.float64)\n","input:\n","tensor([[12.3000,  7.6000, 13.7000,  7.8000, 12.7000,  6.5000, 10.6000,  4.5000,\n","          5.6000,  0.8000,  4.2000,  0.6000,  9.3000, -0.9000],\n","        [ 6.0000,  0.2000, 12.0000,  5.3000,  5.9000,  1.8000,  1.8000, -5.8000,\n","         -3.6000, -8.2000,  2.4000, -5.4000,  6.0000, -0.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.3000,  7.8000],\n","        [ 5.3000,  1.4000]], dtype=torch.float64)\n","input:\n","tensor([[  3.5000,  -2.9000,  -0.7000,  -7.3000,  -7.2000, -15.8000,  -6.9000,\n","         -17.5000,  -1.7000,  -8.1000,   9.8000,  -2.2000,   6.2000,  -1.5000],\n","        [ 15.2000,   4.6000,  11.6000,   5.3000,   9.2000,   3.3000,  14.1000,\n","           8.9000,  16.1000,   5.4000,  12.4333,   3.5000,   8.7667,   3.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.7000, -3.1000],\n","        [ 5.1000, -3.0000]], dtype=torch.float64)\n","input:\n","tensor([[22.3000,  4.2000, 12.3000,  6.3000, 11.7000,  6.8000, 11.1000,  8.8000,\n","         20.9000,  8.3000, 17.1000,  8.2000, 10.4000,  6.1000],\n","        [25.9000, 16.6000, 23.8000, 15.2000, 23.6000, 13.9000, 24.1000, 16.8000,\n","         23.1000, 17.1000, 24.3000, 15.5000, 22.9000, 16.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.8000,  5.2000],\n","        [26.2000, 17.9000]], dtype=torch.float64)\n","input:\n","tensor([[  1.3000,  -7.6000,   6.4000,  -6.8000,   9.9000,   2.9000,   9.9000,\n","           1.8000,   2.7000,   0.8000,  15.6000,   2.3000,   4.5000,  -0.3000],\n","        [ -2.5000, -13.4000,   6.5000,  -2.5000,   3.5000,  -2.9000,  -0.7000,\n","          -7.3000,  -7.2000, -15.8000,  -6.9000, -17.5000,  -1.7000,  -8.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.2000, -2.0000],\n","        [ 9.8000, -2.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 28.2000,  19.7000,  30.8000,  18.2000,  26.8000,  21.0000,  26.6000,\n","          19.6000,  28.8000,  17.7000,  28.9000,  17.8000,  32.0000,  19.6000],\n","        [ 10.0000,  -6.0000,  -1.9000,  -6.4000,   1.4000,  -3.2000,  -0.9000,\n","          -5.5000,  -3.0000, -13.8000,  -8.7000, -16.0000,  -1.7000, -12.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 25.6000,  17.6000],\n","        [ -6.7000, -12.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 7.5000,  1.2000,  4.9000,  1.5000,  6.6000,  0.9000,  9.6000,  2.8000,\n","         10.3000,  2.2000, 13.0000,  1.6000, 16.5000, 11.7000],\n","        [24.1000, 19.4000, 27.6000, 20.0000, 28.4000, 19.2000, 29.2000, 19.5000,\n","         32.2000, 20.5000, 31.3000, 23.4000, 30.2000, 19.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.9000, 11.0000],\n","        [28.8000, 18.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 8.6000,  3.5000,  6.6000, -1.8000,  1.9000, -3.8000,  3.9000, -4.3000,\n","         10.2000,  1.5000, 11.5000,  5.9000, 12.4000,  5.1000],\n","        [24.6000, 16.6000, 23.9000, 15.0000, 26.2000, 15.3000, 27.1000, 15.9000,\n","         25.9000, 17.4000, 24.0000, 17.1000, 24.7000, 18.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.7000,  9.9000],\n","        [28.2000, 19.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 15.1000,   9.1000,  20.0000,   9.5000,  20.5000,  11.3000,  19.7000,\n","          13.5000,  25.1000,  11.5000,  27.7000,  13.2000,  20.2000,  16.3000],\n","        [  4.4000,   2.1000,   5.0000,   0.7000,   2.0000, -10.2000,   0.7000,\n","         -10.3000,   1.5000,  -2.3000,   4.4000,   1.5000,   7.6000,   1.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 20.9000,  16.3000],\n","        [  1.8000, -10.6000]], dtype=torch.float64)\n","input:\n","tensor([[30.9000, 17.6000, 33.2000, 20.2000, 32.9000, 22.4000, 27.1000, 15.7000,\n","         22.8000, 14.8000, 24.7000, 15.3000, 20.9000, 12.9000],\n","        [29.9000, 18.7000, 29.3000, 21.2000, 29.4000, 22.7000, 29.4000, 20.8000,\n","         21.9000, 19.6000, 24.4000, 19.5000, 24.6000, 18.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.7000, 11.7000],\n","        [22.9000, 18.0000]], dtype=torch.float64)\n","input:\n","tensor([[15.1000,  4.1000, 15.8000,  7.2000, 17.6000,  8.7000, 21.2000, 10.8000,\n","         21.1000, 13.8000, 15.5000,  3.6000,  9.4000,  3.1000],\n","        [17.9000, 10.9000, 15.7000, 11.8000, 19.2000, 11.8000, 18.6000, 11.3000,\n","         20.4000, 12.7000, 23.1000, 13.2000, 23.3000, 15.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.5000,  2.4000],\n","        [24.3000, 13.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 21.7000,  13.9000,  24.1000,  14.0000,  21.7000,  16.9000,  22.0000,\n","          16.8000,  23.1000,  17.9000,  24.8000,  17.9000,  22.5000,  18.6000],\n","        [ -0.4000,  -6.4000,  -5.5000,  -9.7000,  -2.6000, -12.3000,   4.5000,\n","          -3.7000,   6.8000,   2.9000,   9.3000, -11.1000,  -6.6000, -15.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 23.1000,  17.2000],\n","        [ -3.7000, -10.9000]], dtype=torch.float64)\n","input:\n","tensor([[15.2000,  8.2000, 14.2000,  6.3000, 23.7000, 11.2000, 24.7000, 10.3000,\n","         15.2000,  9.4000, 22.1000,  9.0000, 23.0000, 12.1000],\n","        [26.2000, 17.5000, 24.8000, 18.9000, 28.7000, 18.2000, 27.7000, 18.8000,\n","         26.2000, 16.3000, 21.6000, 17.9000, 23.9000, 17.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.2000, 13.5000],\n","        [30.8000, 17.6000]], dtype=torch.float64)\n","input:\n","tensor([[19.4000,  5.7000,  8.6000,  4.4000,  9.4000,  4.3000,  7.7000,  2.4000,\n","          7.8000,  2.2000, 14.4000,  3.1000, 10.6000,  2.8000],\n","        [19.6000,  9.7000, 17.4000,  7.9000, 18.2000,  9.0000, 19.0000, 10.9000,\n","         19.8000,  9.8000, 19.3000,  9.6000, 16.5000, 11.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.2000,  0.9000],\n","        [17.6000,  8.8000]], dtype=torch.float64)\n","input:\n","tensor([[25.3000, 17.1000, 27.7000, 17.8000, 26.0000, 16.4000, 27.4000, 17.2000,\n","         27.1000, 16.6000, 28.7000, 17.1000, 24.9000, 18.7000],\n","        [28.4000, 18.1000, 24.0000, 16.0000, 23.7000, 14.3000, 23.3000, 15.1000,\n","         23.8000, 14.3000, 29.1000, 16.1000, 30.7000, 19.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.8000, 17.9000],\n","        [34.1000, 21.1000]], dtype=torch.float64)\n","input:\n","tensor([[21.9000, 13.7000, 17.2000, 12.8000, 24.4000, 13.5000, 25.0000, 16.1000,\n","         21.8000, 16.7000, 24.3000, 16.1000, 24.1000, 15.0000],\n","        [ 9.1000,  2.8000, 11.6000,  2.6000, 14.7000,  6.5000,  6.5000, -2.2000,\n","          1.9000, -4.3000,  5.6000, -2.1000,  6.9000, -1.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.6000, 14.5000],\n","        [ 2.8000, -5.3000]], dtype=torch.float64)\n","input:\n","tensor([[ -1.7000, -12.5000,  -6.7000, -12.5000,   0.1000,  -9.6000,   7.3000,\n","           0.1000,   2.3000,  -2.8000,   3.5000,  -3.3000,  12.3000,   2.9000],\n","        [  9.1000,   2.7000,   9.4000,   2.3000,  10.6000,   3.1000,   7.2000,\n","           4.3000,   9.1000,   2.4000,   9.6667,   6.1000,  10.2333,   5.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.3000,  1.3000],\n","        [10.8000,  5.1000]], dtype=torch.float64)\n","input:\n","tensor([[24.1000, 11.6000, 25.5000, 13.4000, 25.3000, 13.8000, 21.1000, 14.4000,\n","         19.1000, 13.5000, 19.6000, 14.3000, 18.0000, 11.1000],\n","        [26.1000, 16.2000, 26.8000, 17.7000, 24.6000, 16.6000, 23.9000, 15.0000,\n","         26.2000, 15.3000, 27.1000, 15.9000, 25.9000, 17.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.5000,  9.3000],\n","        [24.0000, 17.1000]], dtype=torch.float64)\n","input:\n","tensor([[15.2000,  3.7000, 18.3000,  7.3000, 24.3000, 10.7000, 21.2000, 12.4000,\n","         17.8000,  9.0000, 23.8000, 11.4000, 14.4000,  9.1000],\n","        [ 6.6000,  3.7000,  9.5000,  3.0000, 12.1000,  1.9000, 15.2000,  3.7000,\n","         18.3000,  7.3000, 24.3000, 10.7000, 21.2000, 12.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[17.2000,  7.8000],\n","        [17.8000,  9.0000]], dtype=torch.float64)\n","input:\n","tensor([[18.6000, 11.3000, 20.4000, 12.7000, 23.1000, 13.2000, 23.3000, 15.4000,\n","         24.3000, 13.4000, 23.9000, 14.7000, 23.2000, 15.9000],\n","        [12.1000,  4.1000, 10.2000,  2.4000,  7.9000,  1.6000, 13.6000,  4.4000,\n","         17.1000, 10.3000, 13.2000, 10.5000, 14.6000,  8.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.3000, 14.3000],\n","        [ 9.5000,  2.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 2.1000, -0.4000,  4.1000,  1.3000,  5.5000,  2.0000,  4.9000,  0.2000,\n","          4.2000, -2.3000,  0.4000, -4.9000,  3.3000, -6.4000],\n","        [ 9.0000,  3.3000, 11.1000,  2.5000, 10.4000,  2.7000, 11.5000,  4.0000,\n","          9.4000,  5.0000, 12.2000,  3.5000, 12.1000,  2.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.3000,  0.7000],\n","        [11.5000,  5.2000]], dtype=torch.float64)\n","input:\n","tensor([[20.3000,  9.9000, 12.2000,  5.0000, 11.8000,  4.9000, 18.3000,  5.7000,\n","         10.5000,  4.7000, 17.1000,  6.9000, 18.9000,  8.1000],\n","        [11.9000,  1.3000, 11.7000,  3.9000, 19.2000,  6.9000, 15.1000,  5.0000,\n","          9.3000,  3.1000, 12.2000,  1.8000, 10.6000,  4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.3000,  9.6000],\n","        [10.4000,  4.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 2.9000, -0.6000,  3.0000, -0.4000,  2.3000, -1.0000,  2.3000, -2.0000,\n","         -1.0000, -5.4000,  0.9000, -5.9000,  2.6000, -1.2000],\n","        [ 3.4000,  0.1000,  4.8000,  2.7000,  3.8000, -2.7000,  2.0000, -4.2000,\n","          1.0000, -6.2000,  1.5000, -5.6000,  0.9000, -6.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.6000, -3.8000],\n","        [ 3.9000, -3.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 30.1000,  22.3000,  25.5000,  19.2000,  19.5000,  14.7000,  22.7000,\n","          15.2000,  22.6000,  12.5000,  21.1000,  11.8000,  20.8000,  10.6000],\n","        [ -8.6000, -14.0000,  -1.7000, -12.1000,  -3.3000,  -6.5000,  -4.3000,\n","          -7.3000,   0.8000,  -5.2000,   4.6000,  -3.1000,   4.7000,   2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.0000, 12.0000],\n","        [ 2.9000, -0.6000]], dtype=torch.float64)\n","input:\n","tensor([[14.8000, 11.2000, 16.9000, 11.5000, 21.1000, 10.6000, 14.1000,  9.3000,\n","         16.8000,  7.5000, 14.6000,  6.7000, 22.6000, 11.6000],\n","        [12.6000,  4.6000, 16.3000,  7.6000, 20.6000,  8.9000, 23.3000,  9.8000,\n","         15.4000,  7.2000, 14.5000,  6.6000, 14.9000,  8.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.5000, 14.8000],\n","        [19.5000,  7.0000]], dtype=torch.float64)\n","input:\n","tensor([[-0.7000, -8.1000,  6.6000, -3.4000,  9.5000,  0.1000,  9.1000,  2.8000,\n","         11.6000,  2.6000, 14.7000,  6.5000,  6.5000, -2.2000],\n","        [ 0.9000, -7.9000, -0.4000, -8.8000, -0.3000, -7.5000,  4.2000, -6.4000,\n","          7.7000, -3.7000,  7.1000, -1.8000,  3.8000,  1.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.9000, -4.3000],\n","        [10.9000,  2.6000]], dtype=torch.float64)\n","input:\n","tensor([[29.7000, 18.5000, 28.6000, 18.5000, 30.5000, 19.8000, 29.3000, 17.4000,\n","         29.8000, 20.5000, 23.8000, 15.7000, 23.8000, 14.4000],\n","        [23.4000, 11.4000, 17.9000, 10.9000, 15.7000, 11.8000, 19.2000, 11.8000,\n","         18.6000, 11.3000, 20.4000, 12.7000, 23.1000, 13.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.9000, 14.7000],\n","        [23.3000, 15.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -5.1000, -11.1000, -11.1000, -15.0000,  -9.1000, -18.4000,  -9.9000,\n","         -14.7000,  -7.4000, -13.3000,  -1.8000,  -9.7000,  -0.7000,  -9.3000],\n","        [ 20.6000,  10.3000,  23.4000,  11.4000,  17.9000,  10.9000,  15.7000,\n","          11.8000,  19.2000,  11.8000,  18.6000,  11.3000,  20.4000,  12.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.8000, -1.4000],\n","        [23.1000, 13.2000]], dtype=torch.float64)\n","input:\n","tensor([[  5.1000,  -4.7000,  -4.6000, -12.5000,  -7.7000, -12.1000,  -8.4000,\n","         -17.6000,  -7.7000, -14.8000,  -5.1000, -12.3000,  -8.9000, -14.6000],\n","        [ -1.3000,  -5.2000,  -1.5000, -17.8000,  -7.7000, -21.5000,  -5.7000,\n","         -19.7000, -19.2000, -25.1000, -12.6000, -22.4000,  -7.5000, -13.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  0.5000,  -9.0000],\n","        [ -6.9000, -13.4000]], dtype=torch.float64)\n","input:\n","tensor([[22.5000, 12.2000, 26.2000, 13.6000, 29.9000, 17.4000, 22.5000, 14.1000,\n","         17.5000, 13.9000, 20.8000, 12.1000, 20.0000, 10.9000],\n","        [13.8000,  3.8000, 15.1000,  8.8000,  8.8000,  4.8000,  9.1000,  2.7000,\n","          9.4000,  2.3000, 10.6000,  3.1000,  7.2000,  4.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.8000, 14.1000],\n","        [ 9.1000,  2.4000]], dtype=torch.float64)\n","input:\n","tensor([[  3.4000,  -5.5000,   2.1000,  -6.1000,   5.7000,  -3.0000,   1.1000,\n","          -3.8000,  -3.8000, -12.3000,  -1.9000,  -8.2000,   3.4000,  -4.2000],\n","        [  6.4000,   4.4000,   4.5000,   0.2000,   7.2000,   0.2000,   5.0000,\n","           0.4000,   7.8000,   0.4000,  10.2000,   6.6000,   9.1000,   1.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.1000, -0.4000],\n","        [ 3.7000,  0.7000]], dtype=torch.float64)\n","input:\n","tensor([[25.3000, 16.4000, 29.4000, 18.2000, 32.9000, 21.2000, 33.6000, 19.4000,\n","         31.1000, 19.5000, 30.4000, 17.2000, 28.2000, 19.2000],\n","        [21.9000, 14.4000, 24.6000, 12.3000, 15.8000,  8.5000, 14.2000,  7.5000,\n","         12.6000,  2.4000, 10.6000,  2.0000, 10.5000,  4.2500]],\n","       dtype=torch.float64)\n","label:\n","tensor([[34.5000, 20.3000],\n","        [10.4000,  6.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 3.5000, -3.3000,  2.3000, -5.1000,  2.9000, -8.9000, -1.8000, -9.5000,\n","          4.8000, -1.9000,  7.2000, -1.1000, -1.1000, -5.6000],\n","        [10.5000,  3.1000, 10.1000,  2.1000, 12.8000,  3.5000, 11.4000,  4.0000,\n","         10.4000,  2.5000,  6.6000,  2.7000,  3.9000,  1.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.0000, -9.9000],\n","        [ 5.8000,  1.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 7.1000,  3.0000,  9.4000,  1.3000, 12.5000,  4.3000, 14.5000,  6.0000,\n","         11.3000,  3.3000, 21.2000,  5.3000, 18.6000,  5.3000],\n","        [ 5.3000, -1.2000,  7.7000,  3.1000, 16.6000, -0.2000,  5.8000, -2.7000,\n","          9.6000, -0.8000,  6.5000,  2.5000, 11.7000,  2.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.7000, -0.6000],\n","        [12.3000,  4.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.7000, -2.0000,  2.3000, -0.8000,  1.3000, -7.6000,  6.4000, -6.8000,\n","          9.9000,  2.9000,  9.9000,  1.8000,  2.7000,  0.8000],\n","        [27.8000, 16.6000, 29.5000, 20.2000, 22.3000, 17.3000, 25.3000, 15.7000,\n","         21.1000, 14.2000, 22.9000, 11.7000, 24.4000, 12.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.6000,  2.3000],\n","        [20.9000, 17.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.0000, -0.2000,  3.0000, -0.4000,  3.8000, -0.2000,  9.0000,  0.3000,\n","          3.4000, -5.5000,  2.1000, -6.1000,  5.7000, -3.0000],\n","        [33.9000, 19.6000, 29.3000, 21.4000, 27.2000, 19.0000, 26.0000, 19.2000,\n","         24.1000, 19.4000, 27.6000, 20.0000, 28.4000, 19.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.1000, -3.8000],\n","        [29.2000, 19.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 14.6000,   3.2000,   6.7000,   1.8000,   6.9000,   1.4000,   8.5000,\n","           1.5000,   9.3000,   4.5000,  12.8000,   4.0000,  15.9000,   6.1000],\n","        [ -4.8000, -10.3000,  -2.8000, -10.4000,  -2.3000,  -6.7000,  -1.6000,\n","          -6.8000,  -4.9000,  -8.9000,  -2.4000, -11.7000,   2.4000,  -7.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.5000,  6.9000],\n","        [ 8.0000,  1.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 7.1000, -1.8000,  3.8000,  1.5000, 10.9000,  2.6000, 13.1000,  1.0000,\n","         10.5000,  0.8000, 14.6000,  3.2000,  6.7000,  1.8000],\n","        [ 5.4000,  1.4000,  4.2000, -0.2000,  4.3000, -1.5000,  5.8000, -0.7000,\n","          4.7000, -1.8000,  5.0000, -2.7000,  8.8000, -1.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.9000,  1.4000],\n","        [12.0000,  0.7000]], dtype=torch.float64)\n","input:\n","tensor([[  4.8000,   1.1000,   2.3000,  -1.0000,  -0.9000, -11.5000,  -4.5000,\n","         -14.6000,   0.6000,  -6.2000,   3.2000,   0.6000,   1.9000,  -9.9000],\n","        [ 18.2000,  13.2000,  24.1000,  13.3000,  19.8000,  11.6000,  18.7000,\n","          10.1000,  20.2000,  11.4000,  24.5000,  17.5000,  22.3000,  19.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -9.7000, -16.5000],\n","        [ 28.0000,  17.8000]], dtype=torch.float64)\n","input:\n","tensor([[  3.2000,  -1.3000,  -0.7000,  -5.5000,  -0.2000,  -5.9000,   2.2000,\n","          -2.9000,  -2.9000,  -7.7000,  -3.7000,  -9.0000,  -6.9000, -10.0000],\n","        [  7.4000,   1.4000,   7.5000,   0.1000,   7.4000,   1.2000,   9.2000,\n","          -0.5000,  14.0000,   9.2000,  14.5000,   1.9000,   4.3000,   0.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -3.9000, -12.2000],\n","        [  6.5000,   2.9000]], dtype=torch.float64)\n","input:\n","tensor([[18.1000, 13.3000, 23.5000, 13.7000, 17.0000, 14.9000, 27.5000, 15.8000,\n","         25.5000, 18.9000, 26.5000, 18.0000, 30.6000, 19.1000],\n","        [22.9000, 14.5000, 15.5000, 10.0000, 14.9000,  6.1000,  9.7000,  3.0000,\n","         11.8000,  2.2000, 12.3000,  3.9000, 25.0000,  7.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.3000, 20.5000],\n","        [23.7000, 10.8000]], dtype=torch.float64)\n","input:\n","tensor([[  1.4000,  -3.2000,   3.4000,  -1.4000,   2.0000, -10.3000,   1.9000,\n","         -10.4000,   8.3000,   1.9000,   7.9000,  -7.6000,  -5.1000, -11.1000],\n","        [ 13.9000,   7.6000,  16.7000,   6.0000,  18.1000,  10.9000,  23.3000,\n","          11.7000,  30.1000,  14.0000,  29.2000,  16.2000,  19.1000,  13.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-11.1000, -15.0000],\n","        [ 18.9000,  11.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.0000,  1.6000,  3.6000,  3.0000,  3.2000, -1.3000, -0.7000, -5.5000,\n","         -0.2000, -5.9000,  2.2000, -2.9000, -2.9000, -7.7000],\n","        [27.3000, 16.1000, 34.2000, 20.1000, 27.7000, 13.9000, 19.6000, 13.0000,\n","         20.2000, 15.8000, 19.9000, 14.3000, 19.3000, 12.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-3.7000, -9.0000],\n","        [19.7000, 13.2000]], dtype=torch.float64)\n","input:\n","tensor([[12.3000,  4.2000, 16.1000,  8.5000, 22.3000, 14.7000, 18.8000, 13.7000,\n","         18.6000, 12.7000, 16.7000, 11.8000, 13.8000,  4.4000],\n","        [ 5.9000,  3.5000,  6.9500,  2.1000,  8.0000,  2.7000, 10.1000,  5.7000,\n","         14.4000,  5.2000, 10.7000,  7.0000, 12.2000,  6.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.2000,  3.0000],\n","        [14.5000,  6.0000]], dtype=torch.float64)\n","input:\n","tensor([[10.8000,  6.1000, 10.8000,  5.5000, 21.9000,  8.0000, 15.1000,  9.1000,\n","         20.0000,  9.5000, 20.5000, 11.3000, 19.7000, 13.5000],\n","        [18.1000, 10.3000, 18.4000, 10.0000, 16.6000, 10.6000, 20.1000, 11.5000,\n","         20.0000, 13.8000, 18.5000, 16.0000, 22.9000, 14.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.1000, 11.5000],\n","        [19.4000,  9.9000]], dtype=torch.float64)\n","input:\n","tensor([[23.9000, 18.6000, 23.8000, 16.8000, 21.6000, 15.5000, 23.2000, 16.5000,\n","         25.8000, 14.6000, 24.1000, 17.0000, 27.9000, 18.4000],\n","        [11.9000,  5.8000, 13.8000,  8.7000, 13.5000,  8.5000, 13.0000,  8.2000,\n","         18.3000, 11.4000, 19.7000, 13.1000, 21.1000, 16.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.7000, 19.3000],\n","        [18.3000, 13.9000]], dtype=torch.float64)\n","input:\n","tensor([[-0.7000, -7.6000,  0.3000, -2.0000,  3.1000, -0.7000,  3.2000, -3.6000,\n","          1.9000, -6.1000,  3.4000, -0.1000,  7.0000,  1.9000],\n","        [22.0000, 13.7000, 27.6000, 18.7000, 29.6000, 21.1000, 27.7000, 20.0000,\n","         24.8000, 16.4000, 26.5000, 15.3000, 29.0000, 17.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.6000,  2.5000],\n","        [29.7000, 19.8000]], dtype=torch.float64)\n","input:\n","tensor([[  4.9000, -14.0000,  -6.1000, -16.5000,  10.5000,  -6.1000,   6.1000,\n","          -7.3000,  -7.1000, -12.6000,  -3.5000, -13.8000,   2.0000,  -3.7000],\n","        [ 26.6000,  18.6000,  24.8000,  17.4000,  29.7000,  16.6000,  28.3000,\n","          19.7000,  22.8000,  12.4000,  19.2000,   9.7000,  15.4000,  12.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.1000,  0.8000],\n","        [16.4000, 11.9000]], dtype=torch.float64)\n","input:\n","tensor([[19.6000, 14.3000, 19.6000,  9.7000, 17.4000,  7.9000, 18.2000,  9.0000,\n","         19.0000, 10.9000, 19.8000,  9.8000, 19.3000,  9.6000],\n","        [21.7000, 10.9000, 14.3000, 11.5000, 20.1000, 11.1000, 22.9000, 13.3000,\n","         25.1000, 16.5000, 29.6000, 17.3000, 27.1000, 13.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.5000, 11.7000],\n","        [20.8000, 10.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 7.0000, -0.8000,  6.1000, -0.5000,  6.2000,  0.1000, 15.4000,  4.3000,\n","         13.9000,  5.9000,  5.9000, -2.1000, -1.5000, -5.8000],\n","        [18.1000, 13.3000, 17.7000, 10.9000, 19.2000, 11.0000, 24.4000, 13.0000,\n","         23.7000, 14.4000, 19.6000, 15.3000, 18.0000, 16.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.8000, -6.7000],\n","        [22.5000, 13.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.7000,  1.7000,  8.1000,  1.9000, 12.3000,  6.5000, 11.1000,  4.7000,\n","         15.5000,  6.9000, 10.4000,  2.3000,  3.7000, -0.1000],\n","        [27.2000, 16.6000, 29.1000, 17.0000, 30.6000, 19.6000, 29.7000, 20.2000,\n","         25.9000, 19.2000, 27.3000, 18.1000, 28.6000, 15.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.9000, -0.6000],\n","        [27.1000, 17.1000]], dtype=torch.float64)\n","input:\n","tensor([[  3.7000,  -2.4000,   5.9000,  -0.1000,   8.1000,   3.4000,   7.8000,\n","          -5.5000,  -5.3000,  -8.8000,  -0.8000,  -8.2000,  -6.1000,  -8.9000],\n","        [ -2.3000, -10.8000,   0.8000,  -9.0000,  -3.0000,  -6.9000,  -1.6000,\n","          -7.0000,   0.4000,  -8.3000,   0.6000,  -7.1000,  -1.3000,  -8.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.9000, -7.4000],\n","        [ 0.3000, -3.2000]], dtype=torch.float64)\n","input:\n","tensor([[23.7000, 13.8000, 18.6000, 15.7000, 21.3000, 17.4000, 26.4000, 16.8000,\n","         22.6000, 15.6000, 26.6000, 15.1000, 24.4000, 13.9000],\n","        [29.7000, 16.6000, 28.3000, 19.7000, 22.8000, 12.4000, 19.2000,  9.7000,\n","         15.4000, 12.0000, 16.4000, 11.9000, 19.0000, 12.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.1000, 14.7000],\n","        [16.6000, 10.8000]], dtype=torch.float64)\n","input:\n","tensor([[19.8000,  6.3000, 14.7000,  5.8000, 18.8000, 10.3000, 21.5000, 17.5000,\n","         20.1000, 15.6000, 24.9000, 13.2000, 19.7000, 11.4000],\n","        [11.5000,  9.3000, 13.0000,  7.7000, 13.3000,  7.5000, 13.9000,  8.4000,\n","         12.9000,  9.2000, 11.6000,  8.5000, 11.2000,  7.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.3000, 11.3000],\n","        [10.7000,  6.0000]], dtype=torch.float64)\n","input:\n","tensor([[  3.4000,  -0.1000,   7.0000,   1.9000,   6.6000,   2.5000,   8.1000,\n","           3.7000,  13.0000,   6.7000,  14.7000,   5.2000,   5.4000,  -2.2000],\n","        [ -4.2000, -11.2000,   2.3000,  -6.5000,   2.3000,   0.1000,   1.0000,\n","          -6.6000,  -1.7000,  -6.9000,  -0.7000,  -7.5000,   3.6000,  -2.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.4000, -3.2000],\n","        [ 4.8000,  3.0000]], dtype=torch.float64)\n","input:\n","tensor([[-0.4000, -6.8000,  1.5000, -4.0000, -1.1000, -7.2000, -1.1000, -6.1000,\n","         -0.7000, -7.6000,  0.3000, -2.0000,  3.1000, -0.7000],\n","        [17.1000, 13.2000, 19.6000, 14.3000, 19.6000,  9.7000, 17.4000,  7.9000,\n","         18.2000,  9.0000, 19.0000, 10.9000, 19.8000,  9.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.2000, -3.6000],\n","        [19.3000,  9.6000]], dtype=torch.float64)\n","input:\n","tensor([[  5.7000,  -0.9000,   9.1000,   3.4000,  12.8000,   2.7000,  16.2000,\n","           1.8000,   5.9000,  -2.0000,   3.4000,  -3.0000,  10.2000,   2.9000],\n","        [ -0.7000, -11.8000,   1.1000,  -3.9000,  -0.8000, -13.7000,  -1.9000,\n","         -13.8000,  -1.7000, -13.9000, -10.7000, -14.7000,  -4.4000, -14.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.1000,  0.3000],\n","        [-0.7000, -7.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.4000, -2.9000,  2.0000, -0.6000,  3.8000,  0.1000,  9.1000,  0.8000,\n","          0.8000, -4.4000, -2.2000, -6.8000,  0.5000, -3.9000],\n","        [24.1000, 13.2000, 28.0000, 16.3000, 20.5000, 15.3000, 23.3000, 14.8000,\n","         21.7000, 13.9000, 24.1000, 14.0000, 21.7000, 16.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.0000,  0.2000],\n","        [22.0000, 16.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.6000, -6.0000,  2.1000, -4.9000,  2.0000,  0.5000,  1.9000, -6.9000,\n","         -1.3000, -8.4000,  1.0000, -7.5000, -0.4000, -6.4000],\n","        [24.1000, 16.5000, 23.8000, 16.7000, 25.3000, 19.1000, 27.2000, 19.1000,\n","         30.5000, 21.3000, 31.6000, 22.0000, 31.7000, 20.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-5.5000, -9.7000],\n","        [24.4000, 14.9000]], dtype=torch.float64)\n","input:\n","tensor([[28.2000, 19.2000, 34.5000, 20.3000, 26.8000, 21.9000, 36.0000, 21.7000,\n","         27.8000, 21.2000, 28.0000, 18.6000, 27.1000, 17.3000],\n","        [ 3.6000, -2.4000,  4.8000,  3.0000,  3.5000,  1.0000,  4.2000, -1.1000,\n","          4.0000,  1.6000,  3.6000,  3.0000,  3.2000, -1.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.0000, 18.4000],\n","        [-0.7000, -5.5000]], dtype=torch.float64)\n","input:\n","tensor([[11.4000,  5.3000,  7.4000,  1.4000,  7.5000,  0.1000,  7.4000,  1.2000,\n","          9.2000, -0.5000, 14.0000,  9.2000, 14.5000,  1.9000],\n","        [13.1000,  4.3000, 15.4000,  3.9000,  9.9000,  4.0000,  6.7000,  3.2000,\n","         11.0000,  1.7000,  5.9000, -2.2000,  0.9000, -3.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.3000,  0.0000],\n","        [ 8.5000, -0.5000]], dtype=torch.float64)\n","input:\n","tensor([[20.6000, 11.0000, 14.8000,  8.2000, 20.8000,  8.0000, 22.6000, 10.1000,\n","         30.6000, 13.1000, 19.7000, 13.8000, 19.4000, 11.7000],\n","        [27.0000, 15.3000, 31.2000, 18.7000, 27.0000, 15.7000, 27.6000, 14.5000,\n","         31.6000, 18.7000, 35.5000, 21.5000, 33.7000, 22.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.0000, 10.9000],\n","        [26.1000, 22.2000]], dtype=torch.float64)\n","input:\n","tensor([[26.8000,  7.9000, 18.7000,  7.7000, 11.7000,  7.4000, 15.7000,  8.2000,\n","         20.7000,  7.5000, 14.6000,  5.4000, 18.3000,  7.6000],\n","        [12.8000,  5.2000, 12.8000,  5.0000, 13.8000,  6.5000, 11.5000,  4.7000,\n","         17.6000,  7.3000, 15.2000,  1.2000,  2.7000, -2.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.6000,  9.2000],\n","        [ 1.4000, -2.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 5.3000, -2.0000,  4.8000, -0.8000,  8.7000,  3.0000,  7.1000,  1.4000,\n","          6.4000,  0.2000,  7.4000,  1.7000,  6.9000,  4.0000],\n","        [-1.5000, -5.8000,  0.8000, -6.7000,  2.5000, -3.6000,  3.1000, -2.5000,\n","          0.2000, -9.7000,  6.6000, -4.6000, 13.4000,  3.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.4000,  5.0000],\n","        [10.3000,  1.7000]], dtype=torch.float64)\n","input:\n","tensor([[28.8000, 18.6000, 28.7000, 18.5000, 31.5000, 19.0000, 33.9000, 22.5000,\n","         32.8000, 22.6000, 31.1500, 25.0000, 29.5000, 22.5000],\n","        [ 2.9000, -8.2000, 15.2000,  2.9000, 13.2000,  6.5000, 18.4000,  6.2000,\n","         15.2000,  3.7000, 16.3000,  6.0000, 19.7000,  7.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.8000, 20.4000],\n","        [ 9.7000,  5.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 14.7000,   8.4000,  12.2000,   5.1000,  12.8000,   4.1000,   9.6000,\n","           2.8000,   9.6000,   2.5000,  19.3000,   8.9000,  16.3000,   6.1000],\n","        [ -2.8000,  -8.0000,   8.2000,  -3.1000,   7.1000,  -3.2000,  -3.2000,\n","          -7.8000,  -4.8000, -10.9000,  -3.0000, -11.2000,  -0.8000,  -4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.2000,  4.5000],\n","        [ 0.6000, -7.0000]], dtype=torch.float64)\n","input:\n","tensor([[30.9000, 20.9000, 33.3000, 23.1000, 32.7000, 21.4000, 27.8000, 18.0000,\n","         25.9000, 15.3000, 24.9000, 16.8000, 20.7000, 15.0000],\n","        [28.8000, 15.2000, 30.5000, 16.8000, 31.8000, 18.6000, 31.7000, 19.1000,\n","         26.7000, 14.9000, 26.0000, 15.9000, 23.9000, 15.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.4000, 14.1000],\n","        [28.0000, 15.3000]], dtype=torch.float64)\n","input:\n","tensor([[28.9000, 18.8000, 31.3000, 18.2000, 32.0000, 21.3000, 31.1000, 23.6000,\n","         29.4000, 21.0000, 31.5000, 21.0000, 36.7000, 23.7000],\n","        [ 7.2000,  0.7000,  5.3000,  0.1000,  8.6000,  2.4000,  4.8000,  2.0000,\n","         14.6000,  0.3000, 10.1000, -1.6000,  0.3000, -5.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.2000, 20.5000],\n","        [ 3.7000, -3.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.1000,  0.6000,  7.9000,  2.9000,  4.8000,  2.6000,  3.1000,  1.1000,\n","          4.4000,  0.1000,  0.5000, -2.3000,  0.8000, -4.3000],\n","        [21.9000,  8.0000, 15.1000,  9.1000, 20.0000,  9.5000, 20.5000, 11.3000,\n","         19.7000, 13.5000, 25.1000, 11.5000, 27.7000, 13.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.7000,  0.2000],\n","        [20.2000, 16.3000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.7000,  -9.9000,  -7.0000, -14.3000,   2.0000, -14.0000,   5.9000,\n","          -1.3000,   4.2000,  -3.1000,   4.8000,  -6.1000,  -6.1000, -11.3000],\n","        [  2.9000,  -2.0000,   2.3000,  -2.0000,   4.4000,   2.3000,   7.9000,\n","           3.7000,   7.3000,   3.2000,   8.3000,   3.5000,   8.1000,   4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -2.3000, -11.7000],\n","        [ 13.2000,   6.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 15.9000,   6.6000,  17.6000,   9.3000,  13.1000,   8.6000,  11.4000,\n","           8.5000,  16.5000,   8.3000,  18.2000,   7.2000,  12.7000,   9.1000],\n","        [  0.6000,  -4.7000,   3.3000,  -0.7000,  -0.1000,  -5.2000,  -4.1000,\n","          -9.2000,  -6.7000, -11.7000,  -4.7000,  -9.4000,   0.5000,  -5.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 12.6000,  10.1000],\n","        [ -0.1000, -10.4000]], dtype=torch.float64)\n","input:\n","tensor([[20.5000, 14.1000, 21.7000, 13.4000, 24.2000, 17.6000, 26.1000, 18.0000,\n","         24.9000, 17.9000, 21.7000, 19.4000, 24.2000, 18.5000],\n","        [24.2000, 17.6000, 26.1000, 18.0000, 24.9000, 17.9000, 21.7000, 19.4000,\n","         24.2000, 18.5000, 27.8000, 18.0000, 30.0000, 19.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.8000, 18.0000],\n","        [24.9000, 14.6000]], dtype=torch.float64)\n","input:\n","tensor([[  5.8000,   3.3000,   5.3000,   1.3000,   3.8000,   0.9000,   3.5000,\n","          -1.8000,   3.4000,  -3.7000,   5.7000,  -0.9000,   9.1000,   3.4000],\n","        [  2.7000, -10.0000,  -2.8000, -11.9000,  -2.1000,  -9.6000,  -2.1000,\n","          -8.1000,   2.4000,  -6.8000,   3.8000,   1.9000,   2.7000,  -2.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.8000,  2.7000],\n","        [ 4.1000, -1.1000]], dtype=torch.float64)\n","input:\n","tensor([[22.9000, 16.7000, 26.2000, 17.9000, 23.5000, 15.6000, 25.2000, 13.2000,\n","         24.8000, 19.8000, 28.1000, 19.9000, 30.1000, 19.7000],\n","        [ 2.9000, -8.9000, -1.8000, -9.5000,  4.8000, -1.9000,  7.2000, -1.1000,\n","         -1.1000, -5.6000,  0.0000, -9.9000,  0.9000, -4.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[31.6000, 20.9000],\n","        [ 3.4000,  0.2000]], dtype=torch.float64)\n","input:\n","tensor([[14.5000,  6.8000, 11.1000,  1.3000,  6.5000,  0.9000,  9.5000,  4.8000,\n","         12.3000,  7.6000, 13.7000,  7.8000, 12.7000,  6.5000],\n","        [ 9.0000,  4.6000, 12.6000,  5.9000,  9.2000,  4.0000, 10.3000, -1.8000,\n","         -1.5000, -5.4000, -1.7000, -6.0000, -0.1000, -5.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.6000,  4.5000],\n","        [ 2.3000, -3.9000]], dtype=torch.float64)\n","input:\n","tensor([[26.4000, 16.2000, 29.6000, 16.9000, 28.8000, 20.3000, 29.4000, 17.8000,\n","         25.8000, 15.5000, 23.9000, 17.0000, 25.8000, 18.9000],\n","        [25.3000, 12.5000, 22.5000, 15.3000, 22.9000, 12.4000, 26.9000, 15.0000,\n","         27.4000, 14.9000, 23.2000, 13.1000, 18.5000, 12.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.3000, 19.9000],\n","        [23.9000, 12.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 20.6000,   8.9000,  23.3000,   9.8000,  15.4000,   7.2000,  14.5000,\n","           6.6000,  14.9000,   8.4000,  19.5000,   7.0000,  15.0500,   3.3000],\n","        [ -7.7000, -14.8000,  -5.1000, -12.3000,  -8.9000, -14.6000,   0.5000,\n","          -9.0000,   0.2000, -15.4000, -10.4000, -19.5000,  -3.5000, -11.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 10.6000,   3.7000],\n","        [ -2.1000, -10.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 18.9000,  14.7000,  17.3000,   9.2000,  12.2000,   6.5000,  10.5000,\n","           5.0000,  14.5000,  10.1000,  20.6000,  10.7000,  20.2000,   8.7000],\n","        [  1.3000,  -9.7000,   1.7000, -10.2000,  -9.0000, -14.8000,  -4.6000,\n","         -15.1000,  -0.3000,  -5.6000,   3.3000,  -3.1000,   6.9000,  -0.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.1000,  8.2000],\n","        [ 5.4000, -0.3000]], dtype=torch.float64)\n","input:\n","tensor([[  1.8000, -10.6000, -10.4000, -14.6000,   1.1000, -11.9000,   3.5000,\n","          -0.2000,   8.4000,   3.2000,   8.6000,   1.3000,   1.3000,  -3.5000],\n","        [ 22.9000,  12.8000,  18.8000,  11.0000,  13.2000,   9.5000,  15.6000,\n","          10.4000,  16.4000,  12.1000,  24.0000,  12.7000,  19.4000,   9.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.8000, -0.9000],\n","        [13.5000,  5.5000]], dtype=torch.float64)\n","input:\n","tensor([[18.4000,  5.5000,  5.8000, -1.4000,  5.1000, -2.9000, 20.0000,  4.6000,\n","          5.0000,  0.3000,  4.3000, -0.6000,  7.1000,  0.6000],\n","        [24.3000, 15.5000, 22.9000, 16.7000, 26.2000, 17.9000, 23.5000, 15.6000,\n","         25.2000, 13.2000, 24.8000, 19.8000, 28.1000, 19.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.2000,  3.7000],\n","        [30.1000, 19.7000]], dtype=torch.float64)\n","input:\n","tensor([[26.7000, 17.1000, 24.7250, 20.0000, 22.7500, 17.7333, 20.7750, 15.4667,\n","         18.8000, 13.2000, 23.4000, 13.2000, 20.4000, 13.6000],\n","        [-1.4000, -6.6000,  3.6000, -2.6000,  3.5000, -3.3000,  2.3000, -5.1000,\n","          2.9000, -8.9000, -1.8000, -9.5000,  4.8000, -1.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.7000, 14.5000],\n","        [ 7.2000, -1.1000]], dtype=torch.float64)\n","input:\n","tensor([[23.5000, 11.1000, 25.3000, 12.1000, 30.1000, 16.2000, 26.0000, 18.5000,\n","         16.8000, 13.9000, 18.0000, 13.2000, 25.3000, 12.5000],\n","        [23.3000, 15.4000, 21.9000, 13.7000, 17.2000, 12.8000, 24.4000, 13.5000,\n","         25.0000, 16.1000, 21.8000, 16.7000, 24.3000, 16.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.5000, 15.3000],\n","        [24.1000, 15.0000]], dtype=torch.float64)\n","input:\n","tensor([[16.7000, 11.3000, 11.3000,  6.7000, 18.4000,  5.5000,  5.8000, -1.4000,\n","          5.1000, -2.9000, 20.0000,  4.6000,  5.0000,  0.3000],\n","        [27.3000, 16.3000, 26.1000, 15.2000, 26.1000, 16.2000, 22.3000, 16.2000,\n","         25.9000, 15.0000, 20.6000, 11.0000, 14.8000,  8.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.3000, -0.6000],\n","        [20.8000,  8.0000]], dtype=torch.float64)\n","input:\n","tensor([[19.8000, 15.2000, 22.0000, 13.0000, 28.5000, 16.6000, 26.6000, 17.3000,\n","         26.7000, 16.5000, 24.6000, 14.4000, 23.0000, 17.4000],\n","        [26.8000, 14.5000, 28.1000, 14.7000, 29.0000, 20.6000, 29.6000, 19.2000,\n","         31.4000, 20.2000, 31.8000, 20.4000, 32.2000, 21.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.7000, 15.7000],\n","        [30.8000, 21.2000]], dtype=torch.float64)\n","input:\n","tensor([[ -9.0000, -16.2000,  -3.4000, -14.4000, -14.3000, -24.7000,  -9.6000,\n","         -22.4000,   0.0000,  -9.6000,   0.5000,  -0.8000,   0.0000,  -9.3000],\n","        [ 23.0000,  12.1000,  21.2000,  13.5000,  22.7000,  12.4000,  24.4000,\n","          12.6000,  24.8000,  14.6000,  24.2000,  15.2000,  19.3000,  16.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -3.0000, -11.0000],\n","        [ 16.6000,  14.9000]], dtype=torch.float64)\n","input:\n","tensor([[11.8000,  5.9000,  8.9000,  4.7000, 15.4000,  6.6000,  6.6000, -3.0000,\n","          4.6000, -3.3000,  7.5000,  3.5000,  6.5000, -0.1000],\n","        [15.0000,  5.4000, 18.0000,  9.3000, 17.9000,  8.9000, 17.6000,  9.0000,\n","         15.3000, 11.1000, 12.4000,  4.7000,  8.1000,  2.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.9000, -2.7000],\n","        [ 4.9000,  1.7000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.2000,  -4.7000,  -0.9000,  -5.9000,  -2.7000,  -9.9000,  -1.9000,\n","         -11.6000,   3.6000,  -1.9000,   4.4000,   2.2000,   4.5000,  -6.5000],\n","        [ 29.3000,  23.0000,  26.9000,  21.6000,  29.9000,  20.1000,  30.2000,\n","          21.3000,  32.8000,  21.5000,  29.3000,  22.5000,  25.1000,  17.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -6.3000, -12.6000],\n","        [ 23.5000,  14.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.7000,  3.0000, 11.8000,  2.2000, 12.3000,  3.9000, 25.0000,  7.3000,\n","         23.7000, 10.8000, 17.8000,  8.9000, 19.4000, 11.0000],\n","        [20.6000, 17.0000, 23.7000, 15.5000, 22.4000, 16.4000, 23.9000, 16.4000,\n","         22.8000, 17.5000, 24.2000, 15.4000, 22.8000, 14.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.6000, 12.4000],\n","        [24.2000, 12.6000]], dtype=torch.float64)\n","input:\n","tensor([[19.5000, 12.2000, 22.2000, 13.0000, 24.2000, 14.6000, 25.4000, 15.0000,\n","         21.9000, 14.4000, 24.6000, 12.3000, 15.8000,  8.5000],\n","        [14.9000,  8.4000, 19.5000,  7.0000, 15.0500,  3.3000, 10.6000,  3.7000,\n","          7.4000,  4.9000,  5.9000,  3.5000,  6.9500,  2.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.2000,  7.5000],\n","        [ 8.0000,  2.7000]], dtype=torch.float64)\n","input:\n","tensor([[24.2000, 13.0000, 18.1000, 10.5000, 20.6000, 12.5000, 22.4000, 12.0000,\n","         24.0000, 13.8000, 22.0000, 16.5000, 20.7000, 14.6000],\n","        [16.4000, 11.4000, 15.7000, 10.4000, 23.7000,  9.4000, 26.8000, 13.5000,\n","         27.7000, 16.4000, 27.5000, 16.8000, 26.3000, 17.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.1000, 12.2000],\n","        [24.2000, 13.0000]], dtype=torch.float64)\n","input:\n","tensor([[26.4000, 17.7000, 25.8000, 20.9000, 27.9000, 19.8000, 28.4000, 18.2000,\n","         26.6000, 19.6000, 27.0000, 17.9000, 26.8000, 17.3000],\n","        [15.8000,  6.5000, 16.1500,  7.0000, 16.5000,  1.9000, 13.0000,  0.6000,\n","         10.1000, -0.7000, 12.5000,  3.1000, 12.8000,  5.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.4000, 19.7000],\n","        [12.8000,  5.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 14.6000,   8.9000,   9.5000,   2.4000,   6.6000,   1.7000,  13.1000,\n","           4.8000,  14.8000,   9.5000,  15.4000,   8.8000,  12.8000,   7.3000],\n","        [  8.2000,  -3.1000,   7.1000,  -3.2000,  -3.2000,  -7.8000,  -4.8000,\n","         -10.9000,  -3.0000, -11.2000,  -0.8000,  -4.8000,   0.6000,  -7.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.0000,  3.4000],\n","        [ 2.6000, -6.3000]], dtype=torch.float64)\n","input:\n","tensor([[  1.8000,   0.6000,   0.7000,  -2.9000,   1.5000,  -2.9000,   2.3000,\n","         -10.1000,  -9.9000, -14.2000,  -3.7500, -13.1000,   2.4000,  -4.5000],\n","        [ 30.0000,  19.0000,  24.9000,  14.6000,  22.9000,  13.4000,  22.0000,\n","          13.7000,  27.6000,  18.7000,  29.6000,  21.1000,  27.7000,  20.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.7000, -2.4000],\n","        [24.8000, 16.4000]], dtype=torch.float64)\n","input:\n","tensor([[31.2000, 20.9000, 27.2000, 17.3000, 24.5000, 14.1000, 27.7000, 15.8000,\n","         29.1000, 17.6000, 31.2000, 21.2000, 29.9000, 19.7000],\n","        [ 3.7000, -1.1000,  4.7000,  1.7000,  3.8000, -2.2000, 10.1000, -2.0000,\n","          8.5000, -2.0000,  1.5000, -2.4000,  2.8000, -0.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.6000, 18.1000],\n","        [ 0.9000, -2.3000]], dtype=torch.float64)\n","input:\n","tensor([[11.1000,  2.5000, 10.4000,  2.7000, 11.5000,  4.0000,  9.4000,  5.0000,\n","         12.2000,  3.5000, 12.1000,  2.9000, 11.5000,  5.2000],\n","        [23.5000, 13.6000, 24.9000, 13.1000, 28.5000, 13.7000, 30.1000, 16.6000,\n","         24.7000, 16.6000, 28.8000, 18.0000, 31.5000, 18.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.3000,  4.6000],\n","        [30.0000, 20.1000]], dtype=torch.float64)\n","input:\n","tensor([[28.8000, 20.4000, 25.8000, 18.5000, 28.5000, 19.2000, 26.6000, 19.7000,\n","         27.7000, 20.2000, 29.8000, 20.3000, 31.2000, 20.9000],\n","        [22.1000, 14.3000, 22.9000, 14.8000, 22.4000, 16.2000, 25.3000, 17.1000,\n","         27.7000, 17.8000, 26.0000, 16.4000, 27.4000, 17.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.2000, 17.3000],\n","        [27.1000, 16.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 2.7000, -2.1000,  4.1000, -1.1000,  5.1000,  3.1000,  8.8000, -3.4000,\n","         -0.5000, -4.1000,  0.3000, -1.3000,  1.7000, -3.2000],\n","        [28.1000, 19.9000, 30.1000, 19.7000, 31.6000, 20.9000, 26.4000, 20.8000,\n","         29.1000, 21.4000, 25.9000, 18.9000, 23.0000, 15.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.5000, -0.2000],\n","        [23.8000, 14.0000]], dtype=torch.float64)\n","input:\n","tensor([[15.7000,  8.0000, 12.1000,  4.1000, 10.2000,  2.4000,  7.9000,  1.6000,\n","         13.6000,  4.4000, 17.1000, 10.3000, 13.2000, 10.5000],\n","        [ 3.2000, -4.4000,  4.2000, -3.9000,  8.4000, -1.8000,  6.4000, -1.1000,\n","          5.5000, -2.3000, 17.9000,  4.1000,  8.7000,  4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.6000,  8.9000],\n","        [12.3000,  6.0000]], dtype=torch.float64)\n","input:\n","tensor([[18.5000,  8.2000, 20.3000,  8.9000, 18.0000, 13.4000, 15.5000, 11.8000,\n","         16.4000, 12.7000, 19.8000, 14.7000, 22.8000, 12.4000],\n","        [24.3000, 13.4000, 23.9000, 14.7000, 23.2000, 15.9000, 19.3000, 14.3000,\n","         18.1000, 13.3000, 23.5000, 13.7000, 17.0000, 14.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[17.6000, 15.0000],\n","        [27.5000, 15.8000]], dtype=torch.float64)\n","input:\n","tensor([[17.1000,  4.8000, 11.1000,  3.8000, 13.9000,  7.8000, 13.1000,  6.2000,\n","         11.3000,  8.3000, 15.1000,  9.0000, 12.0000, 10.6000],\n","        [21.6000, 18.4000, 22.7000, 18.5000, 22.6000, 10.5000, 15.9000, 10.3000,\n","         14.8000,  7.8000, 15.8000,  7.1000, 18.2000, 10.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.3000,  9.6000],\n","        [18.9000,  9.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.7000, -3.1000,  8.6000,  1.0000,  9.1000,  6.4000,  7.1000, -1.7000,\n","         -0.3000, -6.1000, -0.9000, -6.5000,  1.8000, -6.3000],\n","        [27.0000, 15.7000, 27.6000, 14.5000, 31.6000, 18.7000, 35.5000, 21.5000,\n","         33.7000, 22.0000, 26.1000, 22.2000, 32.0000, 21.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.6000, -6.0000],\n","        [29.0000, 18.6000]], dtype=torch.float64)\n","input:\n","tensor([[28.9000, 15.1000, 29.7000, 16.0000, 30.7000, 19.9000, 32.2000, 20.1000,\n","         30.5000, 21.5000, 28.7000, 20.8000, 27.5000, 19.4000],\n","        [18.5000, 14.7000, 21.9000, 12.6000, 22.5000, 15.5000, 24.2000, 16.4000,\n","         19.3000, 14.9000, 21.3000, 12.7000, 22.4000, 16.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.9000, 17.4000],\n","        [23.2000, 18.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.9500,  2.1000,  8.0000,  2.7000, 10.1000,  5.7000, 14.4000,  5.2000,\n","         10.7000,  7.0000, 12.2000,  6.6000, 14.5000,  6.0000],\n","        [21.3000, 10.5000, 16.9000, 15.7000, 17.1000, 13.2000, 19.6000, 14.3000,\n","         19.6000,  9.7000, 17.4000,  7.9000, 18.2000,  9.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.2000,  7.0000],\n","        [19.0000, 10.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.5000,  4.4000,  7.6000,  2.1000,  4.0000, -0.1000,  7.4000, -1.1000,\n","         13.7000,  3.7000, 13.2000,  9.1000, 10.5000,  6.0000],\n","        [27.4000, 11.9000, 20.4000, 13.1000, 18.6000, 14.5000, 18.7000, 13.5000,\n","         30.6000, 16.8000, 31.1000, 20.4000, 32.3000, 20.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.4000,  5.1000],\n","        [33.5000, 18.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -7.7000, -12.7000, -10.3000, -18.3000,  -4.3000, -18.5000,   0.7000,\n","          -4.3000,  -0.5000,  -1.6000,   0.5000,  -2.4000,  -0.2000,  -3.8000],\n","        [ 29.3000,  22.5000,  25.1000,  17.1000,  23.5000,  14.3000,  23.6000,\n","          13.1000,  16.4000,  11.4000,  15.7000,  10.4000,  23.7000,   9.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-3.2000, -7.2000],\n","        [26.8000, 13.5000]], dtype=torch.float64)\n","input:\n","tensor([[26.4000, 16.7000, 24.9000, 13.8000, 24.7000, 16.5000, 22.3000, 15.1000,\n","         22.2000, 15.1000, 26.2000, 19.2000, 31.1000, 20.2000],\n","        [16.1000, 12.8000, 21.6000, 13.0000, 23.7000, 13.8000, 18.6000, 15.7000,\n","         21.3000, 17.4000, 26.4000, 16.8000, 22.6000, 15.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.7000, 19.2000],\n","        [26.6000, 15.1000]], dtype=torch.float64)\n","input:\n","tensor([[21.4000, 12.6000, 21.3000, 10.7000, 22.4000, 12.3000, 24.4000, 14.5000,\n","         28.9000, 15.6000, 30.5000, 17.2000, 34.2000, 21.3000],\n","        [20.9000, 10.7000, 22.4000, 10.4000, 24.3000, 11.7000, 16.7000, 11.3000,\n","         11.3000,  6.7000, 18.4000,  5.5000,  5.8000, -1.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[33.0000, 23.1000],\n","        [ 5.1000, -2.9000]], dtype=torch.float64)\n","input:\n","tensor([[27.1000, 19.4000, 23.2000, 15.5000, 24.0000, 12.7000, 23.8000, 14.9000,\n","         21.8000, 12.8000, 21.9000, 13.5000, 24.1000, 12.3000],\n","        [ 9.9000,  2.9000,  9.9000,  1.8000,  2.7000,  0.8000, 15.6000,  2.3000,\n","          4.5000, -0.3000,  2.2000, -2.0000,  4.6000,  0.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.1000, 13.7000],\n","        [ 6.0000, -0.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 18.3000,   8.4000,  14.3000,   5.0000,  15.1000,   4.1000,  15.8000,\n","           7.2000,  17.6000,   8.7000,  21.2000,  10.8000,  21.1000,  13.8000],\n","        [-11.3000, -21.3000,  -6.4000, -11.4000,  -2.7000, -15.4000, -14.2000,\n","         -20.2000,  -7.4000, -18.4000,  -7.2000, -13.6000,  -9.1000, -15.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 15.5000,   3.6000],\n","        [ -8.2000, -17.3000]], dtype=torch.float64)\n","input:\n","tensor([[27.4000, 15.8000, 29.0000, 19.0000, 27.7000, 19.4000, 25.9000, 19.4000,\n","         23.6000, 16.8000, 24.2000, 15.9000, 25.8000, 14.9000],\n","        [ 3.7000, -3.4000,  6.6000,  3.7000,  9.5000,  3.0000, 12.1000,  1.9000,\n","         15.2000,  3.7000, 18.3000,  7.3000, 24.3000, 10.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.1000, 15.3000],\n","        [21.2000, 12.4000]], dtype=torch.float64)\n","input:\n","tensor([[25.8000, 15.5000, 23.9000, 17.0000, 25.8000, 18.9000, 29.3000, 19.9000,\n","         25.3000, 16.5000, 25.6000, 14.5000, 29.9000, 18.7000],\n","        [24.1000, 18.2000, 21.2000, 17.5000, 25.6000, 16.7000, 27.5000, 19.2000,\n","         21.8000, 17.3000, 25.9000, 16.5000, 27.6000, 16.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.3000, 21.2000],\n","        [25.3000, 15.2000]], dtype=torch.float64)\n","input:\n","tensor([[18.2000,  7.2000, 12.7000,  9.1000, 12.6000, 10.1000, 20.9000, 11.9000,\n","         18.4000,  8.6000,  9.4000,  6.1000,  6.5000,  5.1000],\n","        [ 7.4000,  1.2000,  9.2000, -0.5000, 14.0000,  9.2000, 14.5000,  1.9000,\n","          4.3000,  0.0000,  6.5000,  2.9000,  7.8000, -1.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.7000,  4.6000],\n","        [ 4.4000, -0.9000]], dtype=torch.float64)\n","input:\n","tensor([[31.6000, 20.9000, 26.4000, 20.8000, 29.1000, 21.4000, 25.9000, 18.9000,\n","         23.0000, 15.3000, 23.8000, 14.0000, 24.4000, 15.9000],\n","        [13.1000,  2.7000, 10.7000,  1.9000, 12.3000,  2.7000, 17.7000,  6.3000,\n","         19.3000,  9.1000, 12.3000,  8.7000, 20.6000, 11.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.8000, 16.8000],\n","        [21.2000, 13.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.2000,  6.5000, 16.8000,  9.1000, 18.1000,  3.9000,  4.3000,  2.3000,\n","          7.1000,  2.3000,  6.1000,  2.8000,  9.7000,  1.4000],\n","        [24.7000, 18.0000, 28.2000, 19.0000, 23.9000, 19.5000, 27.9000, 19.3000,\n","         26.9000, 20.3000, 28.5000, 18.2000, 31.7000, 20.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.8000,  3.4000],\n","        [32.7000, 22.8000]], dtype=torch.float64)\n","input:\n","tensor([[19.0000, 15.7000, 24.8000, 15.8000, 27.2000, 17.6000, 20.9000, 15.7000,\n","         26.5000, 14.4000, 19.8000, 15.2000, 22.0000, 13.0000],\n","        [14.3000,  5.0000, 17.3000,  6.8000, 15.5000,  8.7000, 16.7000,  8.0000,\n","         16.4000,  8.8000, 17.2000,  8.6000, 15.2000, 11.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.5000, 16.6000],\n","        [17.9000, 11.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 29.4000,  16.8000,  28.9000,  16.9000,  30.0000,  20.2000,  24.9000,\n","          18.7000,  27.8000,  18.3000,  25.7000,  18.7000,  31.3000,  20.6000],\n","        [ -3.0000, -10.6000,   4.8000,  -7.2000,  10.2000,   3.0000,   3.5000,\n","           1.5000,   9.1000,  -0.3000,   9.9000,   1.4000,   9.3500,   3.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[31.7000, 21.8000],\n","        [ 8.8000,  0.9000]], dtype=torch.float64)\n","input:\n","tensor([[  4.5000,  -0.2000,   1.4000,  -0.3000,   0.7000,  -2.8000,  -1.8000,\n","         -17.0000, -11.3000, -20.9000,  -4.8000, -12.8000,  -2.4000,  -9.0000],\n","        [ -8.4000, -14.5000, -14.3000, -19.2000,  -7.1000, -22.3000,   0.3000,\n","          -7.2000,   1.4000,  -1.7000,   2.4000, -15.8000, -15.8000, -22.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  0.5000,  -5.8000],\n","        [ -7.7000, -16.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.9000,  5.3000, 10.7000,  1.1000,  1.1000, -4.3000,  0.9000, -4.7000,\n","          1.9000, -1.9000,  0.7000, -6.3000, -1.6000, -6.6000],\n","        [15.4000, 12.0000, 16.4000, 11.9000, 19.0000, 12.4000, 16.6000, 10.8000,\n","         20.4000, 11.2000, 25.2000, 14.1000, 24.5000, 13.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-2.9000, -6.8000],\n","        [28.2000, 15.1000]], dtype=torch.float64)\n","input:\n","tensor([[ -8.5000, -15.5000, -10.9000, -18.4000,  -8.1000, -15.6000,  -4.7000,\n","         -10.5000,  -2.9000,  -8.6000,   2.9000,  -4.9000,   2.8000,  -6.2000],\n","        [  9.8000,  -2.2000,   6.2000,  -1.5000,   4.7000,  -3.1000,   8.6000,\n","           1.0000,   9.1000,   6.4000,   7.1000,  -1.7000,  -0.3000,  -6.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.4000, -9.2000],\n","        [-0.9000, -6.5000]], dtype=torch.float64)\n","input:\n","tensor([[12.8000,  7.3000, 12.0000,  3.4000,  5.5000,  0.1000,  6.8000, -0.3000,\n","         11.6000,  5.9000, 14.8000,  2.0000,  2.6000, -1.2000],\n","        [19.7000, 12.7000, 26.8000, 15.9000, 19.8000, 14.7000, 17.2000, 13.1000,\n","         19.4000, 12.5000, 20.1000, 11.7000, 21.6000, 13.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.8000, -1.0000],\n","        [24.2000, 13.2000]], dtype=torch.float64)\n","input:\n","tensor([[16.7000, 10.5000, 12.6000,  5.1000, 11.9000,  5.8000, 13.8000,  8.7000,\n","         13.5000,  8.5000, 13.0000,  8.2000, 18.3000, 11.4000],\n","        [-2.1000, -9.6000, -2.1000, -8.1000,  2.4000, -6.8000,  3.8000,  1.9000,\n","          2.7000, -2.1000,  4.1000, -1.1000,  5.1000,  3.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.7000, 13.1000],\n","        [ 8.8000, -3.4000]], dtype=torch.float64)\n","input:\n","tensor([[  4.2000,  -4.0000,  -1.4000,  -6.2000,  -6.2000,  -8.4000,  -1.7000,\n","          -6.6000,   1.3000,  -2.7000,   1.5000,  -2.1000,  -1.9000,  -4.1000],\n","        [ -0.7000,  -6.4000,   0.6000,  -4.7000,   3.3000,  -0.7000,  -0.1000,\n","          -5.2000,  -4.1000,  -9.2000,  -6.7000, -11.7000,  -4.7000,  -9.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.5000, -2.3000],\n","        [ 0.5000, -5.7000]], dtype=torch.float64)\n","input:\n","tensor([[24.0000, 16.1000, 20.0000, 16.7000, 23.2000, 14.9000, 22.1000, 13.6000,\n","         23.4000, 13.9000, 24.3000, 18.4000, 20.8000, 15.8000],\n","        [13.4000,  7.3000, 17.0000,  8.8000, 13.9000,  9.0000, 17.1000,  8.7000,\n","         14.8000,  7.8000, 14.0000,  8.3000, 16.9000,  7.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[30.8000, 16.6000],\n","        [11.9000,  8.2000]], dtype=torch.float64)\n","input:\n","tensor([[  6.7000,   2.7000,   6.7000,   1.3000,   3.9000,   0.7000,   6.3000,\n","           1.5000,   6.0000,   1.9000,   3.9000,   0.3000,   1.0000,  -2.4000],\n","        [  0.7000,  -5.4000,   4.5000,   0.7000,   4.7000,   1.6000,   1.8000,\n","           0.6000,   0.7000,  -2.9000,   1.5000,  -2.9000,   2.3000, -10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -0.2000,  -6.5000],\n","        [ -9.9000, -14.2000]], dtype=torch.float64)\n","input:\n","tensor([[  5.7000,  -2.9000,  -1.7000,  -5.4000,  -0.1000,  -5.1000,  -1.2000,\n","         -10.6000,  -1.6000, -10.1000,   5.0000,  -2.4000,   4.2000,  -6.7000],\n","        [ 16.5000,  11.7000,  17.6000,   8.8000,  18.0000,   9.2000,  20.0000,\n","          12.0000,  17.6000,  11.1000,  15.4000,   9.3000,  11.7000,   6.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.9000, -6.3000],\n","        [13.8000,  3.8000]], dtype=torch.float64)\n","input:\n","tensor([[ -4.9000, -10.4000,  -6.4000, -10.6000,  -4.4000, -11.0000,  -1.4000,\n","          -7.5000,   1.6000, -14.5000, -12.0000, -19.3000,  -9.8000, -16.2000],\n","        [ 10.5000,   6.0000,   9.4000,   5.1000,   5.0000,  -0.7000,   7.3000,\n","           0.0000,   7.9000,   2.7000,   9.6000,   5.5000,  16.0000,   6.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-10.7000, -15.5000],\n","        [  9.4000,   1.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 13.8000,   6.6000,  14.4000,   6.3000,  16.8000,  10.7000,  20.6000,\n","          10.1000,  18.6000,   8.2000,  18.0000,   9.8000,  20.2000,  11.2000],\n","        [ -1.6000, -10.1000,   5.0000,  -2.4000,   4.2000,  -6.7000,  -0.9000,\n","          -6.3000,  -0.6000, -10.1000,   2.5000, -10.4000,   8.1000,   2.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.4000, 12.3000],\n","        [10.0000, -6.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.3000, -4.1000, -2.5000, -6.9000, -5.2000, -8.1000, -0.9000, -6.9000,\n","         -0.5000, -4.0000,  2.8000, -3.5000,  5.1000, -4.7000],\n","        [11.1000,  2.6000, 15.7000,  8.0000, 14.5000,  5.8000, 20.0000,  9.1000,\n","         16.8000, 10.0000, 17.8500, 10.9000, 18.9000,  9.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -4.6000, -12.5000],\n","        [ 12.3000,   4.4000]], dtype=torch.float64)\n","input:\n","tensor([[10.4000,  6.3000,  9.7000,  6.4000,  8.4000,  7.1000, 10.6000,  8.2000,\n","          9.8000,  3.5000,  7.5000,  2.5000,  7.0000,  2.6000],\n","        [ 0.0000, -5.9000,  3.4000, -5.2000,  7.5000,  0.9000,  2.0000, -3.5000,\n","          6.7000,  1.8000,  6.9000,  2.1000,  2.2000, -6.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.1000,  2.6000],\n","        [ 2.7000, -6.3000]], dtype=torch.float64)\n","input:\n","tensor([[ -4.6000, -14.0000,  -0.3000, -14.6000,   3.8000,  -1.5000,  -1.5000,\n","          -9.4000,  -4.2000, -10.9000,  -4.1000, -11.6000,  -7.7000, -12.7000],\n","        [ 13.3000,   7.5000,  13.9000,   8.4000,  12.9000,   9.2000,  11.6000,\n","           8.5000,  11.2000,   7.6000,  10.7000,   6.0000,  14.2000,   5.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-10.3000, -18.3000],\n","        [ 15.6000,   7.4000]], dtype=torch.float64)\n","input:\n","tensor([[28.9000, 19.0000, 29.0000, 18.1000, 26.9000, 17.7000, 22.8000, 10.1000,\n","         18.5000,  8.2000, 20.3000,  8.9000, 18.0000, 13.4000],\n","        [ 4.8000,  2.6000,  3.1000,  1.1000,  4.4000,  0.1000,  0.5000, -2.3000,\n","          0.8000, -4.3000,  3.7000,  0.2000,  3.5000, -3.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 15.5000,  11.8000],\n","        [ -2.0000, -10.9000]], dtype=torch.float64)\n","input:\n","tensor([[18.6000, 15.7000, 21.3000, 17.4000, 26.4000, 16.8000, 22.6000, 15.6000,\n","         26.6000, 15.1000, 24.4000, 13.9000, 26.1000, 14.7000],\n","        [20.8000, 12.6000, 22.0000, 13.8000, 21.6000, 18.4000, 22.7000, 18.5000,\n","         22.6000, 10.5000, 15.9000, 10.3000, 14.8000,  7.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.6000, 19.7000],\n","        [15.8000,  7.1000]], dtype=torch.float64)\n","input:\n","tensor([[  0.0000,  -9.3000,  -3.0000, -11.0000,   8.1000,  -3.3000,  12.9000,\n","           4.8000,   7.6000,  -1.0000,   1.0000,  -3.8000,   0.8000,  -2.7000],\n","        [  7.8000,   1.3000,   3.0000,   1.1000,  10.0000,   2.3000,   9.3000,\n","           6.4000,   8.3000,   2.0000,   7.7000,   1.3000,   7.1000,   0.3500]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.7000, -0.4000],\n","        [ 6.5000, -0.6000]], dtype=torch.float64)\n","input:\n","tensor([[  5.1000,  -1.8000,   5.3000,  -3.8000,   1.3000,  -2.9000,   1.6000,\n","          -0.6000,   0.9000,  -2.1000,  -1.3000,  -6.9000,   2.1000,  -6.4000],\n","        [  8.1000,   2.0000,  10.0000,  -6.0000,  -1.9000,  -6.4000,   1.4000,\n","          -3.2000,  -0.9000,  -5.5000,  -3.0000, -13.8000,  -8.7000, -16.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  3.6000,   0.8000],\n","        [ -1.7000, -12.5000]], dtype=torch.float64)\n","input:\n","tensor([[19.5000, 12.8000, 21.4000, 13.7000, 19.5000, 14.6000, 22.6000, 12.3000,\n","         25.7000, 14.5000, 21.3000, 10.5000, 16.9000, 15.7000],\n","        [23.9000, 17.0000, 25.8000, 18.9000, 29.3000, 19.9000, 25.3000, 16.5000,\n","         25.6000, 14.5000, 29.9000, 18.7000, 29.3000, 21.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[17.1000, 13.2000],\n","        [29.4000, 22.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 12.2000,   7.1000,   9.0000,   4.0000,  13.0000,   4.2000,  14.7000,\n","           8.4000,  12.2000,   5.1000,  12.8000,   4.1000,   9.6000,   2.8000],\n","        [ -2.5000,  -5.2000,  -4.7000, -10.4000,  -1.9000,  -6.5000,  -2.7000,\n","          -6.9000,   1.5000,  -4.1000,  -1.2000,  -5.2000,  -4.9000, -10.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.6000,  2.5000],\n","        [-3.0000, -9.5000]], dtype=torch.float64)\n","input:\n","tensor([[  4.8000,  -0.9000,   5.7000,   3.2000,   5.7000,   2.1000,   5.9000,\n","           2.0000,   5.1000,  -6.8000,  -6.8000, -13.4000,  -4.7000, -14.5000],\n","        [ -6.8000, -13.4000,  -4.7000, -14.5000,   5.0000,  -4.8000,  10.3000,\n","          -2.9000,  -2.9000,  -7.5000,  -0.3000,  -8.8000,  -5.3000, -10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.0000, -4.8000],\n","        [-1.5000, -7.3000]], dtype=torch.float64)\n","input:\n","tensor([[19.6000, 16.0000, 20.2000, 14.8000, 22.8000, 16.7000, 22.4000, 15.5000,\n","         19.6000,  9.0000, 13.4000,  6.3000, 12.6000,  3.9000],\n","        [28.3000, 19.8000, 27.8000, 16.9000, 21.9000, 15.3000, 27.0000, 15.3000,\n","         31.2000, 18.7000, 27.0000, 15.7000, 27.6000, 14.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[17.5000,  5.9000],\n","        [31.6000, 18.7000]], dtype=torch.float64)\n","input:\n","tensor([[22.9000, 13.3000, 25.1000, 16.5000, 29.6000, 17.3000, 27.1000, 13.8000,\n","         20.8000, 10.4000, 23.0000, 10.8000, 18.0000, 12.1000],\n","        [ 5.1000, -2.9000, 20.0000,  4.6000,  5.0000,  0.3000,  4.3000, -0.6000,\n","          7.1000,  0.6000,  6.2000,  3.7000, 13.1000,  2.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.9000, 12.6000],\n","        [11.4000,  2.7000]], dtype=torch.float64)\n","input:\n","tensor([[22.3000,  5.9000,  8.9000,  3.8000, 15.3000,  4.9000, 17.3000,  5.2000,\n","         18.1000,  6.0000, 18.5000,  4.6000, 13.0000,  3.6000],\n","        [19.5000, 12.0000, 20.7000, 11.0000, 21.8000, 11.7000, 24.0000, 13.6000,\n","         24.7000, 14.7000, 25.6000, 14.5000, 23.8000, 17.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.6000,  3.8000],\n","        [22.8000, 17.2000]], dtype=torch.float64)\n","input:\n","tensor([[  0.2000,  -2.9000,   0.4000,  -2.9000,   2.0000,  -0.6000,   3.8000,\n","           0.1000,   9.1000,   0.8000,   0.8000,  -4.4000,  -2.2000,  -6.8000],\n","        [ -8.8000, -13.6000,  -5.2000, -14.1000,  -1.6000,  -9.0000,   0.7000,\n","          -4.4000,  -2.4000, -11.9000,  -6.9000, -12.8000,  -2.2000, -14.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.5000, -3.9000],\n","        [ 0.7000, -4.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.9000, -2.1000, -1.3000, -6.9000,  2.1000, -6.4000,  3.6000,  0.8000,\n","          5.4000,  1.4000,  4.2000, -0.2000,  4.3000, -1.5000],\n","        [24.7000, 14.7000, 25.6000, 14.5000, 23.8000, 17.1000, 22.8000, 17.2000,\n","         23.6000, 18.0000, 24.8000, 18.4000, 23.3000, 18.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.8000, -0.7000],\n","        [24.2000, 15.8000]], dtype=torch.float64)\n","input:\n","tensor([[-13.3000, -20.5000, -11.3000, -21.3000,  -6.4000, -11.4000,  -2.7000,\n","         -15.4000, -14.2000, -20.2000,  -7.4000, -18.4000,  -7.2000, -13.6000],\n","        [  5.1000,  -1.9000,  10.0000,   1.3000,  11.1000,   0.1000,   0.1000,\n","          -6.1000,  -3.2000,  -8.8000,  -5.1000, -10.5000,  -3.9000, -12.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -9.1000, -15.6000],\n","        [ -0.1000,  -6.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 7.8000,  2.9000,  6.7000,  1.7000,  8.1000,  1.9000, 12.3000,  6.5000,\n","         11.1000,  4.7000, 15.5000,  6.9000, 10.4000,  2.3000],\n","        [20.8000, 10.4000, 23.0000, 10.8000, 18.0000, 12.1000, 27.9000, 12.6000,\n","         26.8000, 15.9000, 27.3000, 16.1000, 34.2000, 20.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.7000, -0.1000],\n","        [27.7000, 13.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.0000,  0.9000,  8.4000, -4.4000, -1.3000, -7.6000, -0.7000, -8.1000,\n","          6.6000, -3.4000,  9.5000,  0.1000,  9.1000,  2.8000],\n","        [-3.0000, -9.1000,  0.9000, -4.7000,  0.8000, -2.9000,  2.3000, -4.5000,\n","         12.3000,  1.8000, 11.6000,  5.4000, 18.6000,  6.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.6000,  2.6000],\n","        [15.2000,  3.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.9000,  4.0000,  9.4000,  5.0000,  9.4000,  6.5000, 14.0000,  6.9000,\n","         20.2000,  7.8000, 21.5000,  9.2000, 22.8000, 10.6000],\n","        [ 2.3000, -3.9000,  3.6000, -1.3000,  5.3000, -2.0000,  4.8000, -0.8000,\n","          8.7000,  3.0000,  7.1000,  1.4000,  6.4000,  0.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.5000,  9.7000],\n","        [ 7.4000,  1.7000]], dtype=torch.float64)\n","input:\n","tensor([[  6.6000,   0.9000,   9.6000,   2.8000,  10.3000,   2.2000,  13.0000,\n","           1.6000,  16.5000,  11.7000,  13.9000,  11.0000,  17.1000,   4.8000],\n","        [ -1.9000, -13.8000,  -1.7000, -13.9000, -10.7000, -14.7000,  -4.4000,\n","         -14.0000,  -0.7000,  -7.9000,  -7.9000, -13.7000,  -3.4000, -11.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.1000,  3.8000],\n","        [-1.7000, -7.5000]], dtype=torch.float64)\n","input:\n","tensor([[26.2000, 17.9000, 23.5000, 15.6000, 25.2000, 13.2000, 24.8000, 19.8000,\n","         28.1000, 19.9000, 30.1000, 19.7000, 31.6000, 20.9000],\n","        [22.6000, 12.9000, 24.8000, 14.3000, 23.6000, 14.4000, 25.2000, 12.6000,\n","         27.0000, 15.2000, 28.8000, 17.0000, 29.6000, 17.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.4000, 20.8000],\n","        [30.1000, 19.8000]], dtype=torch.float64)\n","input:\n","tensor([[ -1.6000,  -6.6000,  -2.9000,  -6.8000,  -3.4000,  -8.7000,  -2.9000,\n","          -8.6000,  -2.4000,  -9.1000,  -4.1000,  -8.4000,  -6.5000, -11.1000],\n","        [ 22.1000,  12.9000,  23.1000,  13.8000,  23.5000,  14.9000,  22.8000,\n","          15.1000,  24.9000,  14.4000,  27.4000,  15.8000,  29.0000,  19.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -5.5000, -11.1000],\n","        [ 27.7000,  19.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 5.6000, -2.1000,  6.9000, -1.8000,  2.8000, -5.3000,  3.1000, -1.2000,\n","          8.1000,  2.0000, 10.1000,  4.4000, 12.0000,  2.4000],\n","        [-0.2000, -4.2000,  3.8000, -0.9000,  8.3000,  3.0000, 13.1000,  8.0000,\n","         13.9000, 10.1000, 12.5000,  2.0000,  4.1000,  0.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.9000,  3.1000],\n","        [ 7.9000,  2.9000]], dtype=torch.float64)\n","input:\n","tensor([[12.3000,  6.6000, 11.5000,  5.4000, 13.4000,  7.3000, 17.0000,  8.8000,\n","         13.9000,  9.0000, 17.1000,  8.7000, 14.8000,  7.8000],\n","        [10.4000,  6.1000, 13.8000,  5.2000, 12.9000,  8.7000, 14.0000,  7.9000,\n","          9.0000,  5.8000, 14.3000,  5.0000, 17.3000,  6.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.0000,  8.3000],\n","        [15.5000,  8.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 8.3000, -0.1000,  5.0000, -3.0000,  0.8000, -5.1000,  1.4000, -5.9000,\n","         10.3000,  1.3000,  7.5000,  0.0000,  6.0000, -1.0000],\n","        [ 9.2000,  0.9000,  8.6000, -0.3000, 14.8000,  0.2000,  9.0000,  5.4000,\n","         14.5000,  6.8000, 14.5000,  7.8000, 20.3000,  9.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.3000,  1.5000],\n","        [23.5000, 13.0000]], dtype=torch.float64)\n","input:\n","tensor([[13.9000,  5.1000, 16.6000,  6.4000, 12.9000,  5.9000, 16.5000,  9.2000,\n","         12.4000,  4.9000, 11.9000,  4.1000, 20.5000, 10.6000],\n","        [15.9000,  6.1000, 22.5000,  6.9000, 12.2000,  4.7000, 10.6000,  5.1000,\n","         13.8000,  3.7000,  5.9000, -0.1000,  8.2000,  3.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.9000,  6.6000],\n","        [ 7.2000,  1.6000]], dtype=torch.float64)\n","input:\n","tensor([[28.7000, 16.1000, 23.8000, 12.4000, 23.8000, 13.1000, 24.1000, 12.6000,\n","         24.1000, 13.2000, 28.0000, 16.3000, 20.5000, 15.3000],\n","        [11.1000,  1.3000,  6.5000,  0.9000,  9.5000,  4.8000, 12.3000,  7.6000,\n","         13.7000,  7.8000, 12.7000,  6.5000, 10.6000,  4.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.3000, 14.8000],\n","        [ 5.6000,  0.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 26.5000,  17.9000,  28.8000,  19.8000,  25.6000,  18.4000,  21.9000,\n","          14.5000,  20.4000,  11.8000,  21.7000,  10.1000,  24.6000,  11.3000],\n","        [  4.5000,  -3.7000,   6.8000,   2.9000,   9.3000, -11.1000,  -6.6000,\n","         -15.3000,  -3.7000, -10.9000,  -8.8000, -13.9000,  -4.2000, -14.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.0000, 15.3000],\n","        [ 1.7000, -9.0000]], dtype=torch.float64)\n","input:\n","tensor([[  6.5000,  -0.6000,   1.4000,  -2.3000,   2.8000,  -2.0000,   2.4000,\n","          -1.9000,   1.7000,  -0.8000,   0.0000,  -5.6000,  -3.0000,  -6.6000],\n","        [  7.1000,   2.9000,   9.0000,  -1.0000,   1.4000, -10.6000,  -4.2000,\n","         -11.2000,   2.3000,  -6.5000,   2.3000,   0.1000,   1.0000,  -6.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-2.3000, -5.8000],\n","        [-1.7000, -6.9000]], dtype=torch.float64)\n","input:\n","tensor([[  1.7000, -13.2000,   4.6000,  -4.5000,  -3.7000,  -6.8000,  -3.6000,\n","         -12.5000,   2.0000,  -7.8000,   3.3000,  -0.3000,   2.6000,  -1.4000],\n","        [ 10.7000,   7.0000,  12.2000,   6.6000,  14.5000,   6.0000,  15.2000,\n","           7.0000,  16.9000,   9.3000,  21.0000,   9.7000,  18.3000,   8.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.0000,  0.4000],\n","        [14.3000,  5.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 31.1000,  22.2000,  31.2000,  22.1000,  29.6000,  22.8000,  25.9000,\n","          16.8000,  17.3000,  12.5000,  19.8000,  11.5000,  19.7000,  12.7000],\n","        [ -2.9000,  -9.4000,  -1.3000,  -6.4000,  -1.4000,  -9.2000,  -6.2000,\n","         -12.5000, -12.4000, -15.0000,  -8.8000, -15.8000,  -7.8000, -13.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 26.8000,  15.9000],\n","        [ -6.4000, -13.7000]], dtype=torch.float64)\n","input:\n","tensor([[13.0000,  0.6000, 10.1000, -0.7000, 12.5000,  3.1000, 12.8000,  5.2000,\n","         12.8000,  5.0000, 13.8000,  6.5000, 11.5000,  4.7000],\n","        [ 2.0000, -0.6000,  3.8000,  0.1000,  9.1000,  0.8000,  0.8000, -4.4000,\n","         -2.2000, -6.8000,  0.5000, -3.9000,  3.0000,  0.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 17.6000,   7.3000],\n","        [  0.7000, -16.4000]], dtype=torch.float64)\n","input:\n","tensor([[  9.9000,   1.4000,   9.3500,   3.9000,   8.8000,   0.9000,   4.4000,\n","          -0.5000,   6.6000,   1.9000,   5.0000,  -0.1000,  10.6000,  -1.1000],\n","        [ -4.9000, -10.3000,  -3.0000,  -9.5000,   1.3000,  -6.1000,   4.3000,\n","           0.8000,   4.8000,   1.1000,   2.3000,  -1.0000,  -0.9000, -11.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  8.8000,   2.9000],\n","        [ -4.5000, -14.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.8000, -9.0000, -3.0000, -6.9000, -1.6000, -7.0000,  0.4000, -8.3000,\n","          0.6000, -7.1000, -1.3000, -8.1000,  0.3000, -3.2000],\n","        [ 4.3000, -1.5000,  5.8000, -0.7000,  4.7000, -1.8000,  5.0000, -2.7000,\n","          8.8000, -1.5000, 12.0000,  0.7000, 15.5000,  1.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.5000, -2.6000],\n","        [12.8000,  2.7000]], dtype=torch.float64)\n","input:\n","tensor([[27.6000, 18.7000, 29.6000, 21.1000, 27.7000, 20.0000, 24.8000, 16.4000,\n","         26.5000, 15.3000, 29.0000, 17.7000, 29.7000, 19.8000],\n","        [14.5000,  6.6000, 14.9000,  8.4000, 19.5000,  7.0000, 15.0500,  3.3000,\n","         10.6000,  3.7000,  7.4000,  4.9000,  5.9000,  3.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.0000, 13.9000],\n","        [ 6.9500,  2.1000]], dtype=torch.float64)\n","input:\n","tensor([[28.2000, 20.5000, 23.0000, 19.4000, 24.6000, 18.3000, 27.3000, 17.2000,\n","         30.7000, 21.9000, 33.5000, 22.0000, 27.9000, 19.5000],\n","        [34.2000, 20.1000, 27.7000, 13.9000, 19.6000, 13.0000, 20.2000, 15.8000,\n","         19.9000, 14.3000, 19.3000, 12.6000, 19.7000, 13.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.2000, 18.0000],\n","        [27.3000, 13.3000]], dtype=torch.float64)\n","input:\n","tensor([[26.6000, 14.7000, 24.9000, 16.9000, 23.2000, 12.3000, 18.7000,  9.7000,\n","         17.0000, 10.0000, 18.2000, 13.6000, 21.2000, 10.7000],\n","        [12.6000,  2.4000, 10.6000,  2.0000, 10.5000,  4.2500, 10.4000,  6.5000,\n","         10.8000,  6.1000, 10.8000,  5.5000, 21.9000,  8.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.4000, 14.6000],\n","        [15.1000,  9.1000]], dtype=torch.float64)\n","input:\n","tensor([[ -4.2000,  -7.8000,  -5.0000,  -7.9000,  -4.8000,  -9.9000,  -2.3000,\n","          -7.3000,   0.9000,  -3.1000,   2.5000,  -3.9000,   7.2000,   2.1000],\n","        [ 13.4000,   6.9000,   8.1000,  -5.6000,  -5.5000,  -9.1000,  -4.6000,\n","          -9.3000,  -3.5000,  -9.4000,  -4.8000, -10.3000,  -2.8000, -10.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.1000, -8.5000],\n","        [-2.3000, -6.7000]], dtype=torch.float64)\n","input:\n","tensor([[21.5000, 13.7000, 23.3000, 13.6000, 23.2000, 15.3000, 22.7000, 19.0000,\n","         22.7000, 15.8000, 21.8000, 14.6000, 23.7000, 14.5000],\n","        [29.1000, 19.4000, 29.2000, 19.7000, 28.7000, 19.4000, 28.2000, 18.3000,\n","         30.4000, 21.8000, 31.4000, 23.5000, 28.8000, 18.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.1000, 15.7000],\n","        [25.9000, 16.3000]], dtype=torch.float64)\n","input:\n","tensor([[  5.8000,  -4.3000,   7.1000,  -8.8000,  -1.9000, -12.1000,   5.1000,\n","          -1.9000,  10.0000,   1.3000,  11.1000,   0.1000,   0.1000,  -6.1000],\n","        [ 33.9000,  21.7000,  27.1000,  17.9000,  26.5000,  18.2000,  31.6000,\n","          22.0000,  24.6000,  20.2000,  32.9000,  21.7000,  22.5000,  20.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-3.2000, -8.8000],\n","        [28.6000, 18.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.1000,  2.8000,  9.7000,  1.4000,  9.8000,  3.4000,  9.8000,  4.0000,\n","          9.2000,  4.1000, 10.2000,  5.2000, 10.1000,  3.8000],\n","        [16.7000,  0.7000,  9.1000,  3.7000,  9.7000,  3.7000, 10.4000,  6.9000,\n","         12.6000,  4.0000, 11.1000,  4.4000,  7.1000, -1.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.7000,  5.6000],\n","        [ 1.2000, -4.1000]], dtype=torch.float64)\n","input:\n","tensor([[18.0000, 16.3000, 22.5000, 13.4000, 14.9000, 12.1000, 18.7000, 13.6000,\n","         16.0000,  9.2000, 13.6000,  7.8000, 13.2000,  5.6000],\n","        [27.1000, 17.9000, 26.5000, 18.2000, 31.6000, 22.0000, 24.6000, 20.2000,\n","         32.9000, 21.7000, 22.5000, 20.0000, 28.6000, 18.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.8000,  6.1000],\n","        [29.3000, 18.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.9000, -3.6000,  3.2000, -4.4000,  4.2000, -3.9000,  8.4000, -1.8000,\n","          6.4000, -1.1000,  5.5000, -2.3000, 17.9000,  4.1000],\n","        [23.7000, 14.3000, 23.3000, 15.1000, 23.8000, 14.3000, 29.1000, 16.1000,\n","         30.7000, 19.5000, 34.1000, 21.1000, 30.3000, 22.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.7000,  4.8000],\n","        [28.1000, 20.4000]], dtype=torch.float64)\n","input:\n","tensor([[24.8000, 15.8000, 27.2000, 17.6000, 20.9000, 15.7000, 26.5000, 14.4000,\n","         19.8000, 15.2000, 22.0000, 13.0000, 28.5000, 16.6000],\n","        [17.2000, 13.1000, 19.4000, 12.5000, 20.1000, 11.7000, 21.6000, 13.8000,\n","         24.2000, 13.2000, 20.8000, 11.4000, 18.2000, 10.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.6000, 17.3000],\n","        [15.1000, 11.9000]], dtype=torch.float64)\n","input:\n","tensor([[19.4000, 13.5000, 27.3000, 16.3000, 26.1000, 15.2000, 26.1000, 16.2000,\n","         22.3000, 16.2000, 25.9000, 15.0000, 20.6000, 11.0000],\n","        [ 5.8000, -2.7000,  9.6000, -0.8000,  6.5000,  2.5000, 11.7000,  2.0000,\n","         12.3000,  4.2000, 11.0000,  5.8000, 16.0000,  6.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.8000,  8.2000],\n","        [19.2000,  6.6000]], dtype=torch.float64)\n","input:\n","tensor([[26.2000, 18.9000, 28.1000, 20.3000, 29.8000, 21.1000, 27.9000, 21.5000,\n","         26.7000, 22.1000, 27.1000, 20.2000, 26.7000, 20.5000],\n","        [31.7000, 19.1000, 26.7000, 14.9000, 26.0000, 15.9000, 23.9000, 15.0000,\n","         28.0000, 15.3000, 28.5000, 16.9000, 32.5000, 18.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.7000, 22.7000],\n","        [33.2000, 21.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.5000, -0.1000,  4.9000, -2.7000,  6.1000, -1.1000,  1.6000, -4.2000,\n","          4.7000, -1.1000,  6.9000,  0.0000,  7.8000,  1.3000],\n","        [ 4.8000, -1.9000,  7.2000, -1.1000, -1.1000, -5.6000,  0.0000, -9.9000,\n","          0.9000, -4.7000,  3.4000,  0.2000,  5.8000,  3.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[3.0000, 1.1000],\n","        [5.3000, 1.3000]], dtype=torch.float64)\n","input:\n","tensor([[  1.9000,  -5.0000,  -3.4000,  -8.0000,   0.0000,  -8.1000,  -1.5000,\n","          -6.0000,  -1.1000, -12.8000,   7.1000,  -3.9000,   9.0000,   5.6000],\n","        [ 15.5000,   6.9000,  10.4000,   2.3000,   3.7000,  -0.1000,   3.9000,\n","          -0.6000,   4.3000,  -2.1000,   6.0000,   0.2000,  12.0000,   5.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.2000,  4.6000],\n","        [ 5.9000,  1.8000]], dtype=torch.float64)\n","input:\n","tensor([[ -7.4000, -18.4000,  -7.2000, -13.6000,  -9.1000, -15.6000,  -8.2000,\n","         -17.3000,  -4.4000, -14.6000,  -3.1000,  -8.1000,  -1.3000,  -8.1000],\n","        [ 28.6000,  15.5000,  27.1000,  17.1000,  29.1000,  18.6000,  26.3000,\n","          17.1000,  20.9000,  17.3000,  24.2000,  15.6000,  26.6000,  16.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.3000, -9.7000],\n","        [19.3000, 12.1000]], dtype=torch.float64)\n","input:\n","tensor([[ -8.7000, -16.0000,  -1.7000, -12.5000,  -6.7000, -12.5000,   0.1000,\n","          -9.6000,   7.3000,   0.1000,   2.3000,  -2.8000,   3.5000,  -3.3000],\n","        [ 13.9000,   5.3000,  16.1000,   6.3000,  18.1000,   7.3000,  12.4000,\n","           5.4000,  14.7000,   5.0000,  16.2000,   6.9000,   9.3000,   3.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.3000,  2.9000],\n","        [10.7000,  2.1000]], dtype=torch.float64)\n","input:\n","tensor([[10.6000,  3.7000,  7.4000,  4.9000,  5.9000,  3.5000,  6.9500,  2.1000,\n","          8.0000,  2.7000, 10.1000,  5.7000, 14.4000,  5.2000],\n","        [ 9.2000,  4.1000, 10.2000,  5.2000, 10.1000,  3.8000, 13.7000,  5.6000,\n","         11.8000,  1.4000,  4.3000, -0.8000,  3.2000, -0.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.7000,  7.0000],\n","        [ 3.7000, -0.6000]], dtype=torch.float64)\n","input:\n","tensor([[10.7000,  6.1000, 11.9000,  6.1000, 10.4000,  6.3000,  9.7000,  6.4000,\n","          8.4000,  7.1000, 10.6000,  8.2000,  9.8000,  3.5000],\n","        [26.2000, 18.5000, 24.2000, 17.5000, 26.0000, 16.8000, 25.4000, 16.7000,\n","         25.5000, 16.5000, 26.1000, 16.8000, 26.7000, 17.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.5000,  2.5000],\n","        [24.7250, 20.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.1000, -0.9000, -0.6000, -5.8000,  4.8000, -1.1000,  5.3000,  1.1000,\n","          1.3000, -4.2000, -2.4000, -5.4000,  3.0000, -3.1000],\n","        [ 5.1000,  0.0000,  5.7000,  1.3000,  6.7000,  4.2000, 11.5000,  5.9000,\n","         11.1000,  5.1000, 14.0000,  5.8000,  9.3000,  4.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[2.8000, 1.5000],\n","        [8.2000, 5.2000]], dtype=torch.float64)\n","input:\n","tensor([[13.0000,  4.2000, 14.7000,  8.4000, 12.2000,  5.1000, 12.8000,  4.1000,\n","          9.6000,  2.8000,  9.6000,  2.5000, 19.3000,  8.9000],\n","        [ 3.2000, -0.6000,  0.2000, -3.1000,  3.9000, -2.2000,  6.1000, -0.9000,\n","         -0.6000, -5.8000,  4.8000, -1.1000,  5.3000,  1.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.3000,  6.1000],\n","        [ 1.3000, -4.2000]], dtype=torch.float64)\n","input:\n","tensor([[22.0000, 14.9000, 24.0000, 15.0000, 23.9000, 12.2000, 26.5000, 16.3000,\n","         26.0000, 16.4000, 20.4000, 13.2000, 19.4000, 12.7000],\n","        [22.7000, 19.0000, 22.7000, 15.8000, 21.8000, 14.6000, 23.7000, 14.5000,\n","         25.1000, 15.7000, 26.8000, 16.4000, 25.9000, 15.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.1000, 12.1000],\n","        [25.4000, 15.2000]], dtype=torch.float64)\n","input:\n","tensor([[  0.6000,  -7.0000,   2.6000,  -6.3000,   2.7000,  -4.1000,   1.4000,\n","          -7.0000,  -7.0000, -14.7000,  -9.3000, -16.7000,   1.6000, -10.7000],\n","        [ 16.8000,   5.9000,  25.6000,   8.7000,  17.8000,  11.2000,  25.5000,\n","          12.3000,  18.7000,  13.1000,  27.4000,  11.9000,  20.4000,  13.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.1000, -4.0000],\n","        [18.6000, 14.5000]], dtype=torch.float64)\n","input:\n","tensor([[12.0000,  5.2000, 11.3000,  0.3000,  2.1000, -0.3000,  3.3000, -1.2000,\n","         -0.5000, -5.4000,  0.7000, -5.9000, -3.2000, -4.7000],\n","        [24.3000, 13.0000, 26.2000, 18.9000, 28.1000, 20.3000, 29.8000, 21.1000,\n","         27.9000, 21.5000, 26.7000, 22.1000, 27.1000, 20.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.9000, -5.9000],\n","        [26.7000, 20.5000]], dtype=torch.float64)\n","input:\n","tensor([[28.0000, 18.4000, 28.9000, 18.8000, 31.3000, 18.2000, 32.0000, 21.3000,\n","         31.1000, 23.6000, 29.4000, 21.0000, 31.5000, 21.0000],\n","        [21.3000, 10.0000, 16.1000, 12.8000, 21.6000, 13.0000, 23.7000, 13.8000,\n","         18.6000, 15.7000, 21.3000, 17.4000, 26.4000, 16.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[36.7000, 23.7000],\n","        [22.6000, 15.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 29.3000,  17.4000,  29.8000,  20.5000,  23.8000,  15.7000,  23.8000,\n","          14.4000,  26.9000,  14.7000,  26.0000,  18.7000,  26.7000,  18.8000],\n","        [-11.6000, -18.6000,  -9.2000, -16.5000,  -0.4000, -10.6000,   1.5000,\n","          -2.5000,   1.4000,  -1.1000,   0.9000,  -6.1000,  -2.4000,  -9.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 23.6000,  18.1000],\n","        [ -3.9000, -10.5000]], dtype=torch.float64)\n","input:\n","tensor([[16.4000, 11.9000, 19.0000, 12.4000, 16.6000, 10.8000, 20.4000, 11.2000,\n","         25.2000, 14.1000, 24.5000, 13.2000, 28.2000, 15.1000],\n","        [18.3000,  7.3000, 24.3000, 10.7000, 21.2000, 12.4000, 17.8000,  9.0000,\n","         23.8000, 11.4000, 14.4000,  9.1000, 17.2000,  7.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.1000, 18.3000],\n","        [11.1000,  5.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.1000, -8.5000, -5.1000, -8.8000,  3.1000, -6.2000,  4.5000,  2.5000,\n","          5.1000,  2.3000,  4.7000, -3.4000, -2.5000, -5.2000],\n","        [ 6.9000,  0.0000,  7.8000,  1.3000,  3.0000,  1.1000, 10.0000,  2.3000,\n","          9.3000,  6.4000,  8.3000,  2.0000,  7.7000,  1.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -4.7000, -10.4000],\n","        [  7.1000,   0.3500]], dtype=torch.float64)\n","input:\n","tensor([[23.3000, 15.7000, 22.1000, 13.0000, 24.7000, 14.6000, 27.8000, 16.6000,\n","         29.5000, 20.2000, 22.3000, 17.3000, 25.3000, 15.7000],\n","        [28.1000, 19.5000, 27.7000, 21.3000, 29.4000, 21.0000, 29.1000, 21.2000,\n","         24.5000, 20.8000, 24.5000, 20.4000, 24.8000, 16.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.1000, 14.2000],\n","        [21.8000, 15.3000]], dtype=torch.float64)\n","input:\n","tensor([[ -1.2000, -10.6000,  -1.6000, -10.1000,   5.0000,  -2.4000,   4.2000,\n","          -6.7000,  -0.9000,  -6.3000,  -0.6000, -10.1000,   2.5000, -10.4000],\n","        [ 23.6000,  18.0000,  24.8000,  18.4000,  23.3000,  18.7000,  24.2000,\n","          15.8000,  20.5000,  15.0000,  23.6000,  15.5000,  25.0000,  14.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.1000,  2.0000],\n","        [26.2000, 13.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.9000,  1.4000,  8.5000,  1.5000,  9.3000,  4.5000, 12.8000,  4.0000,\n","         15.9000,  6.1000, 22.5000,  6.9000, 12.2000,  4.7000],\n","        [27.6000, 19.5000, 27.3000, 16.7000, 21.9000, 14.6000, 22.1000, 14.3000,\n","         22.9000, 14.8000, 22.4000, 16.2000, 25.3000, 17.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.6000,  5.1000],\n","        [27.7000, 17.8000]], dtype=torch.float64)\n","input:\n","tensor([[19.0000, 10.9000, 19.8000,  9.8000, 19.3000,  9.6000, 16.5000, 11.7000,\n","         17.6000,  8.8000, 18.0000,  9.2000, 20.0000, 12.0000],\n","        [11.3000,  4.6000, 10.7000,  5.8000, 11.4000,  5.3000,  7.4000,  1.4000,\n","          7.5000,  0.1000,  7.4000,  1.2000,  9.2000, -0.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[17.6000, 11.1000],\n","        [14.0000,  9.2000]], dtype=torch.float64)\n","input:\n","tensor([[26.0000, 16.8000, 25.4000, 16.7000, 25.5000, 16.5000, 26.1000, 16.8000,\n","         26.7000, 17.1000, 24.7250, 20.0000, 22.7500, 17.7333],\n","        [18.0000,  9.3000, 17.9000,  8.9000, 17.6000,  9.0000, 15.3000, 11.1000,\n","         12.4000,  4.7000,  8.1000,  2.9000,  4.9000,  1.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.7750, 15.4667],\n","        [ 6.6000,  2.5000]], dtype=torch.float64)\n","input:\n","tensor([[-6.3000, -9.1000,  1.2000, -7.3000,  1.3000, -4.6000,  4.1000,  0.8000,\n","          3.7000, -1.1000,  4.7000,  1.7000,  3.8000, -2.2000],\n","        [23.5000, 15.1000, 20.5000, 13.6000, 23.2000, 14.9000, 23.8000, 13.2000,\n","         26.1000, 16.2000, 26.8000, 17.7000, 24.6000, 16.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.1000, -2.0000],\n","        [23.9000, 15.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 10.6000,   4.8000,  10.4000,   4.5000,  11.9000,   2.9000,  12.6000,\n","           6.0000,   8.1000,   5.9000,   6.7000,   5.1000,  15.0000,   6.2000],\n","        [  0.1000,  -5.0000,  -4.9000, -13.2000,  -2.3000, -13.0000,   1.9000,\n","          -3.3000,  -1.4000,  -8.8000,  -0.1000,  -9.6000,   1.6000,  -5.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.6000,  8.0000],\n","        [ 0.1000, -6.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 28.0000,  16.9000,  26.6000,  14.7000,  24.9000,  16.9000,  23.2000,\n","          12.3000,  18.7000,   9.7000,  17.0000,  10.0000,  18.2000,  13.6000],\n","        [ -1.1000, -12.8000,   7.1000,  -3.9000,   9.0000,   5.6000,  15.2000,\n","           4.6000,   4.6000,   1.3000,   3.7500,   1.3000,   2.9000,  -3.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.2000, 10.7000],\n","        [-1.8000, -5.5000]], dtype=torch.float64)\n","input:\n","tensor([[23.4000, 13.2000, 20.4000, 13.6000, 22.7000, 14.5000, 20.5000, 14.1000,\n","         21.7000, 13.4000, 24.2000, 17.6000, 26.1000, 18.0000],\n","        [27.1000, 18.0000, 30.0000, 20.2000, 31.4000, 22.5000, 31.7000, 23.5000,\n","         35.4000, 24.7000, 33.9000, 25.2000, 34.7000, 21.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.9000, 17.9000],\n","        [29.8000, 20.7000]], dtype=torch.float64)\n","input:\n","tensor([[17.3000, 12.8000, 12.8000,  7.8000,  9.9000,  7.9000, 14.5000,  7.9000,\n","         18.5000, 11.5000, 18.9000,  9.6000, 24.5000, 13.7000],\n","        [25.6000, 18.4000, 21.9000, 14.5000, 20.4000, 11.8000, 21.7000, 10.1000,\n","         24.6000, 11.3000, 27.0000, 15.3000, 28.5000, 16.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.3000, 14.8000],\n","        [20.4000, 12.4000]], dtype=torch.float64)\n","input:\n","tensor([[23.9000, 12.0000, 25.1000, 13.4000, 20.5000, 15.9000, 26.0000, 15.7000,\n","         23.7000, 16.8000, 22.9000, 15.8000, 25.4000, 16.9000],\n","        [17.0000, 10.2000, 10.7000,  7.9000, 15.6000,  6.2000, 14.6000,  8.8000,\n","         17.5000,  8.8000, 18.9000,  9.2000, 13.5000,  7.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.8000, 12.7000],\n","        [19.5000,  6.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.3000, -2.5000,  2.0000, -1.4000,  4.0000, -0.3000,  5.1000, -1.8000,\n","          5.3000, -3.8000,  1.3000, -2.9000,  1.6000, -0.6000],\n","        [18.8000, 13.7000, 18.6000, 12.7000, 16.7000, 11.8000, 13.8000,  4.4000,\n","          9.2000,  3.0000, 11.4000,  6.8000, 11.5000,  7.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.9000, -2.1000],\n","        [13.9000,  5.1000]], dtype=torch.float64)\n","input:\n","tensor([[24.7000, 16.5000, 22.3000, 15.1000, 22.2000, 15.1000, 26.2000, 19.2000,\n","         31.1000, 20.2000, 26.7000, 19.2000, 26.5000, 18.6000],\n","        [23.7000, 10.8000, 17.8000,  8.9000, 19.4000, 11.0000, 22.6000, 12.4000,\n","         26.3000, 14.2000, 22.3000, 14.5000, 25.7000, 14.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.2000, 19.4000],\n","        [23.5000,  4.9000]], dtype=torch.float64)\n","input:\n","tensor([[25.3000, 16.0000, 22.1000, 12.6000, 22.6000, 14.8000, 20.7000, 17.1000,\n","         29.1000, 19.4000, 30.3000, 20.4000, 28.4000, 18.1000],\n","        [30.1000, 16.2000, 26.0000, 18.5000, 16.8000, 13.9000, 18.0000, 13.2000,\n","         25.3000, 12.5000, 22.5000, 15.3000, 22.9000, 12.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.7000, 18.8000],\n","        [26.9000, 15.0000]], dtype=torch.float64)\n","input:\n","tensor([[25.9000, 14.3000, 27.8000, 15.9000, 26.7000, 19.1000, 25.1000, 20.2000,\n","         26.4000, 19.6000, 29.7000, 18.5000, 28.6000, 18.5000],\n","        [12.4000,  5.1000, 15.7000,  9.9000, 11.8000,  2.6000,  3.9000, -1.6000,\n","          3.8000, -2.5000,  7.1000,  2.9000,  9.0000, -1.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 30.5000,  19.8000],\n","        [  1.4000, -10.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 3.3000, -0.3000,  2.6000, -1.4000,  3.0000,  0.4000,  4.2000,  0.5000,\n","          2.1000,  0.5000,  4.0000, -0.5000, -0.5000, -5.7000],\n","        [18.3000, 13.9000, 22.2000, 11.5000, 23.3000, 13.4000, 17.5000,  8.3000,\n","         15.6000,  7.7000, 12.2000,  6.8000, 14.7000, 10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-2.3000, -7.9000],\n","        [15.7000,  5.9000]], dtype=torch.float64)\n","input:\n","tensor([[ -0.7000,  -7.3000,  -7.2000, -15.8000,  -6.9000, -17.5000,  -1.7000,\n","          -8.1000,   9.8000,  -2.2000,   6.2000,  -1.5000,   4.7000,  -3.1000],\n","        [ 16.9000,   3.3000,  16.6000,   8.2000,   8.8000,   3.1000,   7.4000,\n","           0.6000,  12.1000,   2.7000,   6.8000,   2.3000,   9.0000,   4.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.6000,  1.0000],\n","        [12.6000,  5.9000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.8000, -10.3000,  -3.0000,  -9.1000,   0.9000,  -4.7000,   0.8000,\n","          -2.9000,   2.3000,  -4.5000,  12.3000,   1.8000,  11.6000,   5.4000],\n","        [ 21.8000,  15.4000,  21.6000,  14.0000,  23.6000,  14.8000,  25.1000,\n","          15.1000,  27.5000,  17.1000,  25.8000,  17.4000,  26.8000,  19.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.6000,  6.7000],\n","        [26.2000, 18.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 32.8000,  22.6000,  31.1500,  25.0000,  29.5000,  22.5000,  28.8000,\n","          20.4000,  25.8000,  18.5000,  28.5000,  19.2000,  26.6000,  19.7000],\n","        [  0.7000,  -3.7000,   3.5000,  -0.7000,   1.8000,   0.0000,   1.3000,\n","          -0.6000,   2.2000,  -2.3000,   1.9000,  -6.5000,  -6.5000, -14.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 27.7000,  20.2000],\n","        [ -2.0000, -15.0000]], dtype=torch.float64)\n","input:\n","tensor([[26.9000, 14.4000, 25.4000, 15.4000, 18.1000, 12.5000, 17.1000,  7.8000,\n","         14.2000,  6.7000, 17.6000,  5.5000, 14.1000, 10.1000],\n","        [20.2000, 11.2000, 22.4000, 12.3000, 21.5000,  8.4000, 16.2000,  7.2000,\n","         14.9000,  7.7000, 11.9000,  4.6000, 12.6000,  5.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.9000, 11.9000],\n","        [13.8000,  3.3000]], dtype=torch.float64)\n","input:\n","tensor([[24.8000, 18.4000, 23.3000, 18.7000, 24.2000, 15.8000, 20.5000, 15.0000,\n","         23.6000, 15.5000, 25.0000, 14.9000, 26.2000, 13.1000],\n","        [16.0000,  6.5000, 19.2000,  6.6000, 10.3000,  3.3000,  6.4000,  2.4000,\n","          8.5000,  3.4000,  7.7000,  2.0000, 11.3000,  3.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.0000, 12.1000],\n","        [11.8000,  1.4000]], dtype=torch.float64)\n","input:\n","tensor([[27.7000, 13.2000, 20.2000, 16.3000, 20.9000, 16.3000, 24.7000, 15.5000,\n","         27.2000, 16.6000, 29.1000, 17.0000, 30.6000, 19.6000],\n","        [17.3000,  9.2000, 12.2000,  6.5000, 10.5000,  5.0000, 14.5000, 10.1000,\n","         20.6000, 10.7000, 20.2000,  8.7000, 18.1000,  8.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.7000, 20.2000],\n","        [21.5000,  9.9000]], dtype=torch.float64)\n","input:\n","tensor([[  3.6000,  -3.6000,   0.7000,  -0.8000,   1.9000,  -5.0000,  -3.4000,\n","          -8.0000,   0.0000,  -8.1000,  -1.5000,  -6.0000,  -1.1000, -12.8000],\n","        [ 20.9000,  17.3000,  24.2000,  15.6000,  26.6000,  16.4000,  19.3000,\n","          12.1000,  19.7000,  12.0000,  21.3000,  10.0000,  16.1000,  12.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.1000, -3.9000],\n","        [21.6000, 13.0000]], dtype=torch.float64)\n","input:\n","tensor([[31.7000, 23.5000, 35.4000, 24.7000, 33.9000, 25.2000, 34.7000, 21.3000,\n","         29.8000, 20.7000, 22.3000, 17.3000, 23.6000, 17.3000],\n","        [30.3000, 22.6000, 29.2000, 19.5000, 23.5000, 13.8000, 24.3000, 12.9000,\n","         26.8000, 15.5000, 26.9000, 17.2000, 28.4000, 18.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.4000, 16.8000],\n","        [23.7000, 16.6000]], dtype=torch.float64)\n","input:\n","tensor([[23.2000, 15.5000, 24.0000, 12.7000, 23.8000, 14.9000, 21.8000, 12.8000,\n","         21.9000, 13.5000, 24.1000, 12.3000, 25.1000, 13.7000],\n","        [14.7000,  5.0000, 16.2000,  6.9000,  9.3000,  3.5000, 10.7000,  2.1000,\n","         13.8000,  8.3000, 10.7000,  7.9000, 18.1000, 10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.7000, 16.2000],\n","        [19.7000, 12.9000]], dtype=torch.float64)\n","input:\n","tensor([[29.4000, 17.8000, 25.8000, 15.5000, 23.9000, 17.0000, 25.8000, 18.9000,\n","         29.3000, 19.9000, 25.3000, 16.5000, 25.6000, 14.5000],\n","        [22.8000, 10.6000, 21.5000,  9.7000, 13.4000,  6.3000, 11.2000,  8.1000,\n","          8.9000,  6.7000, 15.8000,  8.2000, 12.3000,  7.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.9000, 18.7000],\n","        [19.9000,  6.7000]], dtype=torch.float64)\n","input:\n","tensor([[20.6000, 10.1000, 18.6000,  8.2000, 18.0000,  9.8000, 20.2000, 11.2000,\n","         22.4000, 12.3000, 21.5000,  8.4000, 16.2000,  7.2000],\n","        [27.2000, 17.3000, 24.5000, 14.1000, 27.7000, 15.8000, 29.1000, 17.6000,\n","         31.2000, 21.2000, 29.9000, 19.7000, 26.6000, 18.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.9000,  7.7000],\n","        [30.7000, 20.7000]], dtype=torch.float64)\n","input:\n","tensor([[26.7000, 16.2000, 26.4000, 16.7000, 27.4000, 16.9000, 29.7000, 18.1000,\n","         29.9000, 19.1000, 29.1000, 19.5000, 24.1000, 17.2000],\n","        [25.1000, 15.1000, 27.5000, 17.1000, 25.8000, 17.4000, 26.8000, 19.7000,\n","         26.2000, 18.5000, 24.2000, 17.5000, 26.0000, 16.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.5000, 15.9000],\n","        [25.4000, 16.7000]], dtype=torch.float64)\n","input:\n","tensor([[  9.7000,   0.9000,   6.4000,  -3.4000,   3.1000,  -4.9000,   1.5000,\n","          -5.4000,   7.7000,  -0.6000,   6.5000,  -5.2000,  -1.3000,  -9.4000],\n","        [ -9.6000, -22.4000,   0.0000,  -9.6000,   0.5000,  -0.8000,   0.0000,\n","          -9.3000,  -3.0000, -11.0000,   8.1000,  -3.3000,  12.9000,   4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -2.7000, -10.6000],\n","        [  7.6000,  -1.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 8.4000,  4.8000,  6.7000,  2.7000,  6.7000,  1.3000,  3.9000,  0.7000,\n","          6.3000,  1.5000,  6.0000,  1.9000,  3.9000,  0.3000],\n","        [24.9000, 18.7000, 25.8000, 17.9000, 20.5000, 14.2000, 18.2000, 13.2000,\n","         24.1000, 13.3000, 19.8000, 11.6000, 18.7000, 10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.0000, -2.4000],\n","        [20.2000, 11.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -0.8000,  -4.8000,   0.6000,  -7.0000,   2.6000,  -6.3000,   2.7000,\n","          -4.1000,   1.4000,  -7.0000,  -7.0000, -14.7000,  -9.3000, -16.7000],\n","        [ 22.0000,  13.8000,  23.3000,  15.6000,  26.8000,  16.5000,  28.7000,\n","          16.1000,  23.8000,  12.4000,  23.8000,  13.1000,  24.1000,  12.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  1.6000, -10.7000],\n","        [ 24.1000,  13.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 30.8000,  18.2000,  26.8000,  21.0000,  26.6000,  19.6000,  28.8000,\n","          17.7000,  28.9000,  17.8000,  32.0000,  19.6000,  25.6000,  17.6000],\n","        [  3.8000,   0.1000,   9.1000,   0.8000,   0.8000,  -4.4000,  -2.2000,\n","          -6.8000,   0.5000,  -3.9000,   3.0000,   0.2000,   0.7000, -16.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 24.1000,  16.5000],\n","        [ -7.9000, -16.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.6000, -4.6000, 13.4000,  3.6000, 10.3000,  1.7000,  7.1000,  3.7000,\n","          4.4000,  1.0000, 16.9000,  3.3000, 16.6000,  8.2000],\n","        [25.6000,  8.7000, 17.8000, 11.2000, 25.5000, 12.3000, 18.7000, 13.1000,\n","         27.4000, 11.9000, 20.4000, 13.1000, 18.6000, 14.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.8000,  3.1000],\n","        [18.7000, 13.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.1000, -2.3000,  2.7000, -4.0000, -0.7000, -5.7000,  0.2000, -6.8000,\n","          7.1000, -1.2000,  8.3000, -0.1000,  5.0000, -3.0000],\n","        [22.8000, 17.2000, 23.6000, 18.0000, 24.8000, 18.4000, 23.3000, 18.7000,\n","         24.2000, 15.8000, 20.5000, 15.0000, 23.6000, 15.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.8000, -5.1000],\n","        [25.0000, 14.9000]], dtype=torch.float64)\n","input:\n","tensor([[ -1.3000,  -8.4000,   1.0000,  -7.5000,  -0.4000,  -6.4000,  -5.5000,\n","          -9.7000,  -2.6000, -12.3000,   4.5000,  -3.7000,   6.8000,   2.9000],\n","        [ 19.2000,   6.6000,  10.3000,   3.3000,   6.4000,   2.4000,   8.5000,\n","           3.4000,   7.7000,   2.0000,  11.3000,   3.1000,  11.8000,   1.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  9.3000, -11.1000],\n","        [ 16.7000,   4.4000]], dtype=torch.float64)\n","input:\n","tensor([[22.5000, 15.3000, 22.9000, 12.4000, 26.9000, 15.0000, 27.4000, 14.9000,\n","         23.2000, 13.1000, 18.5000, 12.1000, 23.9000, 12.0000],\n","        [18.4000, 10.6000, 20.9000, 11.7000, 21.0000, 11.3000, 17.7000,  8.9000,\n","         19.9000, 10.4000, 21.1000, 16.2000, 23.3000, 20.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.1000, 13.4000],\n","        [28.2000, 18.0000]], dtype=torch.float64)\n","input:\n","tensor([[ -7.5000, -13.3000,  -6.9000, -13.4000, -13.3000, -20.5000, -11.3000,\n","         -21.3000,  -6.4000, -11.4000,  -2.7000, -15.4000, -14.2000, -20.2000],\n","        [ 27.4000,  17.2000,  27.1000,  16.6000,  28.7000,  17.1000,  24.9000,\n","          18.7000,  25.8000,  17.9000,  20.5000,  14.2000,  18.2000,  13.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -7.4000, -18.4000],\n","        [ 24.1000,  13.3000]], dtype=torch.float64)\n","input:\n","tensor([[13.9000,  5.9000,  5.9000, -2.1000, -1.5000, -5.8000,  0.8000, -6.7000,\n","          2.5000, -3.6000,  3.1000, -2.5000,  0.2000, -9.7000],\n","        [ 9.6667,  6.1000, 10.2333,  5.6000, 10.8000,  5.1000, 15.8000,  7.6000,\n","         15.3000,  7.7000,  9.0000,  1.7000,  4.7000, -1.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.6000, -4.6000],\n","        [ 5.9000, -0.3000]], dtype=torch.float64)\n","input:\n","tensor([[24.6000, 14.4000, 23.0000, 17.4000, 22.7000, 15.7000, 19.6000, 12.8000,\n","         15.5000, 12.2000, 24.2000, 14.3000, 19.3000, 15.6000],\n","        [28.7000, 18.2000, 27.7000, 18.8000, 26.2000, 16.3000, 21.6000, 17.9000,\n","         23.9000, 17.8000, 30.8000, 17.6000, 21.4000, 12.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.1000, 14.8000],\n","        [21.3000, 10.7000]], dtype=torch.float64)\n","input:\n","tensor([[ -6.1000, -16.5000,  10.5000,  -6.1000,   6.1000,  -7.3000,  -7.1000,\n","         -12.6000,  -3.5000, -13.8000,   2.0000,  -3.7000,   7.1000,   0.8000],\n","        [ 12.8000,   4.0000,  15.9000,   6.1000,  22.5000,   6.9000,  12.2000,\n","           4.7000,  10.6000,   5.1000,  13.8000,   3.7000,   5.9000,  -0.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.3000, -1.3000],\n","        [ 8.2000,  3.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.5000,  2.9000,  7.8000, -1.2000,  4.4000, -0.9000,  3.8000,  1.2000,\n","          6.5000,  1.4000, 12.0000,  5.2000, 11.3000,  0.3000],\n","        [30.8000, 21.9000, 26.0000, 18.2000, 18.3000, 13.7000, 19.4000, 11.5000,\n","         19.2000, 15.2000, 21.1000, 16.7000, 26.1000, 16.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.1000, -0.3000],\n","        [23.3000, 16.3000]], dtype=torch.float64)\n","input:\n","tensor([[24.6000, 11.3000, 27.0000, 15.3000, 28.5000, 16.2000, 20.4000, 12.4000,\n","         19.7000, 10.9000, 20.3000,  9.2000, 24.0000, 13.4000],\n","        [ 7.1000, -1.2000,  8.3000, -0.1000,  5.0000, -3.0000,  0.8000, -5.1000,\n","          1.4000, -5.9000, 10.3000,  1.3000,  7.5000,  0.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.4000,  8.9000],\n","        [ 6.0000, -1.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 2.0000, -3.5000,  6.7000,  1.8000,  6.9000,  2.1000,  2.2000, -6.5000,\n","          2.7000, -6.3000,  6.0000,  1.8000,  4.4000,  2.1000],\n","        [17.0000,  4.0000, 20.6000,  7.8000, 17.5000,  6.1000, 14.6000,  6.3000,\n","         14.2000,  5.3000, 20.9000,  8.9000, 20.4000,  9.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.0000,  0.7000],\n","        [12.2000,  4.6000]], dtype=torch.float64)\n","input:\n","tensor([[27.9000, 12.6000, 26.8000, 15.9000, 27.3000, 16.1000, 34.2000, 20.1000,\n","         27.7000, 13.9000, 19.6000, 13.0000, 20.2000, 15.8000],\n","        [15.2000,  4.6000,  4.6000,  1.3000,  3.7500,  1.3000,  2.9000, -3.3000,\n","         -1.8000, -5.5000,  7.9000, -3.1000, 12.0000,  4.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.9000, 14.3000],\n","        [ 4.6000, -5.8000]], dtype=torch.float64)\n","input:\n","tensor([[22.0000, 13.9000, 20.8000, 12.6000, 22.0000, 13.8000, 21.6000, 18.4000,\n","         22.7000, 18.5000, 22.6000, 10.5000, 15.9000, 10.3000],\n","        [26.7000, 15.5000, 27.6000, 13.5000, 22.8000, 14.6000, 26.6000, 13.2000,\n","         28.9000, 15.1000, 29.7000, 16.0000, 30.7000, 19.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.8000,  7.8000],\n","        [32.2000, 20.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 26.0000,  15.3000,  24.0000,  14.5000,  18.9000,  11.5000,  17.8000,\n","          10.6000,  17.3000,  10.9000,  22.1000,  12.9000,  23.1000,  13.8000],\n","        [ -2.6000, -13.3000,  -2.7000,  -6.3000,  -2.1000,  -6.5000,  -1.8000,\n","          -6.8000,  -2.5000,  -9.7000,   0.2000,  -8.0000,   5.1000,  -0.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.5000, 14.9000],\n","        [ 7.0000,  1.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.0000, -2.4000,  0.9000, -4.3000,  5.3000, -1.2000,  7.7000,  3.1000,\n","         16.6000, -0.2000,  5.8000, -2.7000,  9.6000, -0.8000],\n","        [18.2000, 10.2000, 18.9000,  9.9000, 20.4000,  9.0000, 15.2000,  8.2000,\n","         14.2000,  6.3000, 23.7000, 11.2000, 24.7000, 10.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.5000,  2.5000],\n","        [15.2000,  9.4000]], dtype=torch.float64)\n","input:\n","tensor([[24.2000, 17.4000, 28.1000, 17.1000, 22.3000, 15.2000, 23.1000, 20.2000,\n","         22.3000, 19.8000, 20.8000, 18.6000, 22.8000, 17.7000],\n","        [ 8.5000,  1.5000,  9.3000,  4.5000, 12.8000,  4.0000, 15.9000,  6.1000,\n","         22.5000,  6.9000, 12.2000,  4.7000, 10.6000,  5.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.4000, 17.4000],\n","        [13.8000,  3.7000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.7000,  -9.3000,  -1.3000,  -5.2000,  -1.5000, -17.8000,  -7.7000,\n","         -21.5000,  -5.7000, -19.7000, -19.2000, -25.1000, -12.6000, -22.4000],\n","        [ 28.0000,  16.3000,  20.5000,  15.3000,  23.3000,  14.8000,  21.7000,\n","          13.9000,  24.1000,  14.0000,  21.7000,  16.9000,  22.0000,  16.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -7.5000, -13.3000],\n","        [ 23.1000,  17.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 10.5000,  -6.1000,   6.1000,  -7.3000,  -7.1000, -12.6000,  -3.5000,\n","         -13.8000,   2.0000,  -3.7000,   7.1000,   0.8000,   4.3000,  -1.3000],\n","        [ -9.7000, -16.3000,  -6.3000, -10.8000,  -7.3000, -10.8000,  -1.9000,\n","         -12.8000,  -3.5000,  -8.4000,   0.6000,  -5.5000,   1.1000,  -2.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.8000, -2.5000],\n","        [ 1.5000, -8.8000]], dtype=torch.float64)\n","input:\n","tensor([[10.3000,  5.4000,  8.3000,  2.6000,  4.0000, -1.3000,  1.4000, -2.7000,\n","          2.8000, -2.3000,  2.6000, -0.2000,  3.0000, -2.2000],\n","        [18.3000, 13.7000, 17.4000,  8.9000, 12.4000,  8.7000, 12.5000,  7.1000,\n","         12.2000,  5.6000, 14.2000,  9.5000, 16.3000,  9.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.8000,  0.1000],\n","        [20.6000,  9.1000]], dtype=torch.float64)\n","input:\n","tensor([[18.0000, 13.2000, 25.3000, 12.5000, 22.5000, 15.3000, 22.9000, 12.4000,\n","         26.9000, 15.0000, 27.4000, 14.9000, 23.2000, 13.1000],\n","        [16.6000, 10.8000, 20.4000, 11.2000, 25.2000, 14.1000, 24.5000, 13.2000,\n","         28.2000, 15.1000, 23.1000, 18.3000, 30.5000, 16.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.5000, 12.1000],\n","        [29.2000, 19.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.3500,  3.9000,  8.8000,  0.9000,  4.4000, -0.5000,  6.6000,  1.9000,\n","          5.0000, -0.1000, 10.6000, -1.1000,  8.8000,  2.9000],\n","        [22.8000, 14.6000, 26.6000, 13.2000, 28.9000, 15.1000, 29.7000, 16.0000,\n","         30.7000, 19.9000, 32.2000, 20.1000, 30.5000, 21.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.7000,  2.7000],\n","        [28.7000, 20.8000]], dtype=torch.float64)\n","input:\n","tensor([[28.9000, 19.8000, 26.8000, 21.3000, 29.5000, 20.5000, 25.2000, 20.7000,\n","         31.6000, 18.3000, 24.8000, 16.5000, 24.2000, 17.8000],\n","        [33.5000, 22.0000, 27.9000, 19.5000, 28.2000, 18.0000, 28.0000, 19.6000,\n","         26.9000, 20.0000, 27.5000, 19.9000, 28.2000, 18.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.1000, 18.0000],\n","        [29.1000, 19.4000]], dtype=torch.float64)\n","input:\n","tensor([[  0.4000,  -8.3000,   0.6000,  -7.1000,  -1.3000,  -8.1000,   0.3000,\n","          -3.2000,  -0.5000,  -2.6000,   0.8000,  -3.2000,   1.3000,  -2.5000],\n","        [-13.1000, -16.6000,  -9.6000, -15.3000,  -8.3000, -18.5000,  -3.6000,\n","          -9.5000,  -3.7000,  -9.9000,  -7.0000, -14.3000,   2.0000, -14.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.0000, -1.4000],\n","        [ 5.9000, -1.3000]], dtype=torch.float64)\n","input:\n","tensor([[  4.7000,   1.6000,   1.8000,   0.6000,   0.7000,  -2.9000,   1.5000,\n","          -2.9000,   2.3000, -10.1000,  -9.9000, -14.2000,  -3.7500, -13.1000],\n","        [  6.6000,   1.0000,  10.7000,   1.1000,  19.8000,  10.7000,  12.0000,\n","           2.8000,   9.5000,   2.0000,  17.9000,   7.0000,  19.4000,  12.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.4000, -4.5000],\n","        [14.4000,  7.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 24.2000,  16.4000,  19.3000,  14.9000,  21.3000,  12.7000,  22.4000,\n","          16.0000,  23.2000,  18.4000,  23.1000,  18.1000,  22.0000,  15.8000],\n","        [ -4.5000, -14.6000,   0.6000,  -6.2000,   3.2000,   0.6000,   1.9000,\n","          -9.9000,  -9.7000, -16.5000,  -9.3000, -14.7000,  -6.7000, -12.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 18.9000,  14.7000],\n","        [ -3.6000, -10.4000]], dtype=torch.float64)\n","input:\n","tensor([[27.2000, 16.4000, 32.4000, 19.0000, 30.2000, 20.2000, 23.7000, 18.4000,\n","         25.8000, 16.1000, 27.8000, 17.7000, 29.1000, 18.9000],\n","        [ 7.9000,  2.9000,  4.8000,  2.6000,  3.1000,  1.1000,  4.4000,  0.1000,\n","          0.5000, -2.3000,  0.8000, -4.3000,  3.7000,  0.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.5000, 18.4000],\n","        [ 3.5000, -3.5000]], dtype=torch.float64)\n","input:\n","tensor([[26.8000, 21.0000, 26.6000, 19.6000, 28.8000, 17.7000, 28.9000, 17.8000,\n","         32.0000, 19.6000, 25.6000, 17.6000, 24.1000, 16.5000],\n","        [21.7000, 13.4000, 24.2000, 17.6000, 26.1000, 18.0000, 24.9000, 17.9000,\n","         21.7000, 19.4000, 24.2000, 18.5000, 27.8000, 18.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.8000, 16.7000],\n","        [30.0000, 19.0000]], dtype=torch.float64)\n","input:\n","tensor([[-2.7000, -6.3000, -2.1000, -6.5000, -1.8000, -6.8000, -2.5000, -9.7000,\n","          0.2000, -8.0000,  5.1000, -0.1000,  7.0000,  1.6000],\n","        [25.9000, 19.4000, 23.6000, 16.8000, 24.2000, 15.9000, 25.8000, 14.9000,\n","         26.1000, 15.3000, 22.6000, 16.4000, 23.2000, 15.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.7000, -2.0000],\n","        [24.2000, 14.8000]], dtype=torch.float64)\n","input:\n","tensor([[14.4000,  7.1000, 12.1000,  4.3000, 16.1000,  7.3000, 12.4000,  6.3000,\n","         15.6000,  5.3000, 15.8000,  6.5000, 16.1500,  7.0000],\n","        [ 1.1000, -4.0000,  1.6000, -3.2000, 11.7000,  0.9000,  0.9000, -4.4000,\n","          1.1000, -6.0000,  4.2000, -2.4000,  1.0000, -5.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.5000,  1.9000],\n","        [-4.5000, -8.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 7.2000,  0.2000,  5.0000,  0.4000,  7.8000,  0.4000, 10.2000,  6.6000,\n","          9.1000,  1.3000,  3.7000,  0.7000,  2.2000, -0.2000],\n","        [25.1000, 13.7000, 26.7000, 16.2000, 26.4000, 16.7000, 27.4000, 16.9000,\n","         29.7000, 18.1000, 29.9000, 19.1000, 29.1000, 19.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.3000,  0.6000],\n","        [24.1000, 17.2000]], dtype=torch.float64)\n","input:\n","tensor([[19.8000,  9.8000, 19.3000,  9.6000, 16.5000, 11.7000, 17.6000,  8.8000,\n","         18.0000,  9.2000, 20.0000, 12.0000, 17.6000, 11.1000],\n","        [ 6.1000, -0.5000,  6.2000,  0.1000, 15.4000,  4.3000, 13.9000,  5.9000,\n","          5.9000, -2.1000, -1.5000, -5.8000,  0.8000, -6.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.4000,  9.3000],\n","        [ 2.5000, -3.6000]], dtype=torch.float64)\n","input:\n","tensor([[20.3000, 11.4000, 30.1000, 13.6000, 21.9000, 12.1000, 24.1000, 13.1000,\n","         27.2000, 16.4000, 32.4000, 19.0000, 30.2000, 20.2000],\n","        [12.2000,  6.6000, 14.5000,  6.0000, 15.2000,  7.0000, 16.9000,  9.3000,\n","         21.0000,  9.7000, 18.3000,  8.4000, 14.3000,  5.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.7000, 18.4000],\n","        [15.1000,  4.1000]], dtype=torch.float64)\n","input:\n","tensor([[13.0000,  7.2000, 18.3000,  6.9000, 13.3000,  2.8000,  7.0000,  0.5000,\n","          6.8000,  0.2000, 15.7000,  0.1000, 17.9000, 12.7000],\n","        [32.2000, 21.9000, 30.8000, 21.2000, 30.9000, 18.2000, 27.7000, 17.8000,\n","         28.1000, 17.0000, 27.3000, 15.8000, 25.9000, 16.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.3000,  8.6000],\n","        [23.8000, 15.2000]], dtype=torch.float64)\n","input:\n","tensor([[14.3000, 11.5000, 20.1000, 11.1000, 22.9000, 13.3000, 25.1000, 16.5000,\n","         29.6000, 17.3000, 27.1000, 13.8000, 20.8000, 10.4000],\n","        [ 8.4000,  0.0000,  4.6000, -1.0000,  6.3000, -1.5000, 13.8000,  2.5000,\n","         13.0000,  2.7000,  6.7000, -0.2000,  2.1000, -0.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.0000, 10.8000],\n","        [ 7.8000,  1.5000]], dtype=torch.float64)\n","input:\n","tensor([[14.5000,  5.9000, 13.6000,  5.3000, 14.1000,  7.3000, 12.8000,  7.4000,\n","         18.0000,  9.8000, 20.7000, 10.6000, 21.3000, 11.5000],\n","        [15.1000,  7.0000, 15.1000, 10.7000, 14.2000,  8.5000, 14.1000,  8.2000,\n","         19.6000, 10.3000, 14.7000, 10.3000, 16.7000, 10.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.5000,  9.2000],\n","        [20.1000, 10.2000]], dtype=torch.float64)\n","input:\n","tensor([[23.4000, 13.9000, 24.3000, 18.4000, 20.8000, 15.8000, 30.8000, 16.6000,\n","         21.7000, 15.3000, 17.4000, 10.9000, 16.7000, 10.5000],\n","        [ 8.0000,  4.6000,  5.5000,  3.0000,  6.8000,  2.1000,  2.9000,  1.0000,\n","          2.5000, -0.8000,  3.4000, -0.7000,  6.3000,  0.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.6000,  5.1000],\n","        [ 7.0000, -1.1000]], dtype=torch.float64)\n","input:\n","tensor([[23.3000, 16.3000, 25.6000, 16.2000, 27.5000, 18.4000, 27.1000, 13.4000,\n","         22.0000, 10.6000, 16.7000,  9.2000, 17.2000,  7.2000],\n","        [ 7.0000, -0.6000, 13.3000,  3.5000, 11.3000,  6.0000,  6.0000,  1.3000,\n","          2.6000, -6.8000,  1.4000, -7.1000,  6.4000, -2.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[17.8000,  9.9000],\n","        [-1.5000, -5.2000]], dtype=torch.float64)\n","input:\n","tensor([[28.1000, 19.3000, 25.3000, 16.0000, 22.1000, 12.6000, 22.6000, 14.8000,\n","         20.7000, 17.1000, 29.1000, 19.4000, 30.3000, 20.4000],\n","        [22.5000, 15.3000, 15.5000, 12.0000, 17.4000, 13.5000, 21.2000, 15.0000,\n","         19.0000, 11.9000, 16.4000,  7.9000, 12.3000,  6.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.4000, 18.1000],\n","        [11.5000,  5.4000]], dtype=torch.float64)\n","input:\n","tensor([[11.7000,  6.1000, 13.8000,  3.8000, 15.1000,  8.8000,  8.8000,  4.8000,\n","          9.1000,  2.7000,  9.4000,  2.3000, 10.6000,  3.1000],\n","        [24.2000, 17.5000, 26.0000, 16.8000, 25.4000, 16.7000, 25.5000, 16.5000,\n","         26.1000, 16.8000, 26.7000, 17.1000, 24.7250, 20.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.2000,  4.3000],\n","        [22.7500, 17.7333]], dtype=torch.float64)\n","input:\n","tensor([[  0.2000, -15.4000, -10.4000, -19.5000,  -3.5000, -11.6000,  -2.1000,\n","         -10.8000,  -3.7000,  -8.4000,   0.0000,  -3.8500,   5.5000,   0.7000],\n","        [ 13.0000,   8.2000,  18.3000,  11.4000,  19.7000,  13.1000,  21.1000,\n","          16.1000,  18.3000,  13.9000,  22.2000,  11.5000,  23.3000,  13.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.1000, -7.7000],\n","        [17.5000,  8.3000]], dtype=torch.float64)\n","input:\n","tensor([[-0.7000, -5.7000,  0.2000, -6.8000,  7.1000, -1.2000,  8.3000, -0.1000,\n","          5.0000, -3.0000,  0.8000, -5.1000,  1.4000, -5.9000],\n","        [11.3000,  4.7000,  6.1000, -0.1000,  5.2000, -0.4000, 13.1000,  4.3000,\n","         15.4000,  3.9000,  9.9000,  4.0000,  6.7000,  3.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.3000,  1.3000],\n","        [11.0000,  1.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.5000,  2.5000, 11.7000,  2.0000, 12.3000,  4.2000, 11.0000,  5.8000,\n","         16.0000,  6.5000, 19.2000,  6.6000, 10.3000,  3.3000],\n","        [ 5.3000,  0.7000,  7.3000,  1.7000,  6.1000,  1.5000,  5.8000,  1.1000,\n","          1.1000, -3.6000,  0.9000, -5.1000, 10.1000,  0.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.4000,  2.4000],\n","        [ 2.2000, -1.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.5000, -5.6000,  0.9000, -6.6000,  3.9000, -3.7000,  6.4000,  1.1000,\n","          5.9000,  0.0000,  4.0000, -2.4000,  0.9000, -4.3000],\n","        [22.8000, 10.1000, 18.5000,  8.2000, 20.3000,  8.9000, 18.0000, 13.4000,\n","         15.5000, 11.8000, 16.4000, 12.7000, 19.8000, 14.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.3000, -1.2000],\n","        [22.8000, 12.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -7.3000, -13.6000,  -3.8000, -15.3000,  -0.2000,  -4.2000,   3.8000,\n","          -0.9000,   8.3000,   3.0000,  13.1000,   8.0000,  13.9000,  10.1000],\n","        [ 25.4000,  17.9000,  23.3000,  15.4000,  21.9000,  13.7000,  17.2000,\n","          12.8000,  24.4000,  13.5000,  25.0000,  16.1000,  21.8000,  16.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.5000,  2.0000],\n","        [24.3000, 16.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.9000, -4.3000,  5.6000, -2.1000,  6.9000, -1.8000,  2.8000, -5.3000,\n","          3.1000, -1.2000,  8.1000,  2.0000, 10.1000,  4.4000],\n","        [16.3000,  9.5000, 20.6000,  9.1000, 24.0000,  9.1000, 17.6000,  8.7000,\n","         21.0000,  6.4000, 14.4000,  9.9000, 13.5000,  6.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.0000,  2.4000],\n","        [15.6000,  5.0000]], dtype=torch.float64)\n","input:\n","tensor([[18.7000,  8.5000, 11.1000,  3.2000, 10.0000,  1.1000, 11.0000,  0.4000,\n","         11.9000,  3.5000,  9.3000,  6.1000, 15.9000,  8.0000],\n","        [28.5000, 16.6000, 26.6000, 17.3000, 26.7000, 16.5000, 24.6000, 14.4000,\n","         23.0000, 17.4000, 22.7000, 15.7000, 19.6000, 12.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.6000,  6.2000],\n","        [15.5000, 12.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 12.8000,   4.1000,   9.6000,   2.8000,   9.6000,   2.5000,  19.3000,\n","           8.9000,  16.3000,   6.1000,  12.2000,   4.5000,  15.9000,   6.6000],\n","        [  2.7000,  -0.4000,   2.1000,  -5.9000,  -2.3000, -10.0000,   5.9000,\n","          -4.0000,  14.4000,   3.2000,  11.3000,  -6.3000,  -6.1000, -10.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 17.6000,   9.3000],\n","        [ -3.8000, -10.3000]], dtype=torch.float64)\n","input:\n","tensor([[15.0000,  8.8000, 16.0000,  7.5000, 20.8000,  9.2000, 22.1000, 12.0000,\n","         23.1000, 16.6000, 20.2000, 10.8000, 13.0000,  8.8000],\n","        [29.0000, 18.1000, 26.9000, 17.7000, 22.8000, 10.1000, 18.5000,  8.2000,\n","         20.3000,  8.9000, 18.0000, 13.4000, 15.5000, 11.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.4000,  8.4000],\n","        [16.4000, 12.7000]], dtype=torch.float64)\n","input:\n","tensor([[20.1000, 11.5000, 20.0000, 13.8000, 18.5000, 16.0000, 22.9000, 14.9000,\n","         19.4000,  9.9000, 12.2000,  7.1000,  9.0000,  4.0000],\n","        [25.9000, 19.2000, 27.3000, 18.1000, 28.6000, 15.5000, 27.1000, 17.1000,\n","         29.1000, 18.6000, 26.3000, 17.1000, 20.9000, 17.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.0000,  4.2000],\n","        [24.2000, 15.6000]], dtype=torch.float64)\n","input:\n","tensor([[ -7.1000, -12.7000,  -7.4000, -13.3000,  -3.0000, -10.7000,  -2.0000,\n","          -6.1000,  -2.3000,  -8.2000,  -2.3000,  -9.0000,  -2.5000, -13.4000],\n","        [  7.7000,   4.6000,  13.9000,   7.3000,   8.9000,   7.0000,   8.0000,\n","           4.6000,   5.5000,   3.0000,   6.8000,   2.1000,   2.9000,   1.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.5000, -2.5000],\n","        [ 2.5000, -0.8000]], dtype=torch.float64)\n","input:\n","tensor([[16.9000, 11.5000, 21.1000, 10.6000, 14.1000,  9.3000, 16.8000,  7.5000,\n","         14.6000,  6.7000, 22.6000, 11.6000, 21.5000, 14.8000],\n","        [24.4000, 15.9000, 23.8000, 16.8000, 20.5000, 15.7000, 20.7000, 15.6000,\n","         20.1000, 14.2000, 23.4000, 12.9000, 25.1000, 15.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.0000, 11.8000],\n","        [25.9000, 19.6000]], dtype=torch.float64)\n","input:\n","tensor([[-2.3000, -5.8000, -2.6000, -3.9000, -0.4000, -6.8000,  1.5000, -4.0000,\n","         -1.1000, -7.2000, -1.1000, -6.1000, -0.7000, -7.6000],\n","        [26.3000, 17.3000, 24.2000, 13.0000, 18.1000, 10.5000, 20.6000, 12.5000,\n","         22.4000, 12.0000, 24.0000, 13.8000, 22.0000, 16.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.3000, -2.0000],\n","        [20.7000, 14.6000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.6000,  -9.5000,  -3.7000,  -9.9000,  -7.0000, -14.3000,   2.0000,\n","         -14.0000,   5.9000,  -1.3000,   4.2000,  -3.1000,   4.8000,  -6.1000],\n","        [ 10.2000,   5.2000,  10.1000,   3.8000,  13.7000,   5.6000,  11.8000,\n","           1.4000,   4.3000,  -0.8000,   3.2000,  -0.7000,   3.7000,  -0.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -6.1000, -11.3000],\n","        [  3.6000,  -0.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 27.7000,  16.4000,  27.5000,  16.8000,  26.3000,  17.3000,  24.2000,\n","          13.0000,  18.1000,  10.5000,  20.6000,  12.5000,  22.4000,  12.0000],\n","        [ -2.8000, -10.0000,   0.7000,  -3.7000,   3.5000,  -0.7000,   1.8000,\n","           0.0000,   1.3000,  -0.6000,   2.2000,  -2.3000,   1.9000,  -6.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 24.0000,  13.8000],\n","        [ -6.5000, -14.1000]], dtype=torch.float64)\n","input:\n","tensor([[21.0000,  9.7000, 18.3000,  8.4000, 14.3000,  5.0000, 15.1000,  4.1000,\n","         15.8000,  7.2000, 17.6000,  8.7000, 21.2000, 10.8000],\n","        [14.7000,  6.5000,  6.5000, -2.2000,  1.9000, -4.3000,  5.6000, -2.1000,\n","          6.9000, -1.8000,  2.8000, -5.3000,  3.1000, -1.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.1000, 13.8000],\n","        [ 8.1000,  2.0000]], dtype=torch.float64)\n","input:\n","tensor([[26.8000, 18.2000, 31.7000, 19.2000, 32.3000, 21.7000, 28.5000, 21.4000,\n","         29.0000, 19.9000, 24.4000, 19.6000, 21.2000, 17.5000],\n","        [18.3000,  8.3000, 14.2000,  6.5000,  8.6000,  3.6000,  9.4000,  3.1000,\n","         10.6000,  3.0000, 14.8000,  8.7000, 14.0000,  4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.8000, 17.0000],\n","        [ 9.8000,  3.6000]], dtype=torch.float64)\n","input:\n","tensor([[14.2000,  6.5000,  8.6000,  3.6000,  9.4000,  3.1000, 10.6000,  3.0000,\n","         14.8000,  8.7000, 14.0000,  4.8000,  9.8000,  3.6000],\n","        [20.0000,  4.6000,  5.0000,  0.3000,  4.3000, -0.6000,  7.1000,  0.6000,\n","          6.2000,  3.7000, 13.1000,  2.1000, 11.4000,  2.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.1000,  1.6000],\n","        [12.3000,  4.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.6000,  2.8000,  9.6000,  2.5000, 19.3000,  8.9000, 16.3000,  6.1000,\n","         12.2000,  4.5000, 15.9000,  6.6000, 17.6000,  9.3000],\n","        [26.8000, 15.9000, 19.8000, 14.7000, 17.2000, 13.1000, 19.4000, 12.5000,\n","         20.1000, 11.7000, 21.6000, 13.8000, 24.2000, 13.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.1000,  8.6000],\n","        [20.8000, 11.4000]], dtype=torch.float64)\n","input:\n","tensor([[20.1000, 13.2000, 18.8000, 11.9000, 18.3000, 13.7000, 17.4000,  8.9000,\n","         12.4000,  8.7000, 12.5000,  7.1000, 12.2000,  5.6000],\n","        [30.0000, 16.7000, 32.6000, 20.5000, 31.1000, 22.2000, 31.2000, 22.1000,\n","         29.6000, 22.8000, 25.9000, 16.8000, 17.3000, 12.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.2000,  9.5000],\n","        [19.8000, 11.5000]], dtype=torch.float64)\n","input:\n","tensor([[  5.9000,  -1.3000,   4.2000,  -3.1000,   4.8000,  -6.1000,  -6.1000,\n","         -11.3000,  -2.3000, -11.7000,  -0.8000,  -5.8000,  -0.9000,  -3.5000],\n","        [ 29.1000,  19.4000,  30.3000,  20.4000,  28.4000,  18.1000,  26.7000,\n","          18.8000,  25.7000,  15.3000,  26.8000,  14.5000,  28.1000,  14.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.1000, -3.4000],\n","        [29.0000, 20.6000]], dtype=torch.float64)\n","input:\n","tensor([[-0.1000, -5.7000,  1.5000, -4.0000, -3.6000, -7.7000, -2.4000, -8.3000,\n","          1.8000, -7.5000,  5.0000,  0.1000,  4.9000,  1.7000],\n","        [25.9000, 17.4000, 23.9000, 16.6000, 25.4000, 17.1000, 28.6000, 17.3000,\n","         32.1000, 20.5000, 24.4000, 17.3000, 25.2000, 14.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.6000,  1.5000],\n","        [21.6000, 15.2000]], dtype=torch.float64)\n","input:\n","tensor([[29.3000, 18.5000, 30.3000, 19.2000, 28.3000, 17.7000, 26.3000, 15.9000,\n","         28.8000, 19.8000, 31.2000, 17.2000, 27.4000, 13.7000],\n","        [ 3.0000, -0.4000,  3.8000, -0.2000,  9.0000,  0.3000,  3.4000, -5.5000,\n","          2.1000, -6.1000,  5.7000, -3.0000,  1.1000, -3.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 22.4000,  11.8000],\n","        [ -3.8000, -12.3000]], dtype=torch.float64)\n","input:\n","tensor([[-12.1000, -20.5000, -12.2000, -17.4000,  -6.8000, -17.7000,  -2.8000,\n","         -13.8000,  -3.8000, -14.6000,  -3.7000, -16.0000, -11.6000, -18.6000],\n","        [ 21.1000,  13.4000,  18.9000,  11.2000,  20.4000,  13.7000,  21.0000,\n","          10.4000,  13.5000,   5.4000,  12.0000,   4.1000,  15.1000,   5.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -9.2000, -16.5000],\n","        [ 21.2000,   8.3000]], dtype=torch.float64)\n","input:\n","tensor([[10.6000,  2.5000,  6.8000,  1.8000, 10.6000,  2.8000,  3.4000, -1.6000,\n","         -0.2000, -2.3000,  6.2000, -2.0000,  8.4000,  5.4000],\n","        [23.8000, 17.1000, 22.8000, 17.2000, 23.6000, 18.0000, 24.8000, 18.4000,\n","         23.3000, 18.7000, 24.2000, 15.8000, 20.5000, 15.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.4000,  6.9000],\n","        [23.6000, 15.5000]], dtype=torch.float64)\n","input:\n","tensor([[  5.7000,  -2.1000,   3.9000,  -2.7000,   0.3000,  -9.1000,  -6.6000,\n","         -10.1000,  -2.6000, -13.3000,  -2.7000,  -6.3000,  -2.1000,  -6.5000],\n","        [ 23.1000,  16.6000,  20.2000,  10.8000,  13.0000,   8.8000,  16.4000,\n","           8.4000,  18.1000,   7.9000,  21.2000,   8.2000,  20.8000,  10.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-1.8000, -6.8000],\n","        [18.6000, 12.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 27.3000,  16.7000,  21.9000,  14.6000,  22.1000,  14.3000,  22.9000,\n","          14.8000,  22.4000,  16.2000,  25.3000,  17.1000,  27.7000,  17.8000],\n","        [ -0.1000,  -9.6000,   1.6000,  -5.7000,   0.1000,  -6.8000,   1.6000,\n","          -1.8000,  -1.7000,  -7.5000,  -4.9000, -10.4000,  -6.4000, -10.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 26.0000,  16.4000],\n","        [ -4.4000, -11.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.4000, -6.8000,  9.9000,  2.9000,  9.9000,  1.8000,  2.7000,  0.8000,\n","         15.6000,  2.3000,  4.5000, -0.3000,  2.2000, -2.0000],\n","        [24.7000, 15.3000, 22.9000, 14.3000, 22.6000, 13.5000, 13.8000,  9.1000,\n","         14.1000,  6.4000, 17.9000,  8.1000, 29.7000, 12.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.6000,  0.0000],\n","        [15.8000,  6.7000]], dtype=torch.float64)\n","input:\n","tensor([[12.2000,  1.8000, 10.6000,  4.8000, 10.4000,  4.5000, 11.9000,  2.9000,\n","         12.6000,  6.0000,  8.1000,  5.9000,  6.7000,  5.1000],\n","        [20.0000,  9.1000, 16.8000, 10.0000, 17.8500, 10.9000, 18.9000,  9.2000,\n","         12.3000,  4.4000, 10.4000,  2.8000, 11.2000,  2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.0000,  6.2000],\n","        [ 9.7000,  4.8000]], dtype=torch.float64)\n","input:\n","tensor([[21.1000, 16.2000, 23.3000, 20.4000, 28.2000, 18.0000, 22.5000, 15.3000,\n","         15.5000, 12.0000, 17.4000, 13.5000, 21.2000, 15.0000],\n","        [ 8.4000,  3.2000,  8.6000,  1.3000,  1.3000, -3.5000,  4.8000, -0.9000,\n","          5.7000,  3.2000,  5.7000,  2.1000,  5.9000,  2.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.0000, 11.9000],\n","        [ 5.1000, -6.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 27.7000,  17.8000,  26.0000,  16.4000,  27.4000,  17.2000,  27.1000,\n","          16.6000,  28.7000,  17.1000,  24.9000,  18.7000,  25.8000,  17.9000],\n","        [  1.3000,  -6.1000,   4.3000,   0.8000,   4.8000,   1.1000,   2.3000,\n","          -1.0000,  -0.9000, -11.5000,  -4.5000, -14.6000,   0.6000,  -6.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.5000, 14.2000],\n","        [ 3.2000,  0.6000]], dtype=torch.float64)\n","input:\n","tensor([[ -9.1000, -15.4000,  -4.6000, -15.8000,  -0.7000,  -4.8000,  -1.5000,\n","         -11.1000,  -4.7000, -13.3000,  -5.3000, -10.3000,  -2.9000,  -9.4000],\n","        [ 24.2000,  14.3000,  19.3000,  15.6000,  24.1000,  14.8000,  21.1000,\n","          14.0000,  22.8000,  11.4000,  24.0000,  13.3000,  26.7000,  15.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-1.3000, -6.4000],\n","        [26.4000, 17.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 3.8000,  0.6000,  4.3000,  0.3000,  1.5000, -0.4000,  6.7000,  0.5000,\n","          5.7000, -2.9000, -1.7000, -5.4000, -0.1000, -5.1000],\n","        [23.8000, 15.2000, 25.5000, 19.3000, 21.8000, 17.8000, 26.1000, 18.1000,\n","         23.4000, 18.5000, 22.0000, 17.1000, 24.0000, 17.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -1.2000, -10.6000],\n","        [ 25.1000,  16.1000]], dtype=torch.float64)\n","input:\n","tensor([[32.5000, 18.5000, 33.2000, 21.1000, 24.0000, 16.4000, 26.7000, 15.5000,\n","         27.6000, 13.5000, 22.8000, 14.6000, 26.6000, 13.2000],\n","        [24.1000, 18.1000, 22.1000, 17.5000, 24.5500, 18.5000, 27.0000, 20.4000,\n","         25.0000, 20.4000, 28.9000, 19.8000, 26.8000, 21.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.9000, 15.1000],\n","        [29.5000, 20.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 36.0000,  21.7000,  27.8000,  21.2000,  28.0000,  18.6000,  27.1000,\n","          17.3000,  28.0000,  18.4000,  28.9000,  18.8000,  31.3000,  18.2000],\n","        [ -3.9000,  -7.0000,  -4.4000, -10.0000,  -0.9000, -10.7000,   0.7000,\n","          -3.9000,  -0.2000,  -3.1000,   5.7000,  -3.5000,   9.9000,   5.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[32.0000, 21.3000],\n","        [10.7000,  1.1000]], dtype=torch.float64)\n","input:\n","tensor([[20.0000, 12.9000, 21.4000, 12.7000, 22.1000, 12.5000, 18.9000,  9.9000,\n","         16.7000, 10.9000, 22.0000, 11.6000, 18.7000,  8.5000],\n","        [22.8000, 16.3000, 23.9000, 15.4000, 25.5000, 15.3000, 23.8000, 16.3000,\n","         20.3000, 13.8000, 19.9000, 15.3000, 22.8000, 15.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.1000,  3.2000],\n","        [19.5000, 12.0000]], dtype=torch.float64)\n","input:\n","tensor([[ -0.2000,  -2.1000,  -0.3000,  -5.3000,  -5.3000, -11.1000,  -2.1000,\n","         -10.3000,   1.8000,  -2.5000,   1.4000,  -4.8000,  -4.7000, -11.2000],\n","        [  1.0000,  -2.4000,  -0.2000,  -6.5000,  -0.7000,  -6.4000,   0.6000,\n","          -4.7000,   3.3000,  -0.7000,  -0.1000,  -5.2000,  -4.1000,  -9.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -2.9000,  -9.6000],\n","        [ -6.7000, -11.7000]], dtype=torch.float64)\n","input:\n","tensor([[  2.7000,  -6.3000,   6.0000,   1.8000,   4.4000,   2.1000,   5.0000,\n","           0.7000,   2.0000, -10.2000,   0.7000, -10.3000,   1.5000,  -2.3000],\n","        [-12.6000, -22.4000,  -7.5000, -13.3000,  -6.9000, -13.4000, -13.3000,\n","         -20.5000, -11.3000, -21.3000,  -6.4000, -11.4000,  -2.7000, -15.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  4.4000,   1.5000],\n","        [-14.2000, -20.2000]], dtype=torch.float64)\n","input:\n","tensor([[  0.9000,  -6.1000,  -2.4000,  -9.7000,  -3.9000, -10.5000,  -5.2000,\n","         -11.7000,  -6.5000, -13.2000,  -8.5000, -13.9000,  -8.6000, -14.2000],\n","        [ 26.1000,  18.0000,  24.9000,  17.9000,  21.7000,  19.4000,  24.2000,\n","          18.5000,  27.8000,  18.0000,  30.0000,  19.0000,  24.9000,  14.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -7.2000, -12.1000],\n","        [ 22.9000,  13.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.0000, -0.6000,  7.6000, -0.4000,  0.7000, -5.0000,  6.0000, -4.1000,\n","         11.8000,  5.9000,  8.9000,  4.7000, 15.4000,  6.6000],\n","        [ 8.3000,  2.0000,  7.7000,  1.3000,  7.1000,  0.3500,  6.5000, -0.6000,\n","          1.4000, -2.3000,  2.8000, -2.0000,  2.4000, -1.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.6000, -3.0000],\n","        [ 1.7000, -0.8000]], dtype=torch.float64)\n","input:\n","tensor([[24.0000, 13.8000, 22.0000, 16.5000, 20.7000, 14.6000, 19.1000, 12.2000,\n","         21.4000, 15.0000, 21.5000, 18.1000, 21.3000, 13.6000],\n","        [12.3000,  4.1000,  9.2000,  1.7000, 12.7000,  1.4000, 15.8000,  3.8000,\n","         14.5000,  5.3000, 13.9000,  3.7000,  9.2000,  3.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.8000,  9.0000],\n","        [11.5000,  3.2000]], dtype=torch.float64)\n","input:\n","tensor([[26.9000, 17.4000, 27.4000, 17.6000, 31.5000, 19.2000, 33.8000, 21.4000,\n","         34.5000, 24.3000, 28.4000, 22.7000, 34.2000, 21.0000],\n","        [ 4.4000,  1.0000, 16.9000,  3.3000, 16.6000,  8.2000,  8.8000,  3.1000,\n","          7.4000,  0.6000, 12.1000,  2.7000,  6.8000,  2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[38.2000, 24.9000],\n","        [ 9.0000,  4.6000]], dtype=torch.float64)\n","input:\n","tensor([[21.7000, 10.1000, 24.4000, 11.3000, 21.5000, 12.8000, 16.2000, 10.4000,\n","         21.1000, 10.0000, 23.1000, 12.1000, 24.9000, 13.3000],\n","        [-0.1000, -6.8000,  3.1000, -1.9000,  1.6000, -6.2000, -1.4000, -6.6000,\n","          3.6000, -2.6000,  3.5000, -3.3000,  2.3000, -5.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.9000, 14.4000],\n","        [ 2.9000, -8.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 10.9000,   2.1000,   2.1000,  -0.8000,   4.0000,  -0.2000,   3.0000,\n","          -0.4000,   3.8000,  -0.2000,   9.0000,   0.3000,   3.4000,  -5.5000],\n","        [  2.9000,  -4.9000,   2.8000,  -6.2000,   1.4000,  -9.2000,   6.9000,\n","           1.2000,  10.6000,   3.9000,   4.9000, -14.0000,  -6.1000, -16.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.1000, -6.1000],\n","        [10.5000, -6.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 15.7000,   8.6000,  20.9000,  10.7000,  21.7000,  10.1000,  24.4000,\n","          11.3000,  21.5000,  12.8000,  16.2000,  10.4000,  21.1000,  10.0000],\n","        [  5.3000,   1.3000,   2.4000,  -3.5000,  -0.4000,  -3.6000,   2.3000,\n","          -1.2000,  -0.8000,  -6.9000,  -1.9000,  -7.2000,  -1.8000, -16.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 23.1000,  12.1000],\n","        [-14.2000, -19.8000]], dtype=torch.float64)\n","input:\n","tensor([[21.6000, 15.2000, 25.5000, 14.4000, 30.4000, 17.1000, 20.7000, 16.7000,\n","         21.9000, 16.9000, 31.0000, 17.0000, 30.1000, 22.3000],\n","        [18.3000, 13.8000, 19.6000, 16.0000, 20.2000, 14.8000, 22.8000, 16.7000,\n","         22.4000, 15.5000, 19.6000,  9.0000, 13.4000,  6.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.5000, 19.2000],\n","        [12.6000,  3.9000]], dtype=torch.float64)\n","input:\n","tensor([[ -2.7000,  -6.9000,   1.5000,  -4.1000,  -1.2000,  -5.2000,  -4.9000,\n","         -10.3000,  -3.0000,  -9.5000,   1.3000,  -6.1000,   4.3000,   0.8000],\n","        [ 17.8000,   9.5000,  16.7000,   8.6000,  15.6000,  11.1000,  20.1000,\n","          13.2000,  18.8000,  11.9000,  18.3000,  13.7000,  17.4000,   8.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.8000,  1.1000],\n","        [12.4000,  8.7000]], dtype=torch.float64)\n","input:\n","tensor([[18.7000, 13.5000, 20.8000, 12.3000, 18.1000,  9.9000, 15.2000,  7.3000,\n","         15.7000,  6.0000, 20.2000, 11.3000, 18.4000,  9.8000],\n","        [24.8000, 14.6000, 24.2000, 15.2000, 19.3000, 16.0000, 16.6000, 14.9000,\n","         18.4000, 15.2000, 22.2000, 15.0000, 15.2000,  5.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.6000,  8.4000],\n","        [13.9000,  4.6000]], dtype=torch.float64)\n","input:\n","tensor([[14.1000,  9.3000, 16.8000,  7.5000, 14.6000,  6.7000, 22.6000, 11.6000,\n","         21.5000, 14.8000, 18.0000, 11.8000, 13.0000,  7.2000],\n","        [ 6.4000,  1.0000,  7.0000, -0.6000, 13.3000,  3.5000, 11.3000,  6.0000,\n","          6.0000,  1.3000,  2.6000, -6.8000,  1.4000, -7.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.3000,  6.9000],\n","        [ 6.4000, -2.1000]], dtype=torch.float64)\n","input:\n","tensor([[ -5.3000,  -8.8000,  -0.8000,  -8.2000,  -6.1000,  -8.9000,  -0.9000,\n","          -7.4000,   5.7000,  -2.1000,   3.9000,  -2.7000,   0.3000,  -9.1000],\n","        [  2.7000,  -4.1000,   1.4000,  -7.0000,  -7.0000, -14.7000,  -9.3000,\n","         -16.7000,   1.6000, -10.7000,   1.1000,  -4.0000,   1.6000,  -3.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -6.6000, -10.1000],\n","        [ 11.7000,   0.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 24.7250,  20.0000,  22.7500,  17.7333,  20.7750,  15.4667,  18.8000,\n","          13.2000,  23.4000,  13.2000,  20.4000,  13.6000,  22.7000,  14.5000],\n","        [ -2.4000,  -9.7000,  -3.9000, -10.5000,  -5.2000, -11.7000,  -6.5000,\n","         -13.2000,  -8.5000, -13.9000,  -8.6000, -14.2000,  -7.2000, -12.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 20.5000,  14.1000],\n","        [ -5.7000, -12.0000]], dtype=torch.float64)\n","input:\n","tensor([[10.7000,  1.1000, 19.8000, 10.7000, 12.0000,  2.8000,  9.5000,  2.0000,\n","         17.9000,  7.0000, 19.4000, 12.5000, 14.4000,  7.1000],\n","        [14.1000,  8.2000, 19.6000, 10.3000, 14.7000, 10.3000, 16.7000, 10.3000,\n","         20.1000, 10.2000, 16.9000, 10.5000, 16.1000,  6.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.1000,  4.3000],\n","        [16.9000,  9.7000]], dtype=torch.float64)\n","input:\n","tensor([[-6.2000, -8.4000, -1.7000, -6.6000,  1.3000, -2.7000,  1.5000, -2.1000,\n","         -1.9000, -4.1000,  2.5000, -2.3000,  3.0000, -1.6000],\n","        [27.8000, 20.6000, 23.6000, 19.0000, 25.5000, 16.9000, 25.9000, 14.3000,\n","         27.8000, 15.9000, 26.7000, 19.1000, 25.1000, 20.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.0000, -3.2000],\n","        [26.4000, 19.6000]], dtype=torch.float64)\n","input:\n","tensor([[17.1000,  8.7000, 14.8000,  7.8000, 14.0000,  8.3000, 16.9000,  7.1000,\n","         11.9000,  8.2000, 13.5000,  7.3000,  9.7000,  2.3000],\n","        [16.0000,  7.5000, 20.8000,  9.2000, 22.1000, 12.0000, 23.1000, 16.6000,\n","         20.2000, 10.8000, 13.0000,  8.8000, 16.4000,  8.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.0000,  1.5000],\n","        [18.1000,  7.9000]], dtype=torch.float64)\n","input:\n","tensor([[11.2000,  2.3000,  9.7000,  4.8000, 12.1000,  7.4000, 12.3000,  7.5000,\n","         10.3000,  2.3000,  6.5000,  1.6000, 15.2000,  4.6000],\n","        [22.2000, 14.8000, 25.8000, 13.2000, 28.5000, 15.0000, 25.1000, 18.8000,\n","         25.1000, 19.6000, 28.7000, 19.0000, 30.8000, 21.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.6000,  5.3000],\n","        [26.0000, 18.2000]], dtype=torch.float64)\n","input:\n","tensor([[23.8000, 16.7000, 25.3000, 19.1000, 27.2000, 19.1000, 30.5000, 21.3000,\n","         31.6000, 22.0000, 31.7000, 20.2000, 24.4000, 14.9000],\n","        [21.2000,  8.3000, 19.4000, 12.7000, 20.0000, 11.6000, 21.7000, 10.9000,\n","         17.5000, 10.7000, 23.5000, 11.1000, 25.3000, 12.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.3000, 13.0000],\n","        [30.1000, 16.2000]], dtype=torch.float64)\n","input:\n","tensor([[13.5000,  8.5000, 13.0000,  8.2000, 18.3000, 11.4000, 19.7000, 13.1000,\n","         21.1000, 16.1000, 18.3000, 13.9000, 22.2000, 11.5000],\n","        [-0.7000, -9.3000,  3.8000, -1.4000,  7.1000,  1.3000, 13.4000,  6.9000,\n","          8.1000, -5.6000, -5.5000, -9.1000, -4.6000, -9.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.3000, 13.4000],\n","        [-3.5000, -9.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 14.0000,   7.9000,  17.9000,   6.6000,  19.8000,   9.6000,  20.5000,\n","          12.0000,  25.5000,  14.7000,  24.4000,  17.3000,  27.2000,  16.3000],\n","        [ -0.1000, -10.4000,  -9.0000, -16.2000,  -3.4000, -14.4000, -14.3000,\n","         -24.7000,  -9.6000, -22.4000,   0.0000,  -9.6000,   0.5000,  -0.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.5000, 15.3000],\n","        [ 0.0000, -9.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 28.7000,  16.4000,  30.9000,  16.9000,  28.0000,  19.5000,  34.7000,\n","          21.2000,  30.0000,  22.2000,  26.1000,  16.5000,  27.7000,  14.1000],\n","        [-11.3000, -20.9000,  -4.8000, -12.8000,  -2.4000,  -9.0000,   0.5000,\n","          -5.8000,   7.0000,  -0.8000,   6.1000,  -0.5000,   6.2000,   0.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.5000, 15.1000],\n","        [15.4000,  4.3000]], dtype=torch.float64)\n","input:\n","tensor([[24.1000, 17.0000, 27.9000, 18.4000, 23.7000, 19.3000, 27.0000, 18.8000,\n","         27.1000, 17.6000, 28.8000, 20.4000, 29.8000, 20.9000],\n","        [12.3000,  6.5000, 11.1000,  4.7000, 15.5000,  6.9000, 10.4000,  2.3000,\n","          3.7000, -0.1000,  3.9000, -0.6000,  4.3000, -2.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.5000, 21.4000],\n","        [ 6.0000,  0.2000]], dtype=torch.float64)\n","input:\n","tensor([[23.0000, 17.4000, 22.7000, 15.7000, 19.6000, 12.8000, 15.5000, 12.2000,\n","         24.2000, 14.3000, 19.3000, 15.6000, 24.1000, 14.8000],\n","        [ 7.1000,  3.7000,  4.4000,  1.0000, 16.9000,  3.3000, 16.6000,  8.2000,\n","          8.8000,  3.1000,  7.4000,  0.6000, 12.1000,  2.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.1000, 14.0000],\n","        [ 6.8000,  2.3000]], dtype=torch.float64)\n","input:\n","tensor([[11.3000,  6.2000, 13.1000,  2.7000, 10.7000,  1.9000, 12.3000,  2.7000,\n","         17.7000,  6.3000, 19.3000,  9.1000, 12.3000,  8.7000],\n","        [23.5000,  4.9000, 12.0000,  4.5000, 14.9000,  4.9000, 17.7000,  6.5000,\n","         20.5000,  7.1000, 15.9000, 10.0000, 27.3000, 15.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.6000, 11.6000],\n","        [28.9000, 19.0000]], dtype=torch.float64)\n","input:\n","tensor([[16.7000, 10.3000, 20.1000, 10.2000, 16.9000, 10.5000, 16.1000,  6.9000,\n","         16.9000,  9.7000, 20.3000,  9.9000, 12.2000,  5.0000],\n","        [30.9000, 19.9000, 28.2000, 19.7000, 30.8000, 18.2000, 26.8000, 21.0000,\n","         26.6000, 19.6000, 28.8000, 17.7000, 28.9000, 17.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.8000,  4.9000],\n","        [32.0000, 19.6000]], dtype=torch.float64)\n","input:\n","tensor([[24.2000, 15.8000, 20.5000, 15.0000, 23.6000, 15.5000, 25.0000, 14.9000,\n","         26.2000, 13.1000, 24.0000, 12.1000, 18.4000, 10.6000],\n","        [14.4000,  3.1000, 10.6000,  2.8000,  9.2000,  0.9000,  8.6000, -0.3000,\n","         14.8000,  0.2000,  9.0000,  5.4000, 14.5000,  6.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.9000, 11.7000],\n","        [14.5000,  7.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 5.9000, -0.1000,  8.2000,  3.5000,  7.2000,  1.6000,  3.3000,  1.4000,\n","          5.6000,  0.3000,  7.7000,  3.2000,  8.3000,  2.4000],\n","        [ 3.9000,  1.2000,  5.8000,  1.7000,  7.8000,  2.9000,  6.7000,  1.7000,\n","          8.1000,  1.9000, 12.3000,  6.5000, 11.1000,  4.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.9000,  3.0000],\n","        [15.5000,  6.9000]], dtype=torch.float64)\n","input:\n","tensor([[17.9000,  6.6000, 19.8000,  9.6000, 20.5000, 12.0000, 25.5000, 14.7000,\n","         24.4000, 17.3000, 27.2000, 16.3000, 25.5000, 15.3000],\n","        [ 2.3000, -0.5000,  3.8000, -3.0000,  3.5000, -0.2000,  9.0000,  2.4000,\n","          7.9000,  2.9000,  7.0000,  3.2000,  6.4000,  4.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.5000, 12.2000],\n","        [ 7.3000,  1.9000]], dtype=torch.float64)\n","input:\n","tensor([[30.0000, 18.4000, 25.1000, 17.1000, 22.7000, 15.4000, 19.3000,  7.4000,\n","         17.3000,  8.1000, 20.3000, 11.4000, 30.1000, 13.6000],\n","        [25.4000, 15.9000, 25.8000, 15.7000, 23.7000, 16.1000, 28.0000, 11.9000,\n","         11.9000,  7.4000, 15.0000,  9.5000, 18.1000, 10.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.9000, 12.1000],\n","        [17.9000, 10.3000]], dtype=torch.float64)\n","input:\n","tensor([[27.5000, 19.3000, 27.6000, 16.6000, 28.3000, 17.6000, 26.4000, 17.7000,\n","         25.8000, 20.9000, 27.9000, 19.8000, 28.4000, 18.2000],\n","        [23.2000, 15.3000, 22.7000, 19.0000, 22.7000, 15.8000, 21.8000, 14.6000,\n","         23.7000, 14.5000, 25.1000, 15.7000, 26.8000, 16.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.6000, 19.6000],\n","        [25.9000, 15.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 11.7000,   6.8000,  11.1000,   8.8000,  20.9000,   8.3000,  17.1000,\n","           8.2000,  10.4000,   6.1000,  13.8000,   5.2000,  12.9000,   8.7000],\n","        [ -1.7000,  -5.4000,  -0.1000,  -5.1000,  -1.2000, -10.6000,  -1.6000,\n","         -10.1000,   5.0000,  -2.4000,   4.2000,  -6.7000,  -0.9000,  -6.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 14.0000,   7.9000],\n","        [ -0.6000, -10.1000]], dtype=torch.float64)\n","input:\n","tensor([[17.5000, 13.9000, 20.8000, 12.1000, 20.0000, 10.9000, 21.8000, 14.1000,\n","         24.0000, 16.1000, 20.0000, 16.7000, 23.2000, 14.9000],\n","        [ 0.9000, -4.7000,  0.8000, -2.9000,  2.3000, -4.5000, 12.3000,  1.8000,\n","         11.6000,  5.4000, 18.6000,  6.7000, 15.2000,  3.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.1000, 13.6000],\n","        [ 8.6000,  2.4000]], dtype=torch.float64)\n","input:\n","tensor([[  4.2000,  -6.7000,  -0.9000,  -6.3000,  -0.6000, -10.1000,   2.5000,\n","         -10.4000,   8.1000,   2.0000,  10.0000,  -6.0000,  -1.9000,  -6.4000],\n","        [ 18.1000,   3.9000,   4.3000,   2.3000,   7.1000,   2.3000,   6.1000,\n","           2.8000,   9.7000,   1.4000,   9.8000,   3.4000,   9.8000,   4.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.4000, -3.2000],\n","        [ 9.2000,  4.1000]], dtype=torch.float64)\n","input:\n","tensor([[ -6.6000, -10.1000,  -2.6000, -13.3000,  -2.7000,  -6.3000,  -2.1000,\n","          -6.5000,  -1.8000,  -6.8000,  -2.5000,  -9.7000,   0.2000,  -8.0000],\n","        [ 24.9000,  11.6000,  17.3000,   7.7000,  16.3000,   5.9000,  19.6000,\n","           9.5000,  27.0000,  11.5000,  26.4000,  14.5000,  25.7000,  16.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 5.1000, -0.1000],\n","        [24.6000, 15.1000]], dtype=torch.float64)\n","input:\n","tensor([[25.1000, 17.1000, 23.5000, 14.3000, 23.6000, 13.1000, 16.4000, 11.4000,\n","         15.7000, 10.4000, 23.7000,  9.4000, 26.8000, 13.5000],\n","        [ 1.2000, -4.1000,  2.2000, -3.0000,  5.0000, -1.9000,  5.3000, -1.5000,\n","          5.0000, -0.2000,  0.8000, -1.5000,  2.3000, -1.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.7000, 16.4000],\n","        [ 5.9000, -1.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.8000,  1.8000, 10.6000,  2.8000,  3.4000, -1.6000, -0.2000, -2.3000,\n","          6.2000, -2.0000,  8.4000,  5.4000, 13.4000,  6.9000],\n","        [13.3000,  3.5000, 11.3000,  6.0000,  6.0000,  1.3000,  2.6000, -6.8000,\n","          1.4000, -7.1000,  6.4000, -2.1000, -1.5000, -5.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.9000,  6.7000],\n","        [-0.4000, -5.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 5.8000, -0.7000,  4.7000, -1.8000,  5.0000, -2.7000,  8.8000, -1.5000,\n","         12.0000,  0.7000, 15.5000,  1.7000, 12.8000,  2.7000],\n","        [26.1000, 16.2000, 23.3000, 16.3000, 25.6000, 16.2000, 27.5000, 18.4000,\n","         27.1000, 13.4000, 22.0000, 10.6000, 16.7000,  9.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.9000,  2.3000],\n","        [17.2000,  7.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.4000,  0.2000,  7.4000,  1.7000,  6.9000,  4.0000,  9.4000,  5.0000,\n","          9.4000,  6.5000, 14.0000,  6.9000, 20.2000,  7.8000],\n","        [21.1000, 10.0000, 23.1000, 12.1000, 24.9000, 13.3000, 26.9000, 14.4000,\n","         25.4000, 15.4000, 18.1000, 12.5000, 17.1000,  7.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.5000,  9.2000],\n","        [14.2000,  6.7000]], dtype=torch.float64)\n","input:\n","tensor([[12.2000,  3.5000, 12.1000,  2.9000, 11.5000,  5.2000, 11.3000,  4.6000,\n","         10.7000,  5.8000, 11.4000,  5.3000,  7.4000,  1.4000],\n","        [22.7000, 11.7000, 25.6000, 14.0000, 19.0000, 16.5000, 26.1000, 15.9000,\n","         28.7000, 16.4000, 30.9000, 16.9000, 28.0000, 19.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.5000,  0.1000],\n","        [34.7000, 21.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.8000,  3.5000,  7.5000,  2.5000,  7.0000,  2.6000,  8.1000,  2.6000,\n","          5.9000,  2.1000,  7.4000,  1.7000, 10.3000,  5.4000],\n","        [26.2000, 13.6000, 29.9000, 17.4000, 22.5000, 14.1000, 17.5000, 13.9000,\n","         20.8000, 12.1000, 20.0000, 10.9000, 21.8000, 14.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.3000,  2.6000],\n","        [24.0000, 16.1000]], dtype=torch.float64)\n","input:\n","tensor([[16.3000,  7.6000, 20.6000,  8.9000, 23.3000,  9.8000, 15.4000,  7.2000,\n","         14.5000,  6.6000, 14.9000,  8.4000, 19.5000,  7.0000],\n","        [ 2.7000,  0.8000, 15.6000,  2.3000,  4.5000, -0.3000,  2.2000, -2.0000,\n","          4.6000,  0.0000,  6.0000, -0.5000,  4.4000, -1.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.0500,  3.3000],\n","        [ 2.2000, -2.0000]], dtype=torch.float64)\n","input:\n","tensor([[-1.5000, -7.3000,  2.6000, -4.6000,  8.2000,  1.8000,  3.0000, -0.8000,\n","          0.0000, -1.1000,  2.9000, -1.0000,  4.6000,  0.6000],\n","        [12.1000,  4.3000, 16.1000,  7.3000, 12.4000,  6.3000, 15.6000,  5.3000,\n","         15.8000,  6.5000, 16.1500,  7.0000, 16.5000,  1.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.1000, -1.8000],\n","        [13.0000,  0.6000]], dtype=torch.float64)\n","input:\n","tensor([[ -8.3000, -18.5000,  -3.6000,  -9.5000,  -3.7000,  -9.9000,  -7.0000,\n","         -14.3000,   2.0000, -14.0000,   5.9000,  -1.3000,   4.2000,  -3.1000],\n","        [ 24.0000,  13.4000,  20.4000,   8.9000,  16.4000,   7.8000,  18.7000,\n","          13.5000,  20.8000,  12.3000,  18.1000,   9.9000,  15.2000,   7.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.8000, -6.1000],\n","        [15.7000,  6.0000]], dtype=torch.float64)\n","input:\n","tensor([[11.1000,  3.9000, 14.3000,  5.0000, 19.7000,  5.7000, 19.5000, 12.2000,\n","         22.2000, 13.0000, 24.2000, 14.6000, 25.4000, 15.0000],\n","        [19.3000, 14.3000, 18.1000, 13.3000, 23.5000, 13.7000, 17.0000, 14.9000,\n","         27.5000, 15.8000, 25.5000, 18.9000, 26.5000, 18.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.9000, 14.4000],\n","        [30.6000, 19.1000]], dtype=torch.float64)\n","input:\n","tensor([[10.5000,  0.8000, 14.6000,  3.2000,  6.7000,  1.8000,  6.9000,  1.4000,\n","          8.5000,  1.5000,  9.3000,  4.5000, 12.8000,  4.0000],\n","        [18.1000,  9.9000, 15.2000,  7.3000, 15.7000,  6.0000, 20.2000, 11.3000,\n","         18.4000,  9.8000, 16.6000,  8.4000, 18.1000, 10.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.9000,  6.1000],\n","        [18.4000, 10.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.3000, -6.8000,  0.9000, -7.9000, -0.4000, -8.8000, -0.3000, -7.5000,\n","          4.2000, -6.4000,  7.7000, -3.7000,  7.1000, -1.8000],\n","        [15.5000, 10.6000, 17.2000,  6.3000, 19.3000, 10.8000, 15.0000,  8.8000,\n","         16.0000,  7.5000, 20.8000,  9.2000, 22.1000, 12.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.8000,  1.5000],\n","        [23.1000, 16.6000]], dtype=torch.float64)\n","input:\n","tensor([[26.2000, 19.2000, 31.1000, 20.2000, 26.7000, 19.2000, 26.5000, 18.6000,\n","         28.2000, 19.4000, 29.0000, 19.3000, 30.0000, 20.5000],\n","        [ 0.2000, -3.1000,  3.9000, -2.2000,  6.1000, -0.9000, -0.6000, -5.8000,\n","          4.8000, -1.1000,  5.3000,  1.1000,  1.3000, -4.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.7000, 21.0000],\n","        [-2.4000, -5.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -4.7000, -10.4000,  -1.9000,  -6.5000,  -2.7000,  -6.9000,   1.5000,\n","          -4.1000,  -1.2000,  -5.2000,  -4.9000, -10.3000,  -3.0000,  -9.5000],\n","        [ 15.1000,  11.9000,  16.8000,   9.7000,  21.0000,  12.0000,  19.8000,\n","          11.1000,  18.7000,   9.1000,  24.7000,  11.5000,  22.7000,  13.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.3000, -6.1000],\n","        [18.9000, 12.3000]], dtype=torch.float64)\n","input:\n","tensor([[29.9000, 16.8000, 29.9000, 21.5000, 21.9000, 19.1000, 24.1000, 18.2000,\n","         21.2000, 17.5000, 25.6000, 16.7000, 27.5000, 19.2000],\n","        [23.3000, 13.6000, 23.2000, 15.3000, 22.7000, 19.0000, 22.7000, 15.8000,\n","         21.8000, 14.6000, 23.7000, 14.5000, 25.1000, 15.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.8000, 17.3000],\n","        [26.8000, 16.4000]], dtype=torch.float64)\n","input:\n","tensor([[  9.1000,   3.4000,  12.8000,   2.7000,  16.2000,   1.8000,   5.9000,\n","          -2.0000,   3.4000,  -3.0000,  10.2000,   2.9000,   6.1000,   0.3000],\n","        [ -3.1000,  -8.1000,  -1.3000,  -8.1000,   1.3000,  -9.7000,   1.7000,\n","         -10.2000,  -9.0000, -14.8000,  -4.6000, -15.1000,  -0.3000,  -5.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.3000, -4.7000],\n","        [ 3.3000, -3.1000]], dtype=torch.float64)\n","input:\n","tensor([[24.4000, 13.9000, 26.1000, 14.7000, 28.6000, 19.7000, 28.2000, 18.8000,\n","         26.2000, 17.5000, 24.8000, 18.9000, 28.7000, 18.2000],\n","        [10.1000,  2.1000, 12.8000,  3.5000, 11.4000,  4.0000, 10.4000,  2.5000,\n","          6.6000,  2.7000,  3.9000,  1.2000,  5.8000,  1.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.7000, 18.8000],\n","        [ 7.8000,  2.9000]], dtype=torch.float64)\n","input:\n","tensor([[22.9000, 14.8000, 22.4000, 16.2000, 25.3000, 17.1000, 27.7000, 17.8000,\n","         26.0000, 16.4000, 27.4000, 17.2000, 27.1000, 16.6000],\n","        [ 9.4000,  0.6000,  9.3000,  2.8000, 10.1000,  1.2000,  9.9000,  6.3000,\n","         12.7000,  6.5000, 15.7000,  8.0000, 12.1000,  4.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.7000, 17.1000],\n","        [10.2000,  2.4000]], dtype=torch.float64)\n","input:\n","tensor([[15.9000,  8.0000, 14.6000,  6.2000, 17.0000,  6.5000, 15.1000,  7.0000,\n","         15.1000, 10.7000, 14.2000,  8.5000, 14.1000,  8.2000],\n","        [12.5000,  2.0000,  4.1000,  0.6000,  7.9000,  2.9000,  4.8000,  2.6000,\n","          3.1000,  1.1000,  4.4000,  0.1000,  0.5000, -2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.6000, 10.3000],\n","        [ 0.8000, -4.3000]], dtype=torch.float64)\n","input:\n","tensor([[  0.0000,  -5.6000,  -3.0000,  -6.6000,  -2.3000,  -5.8000,  -2.6000,\n","          -3.9000,  -0.4000,  -6.8000,   1.5000,  -4.0000,  -1.1000,  -7.2000],\n","        [  3.5000,  -3.5000,  -2.0000, -10.9000,  -7.1000, -12.2000,  -4.4000,\n","         -11.2000,   0.8000,  -6.6000,  -4.2000,  -7.8000,  -5.0000,  -7.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-1.1000, -6.1000],\n","        [-4.8000, -9.9000]], dtype=torch.float64)\n","input:\n","tensor([[ -5.7000, -19.7000, -19.2000, -25.1000, -12.6000, -22.4000,  -7.5000,\n","         -13.3000,  -6.9000, -13.4000, -13.3000, -20.5000, -11.3000, -21.3000],\n","        [  5.5000,  -2.3000,  17.9000,   4.1000,   8.7000,   4.8000,  12.3000,\n","           6.0000,   8.5000,   4.9000,   5.4000,  -0.5000,   6.7000,   0.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -6.4000, -11.4000],\n","        [  7.1000,   3.0000]], dtype=torch.float64)\n","input:\n","tensor([[12.9000,  6.8000,  7.9000,  4.3000,  6.4000,  4.4000,  4.5000,  0.2000,\n","          7.2000,  0.2000,  5.0000,  0.4000,  7.8000,  0.4000],\n","        [ 8.1000,  2.9000,  4.9000,  1.7000,  6.6000,  2.5000,  7.2000,  3.5000,\n","         11.1000,  6.6000, 14.2000,  9.6000, 11.0000,  1.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.2000,  6.6000],\n","        [ 5.4000,  0.3000]], dtype=torch.float64)\n","input:\n","tensor([[27.8000, 18.0000, 30.0000, 19.0000, 24.9000, 14.6000, 22.9000, 13.4000,\n","         22.0000, 13.7000, 27.6000, 18.7000, 29.6000, 21.1000],\n","        [13.2000,  9.5000, 15.6000, 10.4000, 16.4000, 12.1000, 24.0000, 12.7000,\n","         19.4000,  9.2000, 13.5000,  5.5000, 17.4000,  9.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.7000, 20.0000],\n","        [17.0000, 10.2000]], dtype=torch.float64)\n","input:\n","tensor([[  7.1000,   1.6000,  11.1000,   3.6000,  10.8000,   8.2000,  10.7000,\n","           6.1000,  11.9000,   6.1000,  10.4000,   6.3000,   9.7000,   6.4000],\n","        [ -1.4000,  -9.2000,  -6.2000, -12.5000, -12.4000, -15.0000,  -8.8000,\n","         -15.8000,  -7.8000, -13.2000,  -6.4000, -13.7000,  -3.6000,  -9.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  8.4000,   7.1000],\n","        [ -2.9000, -12.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 28.0000,  12.9000,  19.2000,   6.7000,  16.8000,   5.9000,  25.6000,\n","           8.7000,  17.8000,  11.2000,  25.5000,  12.3000,  18.7000,  13.1000],\n","        [  6.9000,   2.1000,   2.2000,  -6.5000,   2.7000,  -6.3000,   6.0000,\n","           1.8000,   4.4000,   2.1000,   5.0000,   0.7000,   2.0000, -10.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 27.4000,  11.9000],\n","        [  0.7000, -10.3000]], dtype=torch.float64)\n","input:\n","tensor([[  3.1000,  -4.9000,   1.5000,  -5.4000,   7.7000,  -0.6000,   6.5000,\n","          -5.2000,  -1.3000,  -9.4000,  -2.7000, -10.6000,   1.3000,  -8.0000],\n","        [ -2.6000,  -6.3000,  -2.2000,  -4.7000,  -2.2000,  -5.7000,  -3.9000,\n","          -7.0000,  -4.4000, -10.0000,  -0.9000, -10.7000,   0.7000,  -3.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.1000, -1.1000],\n","        [-0.2000, -3.1000]], dtype=torch.float64)\n","input:\n","tensor([[27.0000, 17.9000, 26.8000, 17.3000, 26.4000, 19.7000, 28.7000, 18.5000,\n","         25.4000, 17.9000, 23.3000, 15.4000, 21.9000, 13.7000],\n","        [-1.9000, -8.2000,  3.4000, -4.2000,  2.1000, -0.4000,  4.1000,  1.3000,\n","          5.5000,  2.0000,  4.9000,  0.2000,  4.2000, -2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[17.2000, 12.8000],\n","        [ 0.4000, -4.9000]], dtype=torch.float64)\n","input:\n","tensor([[-1.8000, -6.8000, -2.5000, -9.7000,  0.2000, -8.0000,  5.1000, -0.1000,\n","          7.0000,  1.6000,  1.7000, -2.0000,  2.3000, -0.8000],\n","        [13.0000,  3.6000, 12.6000,  3.8000, 16.8000,  7.6000, 13.1000,  9.9000,\n","         16.6000,  7.1000, 11.1000,  3.9000, 14.3000,  5.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 1.3000, -7.6000],\n","        [19.7000,  5.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.0000, -6.2000,  1.5000, -5.6000,  0.9000, -6.6000,  3.9000, -3.7000,\n","          6.4000,  1.1000,  5.9000,  0.0000,  4.0000, -2.4000],\n","        [13.4000,  6.3000, 12.6000,  3.9000, 17.5000,  5.9000, 21.8000, 12.3000,\n","         19.8000,  6.3000, 14.7000,  5.8000, 18.8000, 10.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 0.9000, -4.3000],\n","        [21.5000, 17.5000]], dtype=torch.float64)\n","input:\n","tensor([[33.9000, 22.5000, 32.8000, 22.6000, 31.1500, 25.0000, 29.5000, 22.5000,\n","         28.8000, 20.4000, 25.8000, 18.5000, 28.5000, 19.2000],\n","        [15.7000,  0.1000, 17.9000, 12.7000, 14.3000,  8.6000, 16.3000,  6.2000,\n","          8.7000,  2.1000, 14.9000,  7.7000, 13.9000,  5.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.6000, 19.7000],\n","        [10.4000,  5.2000]], dtype=torch.float64)\n","input:\n","tensor([[11.7000,  3.9000, 19.2000,  6.9000, 15.1000,  5.0000,  9.3000,  3.1000,\n","         12.2000,  1.8000, 10.6000,  4.8000, 10.4000,  4.5000],\n","        [27.1000, 15.7000, 22.8000, 14.8000, 24.7000, 15.3000, 20.9000, 12.9000,\n","         22.7000, 11.7000, 25.6000, 14.0000, 19.0000, 16.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.9000,  2.9000],\n","        [26.1000, 15.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 26.4000,  14.1000,  25.3000,  16.4000,  29.4000,  18.2000,  32.9000,\n","          21.2000,  33.6000,  19.4000,  31.1000,  19.5000,  30.4000,  17.2000],\n","        [ -1.3000,  -9.4000,  -2.7000, -10.6000,   1.3000,  -8.0000,   6.1000,\n","          -1.1000,   5.7000,   1.1000,   2.1000,  -7.1000,  -0.5000, -10.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[28.2000, 19.2000],\n","        [ 4.7000, -6.2000]], dtype=torch.float64)\n","input:\n","tensor([[  0.7000, -10.3000,   1.5000,  -2.3000,   4.4000,   1.5000,   7.6000,\n","           1.8000,   1.8000, -10.6000, -10.4000, -14.6000,   1.1000, -11.9000],\n","        [  3.4000,   0.2000,   5.8000,   3.3000,   5.3000,   1.3000,   3.8000,\n","           0.9000,   3.5000,  -1.8000,   3.4000,  -3.7000,   5.7000,  -0.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.5000, -0.2000],\n","        [ 9.1000,  3.4000]], dtype=torch.float64)\n","input:\n","tensor([[24.5000, 15.9000, 26.9000, 15.3000, 24.6000, 20.3000, 28.1000, 19.5000,\n","         27.7000, 21.3000, 29.4000, 21.0000, 29.1000, 21.2000],\n","        [11.3000,  0.3000,  2.1000, -0.3000,  3.3000, -1.2000, -0.5000, -5.4000,\n","          0.7000, -5.9000, -3.2000, -4.7000, -0.9000, -5.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.5000, 20.8000],\n","        [-2.7000, -9.9000]], dtype=torch.float64)\n","input:\n","tensor([[  9.0000,   4.0000,  13.0000,   4.2000,  14.7000,   8.4000,  12.2000,\n","           5.1000,  12.8000,   4.1000,   9.6000,   2.8000,   9.6000,   2.5000],\n","        [  4.0000,  -7.0000,  -7.0000, -17.0000,  -7.1000, -12.7000,  -7.4000,\n","         -13.3000,  -3.0000, -10.7000,  -2.0000,  -6.1000,  -2.3000,  -8.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.3000,  8.9000],\n","        [-2.3000, -9.0000]], dtype=torch.float64)\n","input:\n","tensor([[19.4000, 11.7000, 21.0000, 10.9000, 24.3000, 11.9000, 25.6000, 15.2000,\n","         28.8000, 15.2000, 30.5000, 16.8000, 31.8000, 18.6000],\n","        [ 6.7000,  5.1000, 15.0000,  6.2000, 12.6000,  8.0000, 11.8000,  7.7000,\n","         14.5000,  5.9000, 13.6000,  5.3000, 14.1000,  7.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[31.7000, 19.1000],\n","        [12.8000,  7.4000]], dtype=torch.float64)\n","input:\n","tensor([[16.4000, 12.7000, 19.8000, 14.7000, 22.8000, 12.4000, 17.6000, 15.0000,\n","         24.3000, 15.9000, 22.7000, 14.5000, 22.0000, 14.9000],\n","        [21.1000, 16.7000, 26.1000, 16.2000, 23.3000, 16.3000, 25.6000, 16.2000,\n","         27.5000, 18.4000, 27.1000, 13.4000, 22.0000, 10.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.0000, 15.0000],\n","        [16.7000,  9.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 30.0000,  20.2000,  24.9000,  18.7000,  27.8000,  18.3000,  25.7000,\n","          18.7000,  31.3000,  20.6000,  31.7000,  21.8000,  33.1000,  19.7000],\n","        [  4.9000,  -1.7000,   4.7000,  -5.6000,   5.9000,  -3.1000,   3.5000,\n","          -4.7000,  -4.4000, -10.1000,   3.6000,  -5.6000,   4.2000,  -4.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.8000, 18.5000],\n","        [-1.4000, -6.2000]], dtype=torch.float64)\n","input:\n","tensor([[27.0000, 19.2000, 29.6000, 21.5000, 28.7000, 21.4000, 27.8000, 20.6000,\n","         23.6000, 19.0000, 25.5000, 16.9000, 25.9000, 14.3000],\n","        [21.4000, 15.0000, 21.5000, 18.1000, 21.3000, 13.6000, 18.8000,  9.0000,\n","         15.1000,  5.8000, 12.3000,  5.8000, 12.5000,  7.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.8000, 15.9000],\n","        [14.2000, 10.5000]], dtype=torch.float64)\n","input:\n","tensor([[28.7000, 21.4000, 27.8000, 20.6000, 23.6000, 19.0000, 25.5000, 16.9000,\n","         25.9000, 14.3000, 27.8000, 15.9000, 26.7000, 19.1000],\n","        [19.4000, 12.7000, 20.0000, 11.6000, 21.7000, 10.9000, 17.5000, 10.7000,\n","         23.5000, 11.1000, 25.3000, 12.1000, 30.1000, 16.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.1000, 20.2000],\n","        [26.0000, 18.5000]], dtype=torch.float64)\n","input:\n","tensor([[18.5000, 12.1000, 23.9000, 12.0000, 25.1000, 13.4000, 20.5000, 15.9000,\n","         26.0000, 15.7000, 23.7000, 16.8000, 22.9000, 15.8000],\n","        [13.9000,  3.7000,  9.2000,  3.4000, 11.5000,  3.2000, 12.2000,  3.0000,\n","         14.1000,  3.5000, 15.2000,  6.5000, 18.3000, 10.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.4000, 16.9000],\n","        [25.3000, 10.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 11.9000,   3.5000,   9.3000,   6.1000,  15.9000,   8.0000,  14.6000,\n","           6.2000,  17.0000,   6.5000,  15.1000,   7.0000,  15.1000,  10.7000],\n","        [  2.2000,  -2.0000,  -0.1000, -10.4000,  -9.0000, -16.2000,  -3.4000,\n","         -14.4000, -14.3000, -24.7000,  -9.6000, -22.4000,   0.0000,  -9.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.2000,  8.5000],\n","        [ 0.5000, -0.8000]], dtype=torch.float64)\n","input:\n","tensor([[23.3000, 14.8000, 21.7000, 13.9000, 24.1000, 14.0000, 21.7000, 16.9000,\n","         22.0000, 16.8000, 23.1000, 17.9000, 24.8000, 17.9000],\n","        [20.4000, 12.4000, 19.7000, 10.9000, 20.3000,  9.2000, 24.0000, 13.4000,\n","         20.4000,  8.9000, 16.4000,  7.8000, 18.7000, 13.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.5000, 18.6000],\n","        [20.8000, 12.3000]], dtype=torch.float64)\n","input:\n","tensor([[13.8000,  9.8000, 17.6000,  8.8000, 15.4000, 12.3000, 17.8000, 11.7000,\n","         19.7000,  9.3000, 16.6000,  8.3000, 21.6000,  7.9000],\n","        [21.9000, 16.9000, 31.0000, 17.0000, 30.1000, 22.3000, 25.5000, 19.2000,\n","         19.5000, 14.7000, 22.7000, 15.2000, 22.6000, 12.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.6000, 11.7000],\n","        [21.1000, 11.8000]], dtype=torch.float64)\n","input:\n","tensor([[24.0000, 17.1000, 24.7000, 18.0000, 28.2000, 19.0000, 23.9000, 19.5000,\n","         27.9000, 19.3000, 26.9000, 20.3000, 28.5000, 18.2000],\n","        [24.2000, 12.8000, 21.7000, 10.5000, 20.0000, 12.9000, 21.4000, 12.7000,\n","         22.1000, 12.5000, 18.9000,  9.9000, 16.7000, 10.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[31.7000, 20.1000],\n","        [22.0000, 11.6000]], dtype=torch.float64)\n","input:\n","tensor([[-3.0000, -6.6000, -2.3000, -5.8000, -2.6000, -3.9000, -0.4000, -6.8000,\n","          1.5000, -4.0000, -1.1000, -7.2000, -1.1000, -6.1000],\n","        [ 1.9000, -3.8000,  3.9000, -4.3000, 10.2000,  1.5000, 11.5000,  5.9000,\n","         12.4000,  5.1000, 15.7000,  9.9000, 11.8000,  2.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.7000, -7.6000],\n","        [ 3.9000, -1.6000]], dtype=torch.float64)\n","input:\n","tensor([[22.3000, 11.7000, 28.4000, 15.3000, 30.9000, 17.6000, 33.2000, 20.2000,\n","         32.9000, 22.4000, 27.1000, 15.7000, 22.8000, 14.8000],\n","        [20.1000, 11.1000, 22.9000, 13.3000, 25.1000, 16.5000, 29.6000, 17.3000,\n","         27.1000, 13.8000, 20.8000, 10.4000, 23.0000, 10.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.7000, 15.3000],\n","        [18.0000, 12.1000]], dtype=torch.float64)\n","input:\n","tensor([[14.3000,  8.6000, 16.3000,  6.2000,  8.7000,  2.1000, 14.9000,  7.7000,\n","         13.9000,  5.4000, 10.4000,  5.2000, 11.3000,  5.6000],\n","        [12.9000,  0.0000,  4.5000, -5.5000,  2.9000, -8.2000, 15.2000,  2.9000,\n","         13.2000,  6.5000, 18.4000,  6.2000, 15.2000,  3.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.8000,  9.1000],\n","        [16.3000,  6.0000]], dtype=torch.float64)\n","input:\n","tensor([[24.4000, 11.3000, 21.5000, 12.8000, 16.2000, 10.4000, 21.1000, 10.0000,\n","         23.1000, 12.1000, 24.9000, 13.3000, 26.9000, 14.4000],\n","        [19.4000, 12.7000, 23.1000, 12.1000, 26.4000, 14.4000, 26.8000, 18.2000,\n","         31.7000, 19.2000, 32.3000, 21.7000, 28.5000, 21.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.4000, 15.4000],\n","        [29.0000, 19.9000]], dtype=torch.float64)\n","input:\n","tensor([[ 8.6000,  4.4000,  9.4000,  4.3000,  7.7000,  2.4000,  7.8000,  2.2000,\n","         14.4000,  3.1000, 10.6000,  2.8000,  9.2000,  0.9000],\n","        [12.8000,  6.0000,  6.1000,  0.4000,  7.5000, -0.3000,  9.1000,  0.5000,\n","         10.7000,  2.0000,  8.6000,  5.6000,  6.8000,  2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.6000, -0.3000],\n","        [ 5.6000,  0.4000]], dtype=torch.float64)\n","input:\n","tensor([[10.7000,  2.0000,  8.6000,  5.6000,  6.8000,  2.3000,  5.6000,  0.4000,\n","          9.0000,  3.3000, 11.1000,  2.5000, 10.4000,  2.7000],\n","        [20.0000, 16.7000, 23.2000, 14.9000, 22.1000, 13.6000, 23.4000, 13.9000,\n","         24.3000, 18.4000, 20.8000, 15.8000, 30.8000, 16.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.5000,  4.0000],\n","        [21.7000, 15.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.1000,  3.7000,  9.7000,  3.7000, 10.4000,  6.9000, 12.6000,  4.0000,\n","         11.1000,  4.4000,  7.1000, -1.4000,  1.2000, -4.1000],\n","        [26.6000, 19.6000, 28.8000, 17.7000, 28.9000, 17.8000, 32.0000, 19.6000,\n","         25.6000, 17.6000, 24.1000, 16.5000, 23.8000, 16.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 2.2000, -3.0000],\n","        [25.3000, 19.1000]], dtype=torch.float64)\n","input:\n","tensor([[22.7000, 13.4000, 22.5000, 19.3000, 25.3000, 17.8000, 25.7000, 16.5000,\n","         28.0000, 16.9000, 26.6000, 14.7000, 24.9000, 16.9000],\n","        [ 9.4000,  3.6000,  6.7000,  1.5000, 10.6000,  3.4000,  8.6000,  3.5000,\n","          6.6000, -1.8000,  1.9000, -3.8000,  3.9000, -4.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.2000, 12.3000],\n","        [10.2000,  1.5000]], dtype=torch.float64)\n","input:\n","tensor([[24.7000, 14.6000, 27.8000, 16.6000, 29.5000, 20.2000, 22.3000, 17.3000,\n","         25.3000, 15.7000, 21.1000, 14.2000, 22.9000, 11.7000],\n","        [22.0000, 13.8000, 21.6000, 18.4000, 22.7000, 18.5000, 22.6000, 10.5000,\n","         15.9000, 10.3000, 14.8000,  7.8000, 15.8000,  7.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.4000, 12.7000],\n","        [18.2000, 10.2000]], dtype=torch.float64)\n","input:\n","tensor([[32.9000, 22.4000, 27.1000, 15.7000, 22.8000, 14.8000, 24.7000, 15.3000,\n","         20.9000, 12.9000, 22.7000, 11.7000, 25.6000, 14.0000],\n","        [ 2.3000, -0.8000,  1.3000, -7.6000,  6.4000, -6.8000,  9.9000,  2.9000,\n","          9.9000,  1.8000,  2.7000,  0.8000, 15.6000,  2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.0000, 16.5000],\n","        [ 4.5000, -0.3000]], dtype=torch.float64)\n","input:\n","tensor([[14.6000,  5.4000, 18.3000,  7.6000, 16.6000,  9.2000, 16.2000,  9.6000,\n","         16.5000,  9.7000, 19.0000, 11.1000, 23.2000, 11.2000],\n","        [25.7000, 14.5000, 21.3000, 10.5000, 16.9000, 15.7000, 17.1000, 13.2000,\n","         19.6000, 14.3000, 19.6000,  9.7000, 17.4000,  7.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.3000,  9.1000],\n","        [18.2000,  9.0000]], dtype=torch.float64)\n","input:\n","tensor([[19.0000, 16.5000, 26.1000, 15.9000, 28.7000, 16.4000, 30.9000, 16.9000,\n","         28.0000, 19.5000, 34.7000, 21.2000, 30.0000, 22.2000],\n","        [22.5000,  6.9000, 12.2000,  4.7000, 10.6000,  5.1000, 13.8000,  3.7000,\n","          5.9000, -0.1000,  8.2000,  3.5000,  7.2000,  1.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.1000, 16.5000],\n","        [ 3.3000,  1.4000]], dtype=torch.float64)\n","input:\n","tensor([[10.5000,  3.2000,  7.6000, -0.2000, 10.8000,  1.0000, 14.6000,  8.5000,\n","         12.9000,  4.4000,  6.1000, -2.3000,  2.7000, -4.0000],\n","        [ 2.6000, -0.2000,  3.0000, -2.2000,  6.8000,  0.1000,  0.1000, -8.5000,\n","         -5.1000, -8.8000,  3.1000, -6.2000,  4.5000,  2.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-0.7000, -5.7000],\n","        [ 5.1000,  2.3000]], dtype=torch.float64)\n","input:\n","tensor([[  2.9000,  -0.2000,   2.1000,  -3.2000,   2.9000,  -2.8000,   3.0000,\n","          -5.5000,  -1.4000,  -7.5000,  -7.5000, -14.2000,   1.7000, -13.2000],\n","        [ 29.5000,  21.4000,  27.0000,  20.4000,  25.6000,  18.6000,  22.8000,\n","          16.3000,  23.9000,  15.4000,  25.5000,  15.3000,  23.8000,  16.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.6000, -4.5000],\n","        [20.3000, 13.8000]], dtype=torch.float64)\n","input:\n","tensor([[15.0000,  7.9000, 10.3000,  5.8000, 12.8000,  6.0000,  6.1000,  0.4000,\n","          7.5000, -0.3000,  9.1000,  0.5000, 10.7000,  2.0000],\n","        [ 2.1000,  0.1500,  7.0000,  1.9000, 10.6000,  5.6000,  5.7000,  4.0000,\n","          6.7000,  2.1000, 10.1000,  4.3000,  6.4000,  0.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.6000,  5.6000],\n","        [ 1.3000, -4.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 31.5000,  19.2000,  33.8000,  21.4000,  34.5000,  24.3000,  28.4000,\n","          22.7000,  34.2000,  21.0000,  38.2000,  24.9000,  32.5000,  22.7000],\n","        [ -0.2000,  -5.9000,   2.2000,  -2.9000,  -2.9000,  -7.7000,  -3.7000,\n","          -9.0000,  -6.9000, -10.0000,  -3.9000, -12.2000,  -9.4000, -13.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 33.4000,  23.4000],\n","        [ -3.7000, -11.8000]], dtype=torch.float64)\n","input:\n","tensor([[ 8.3000,  3.0000, 13.1000,  8.0000, 13.9000, 10.1000, 12.5000,  2.0000,\n","          4.1000,  0.6000,  7.9000,  2.9000,  4.8000,  2.6000],\n","        [ 7.4000,  1.7000, 10.3000,  5.4000,  8.3000,  2.6000,  4.0000, -1.3000,\n","          1.4000, -2.7000,  2.8000, -2.3000,  2.6000, -0.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.1000,  1.1000],\n","        [ 3.0000, -2.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 4.2000, -3.3000,  6.5000,  0.4000,  7.2000,  0.9000,  8.6000,  3.7000,\n","         13.1000,  3.8000,  6.3000,  0.0000,  0.0000, -5.9000],\n","        [29.4000, 18.4000, 21.8000, 15.4000, 21.6000, 14.0000, 23.6000, 14.8000,\n","         25.1000, 15.1000, 27.5000, 17.1000, 25.8000, 17.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 3.4000, -5.2000],\n","        [26.8000, 19.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.9000, -3.3000, -1.4000, -8.8000, -0.1000, -9.6000,  1.6000, -5.7000,\n","          0.1000, -6.8000,  1.6000, -1.8000, -1.7000, -7.5000],\n","        [16.8000, 12.0000, 26.6000, 14.3000, 17.3000, 12.8000, 12.8000,  7.8000,\n","          9.9000,  7.9000, 14.5000,  7.9000, 18.5000, 11.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -4.9000, -10.4000],\n","        [ 18.9000,   9.6000]], dtype=torch.float64)\n","input:\n","tensor([[13.6000,  4.4000, 17.1000, 10.3000, 13.2000, 10.5000, 14.6000,  8.9000,\n","          9.5000,  2.4000,  6.6000,  1.7000, 13.1000,  4.8000],\n","        [ 5.4000, -0.3000,  8.8000,  1.9000,  3.8000, -1.0000,  4.4000,  0.0000,\n","          6.1000,  2.5000,  6.6000,  1.2000,  9.7000,  0.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[14.8000,  9.5000],\n","        [ 6.4000, -3.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 26.3000,  13.3000,  26.4000,  14.6000,  26.8000,  18.4000,  31.1000,\n","          18.8000,  29.4000,  16.8000,  28.9000,  16.9000,  30.0000,  20.2000],\n","        [ -0.7000, -10.2000,  -8.5000, -15.5000, -10.9000, -18.4000,  -8.1000,\n","         -15.6000,  -4.7000, -10.5000,  -2.9000,  -8.6000,   2.9000,  -4.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.9000, 18.7000],\n","        [ 2.8000, -6.2000]], dtype=torch.float64)\n","input:\n","tensor([[ 2.6000, -1.2000,  1.8000, -1.0000,  8.2000,  1.7000,  8.5000,  1.8000,\n","         13.6000,  6.7000, 12.3000,  8.8000, 12.9000,  6.8000],\n","        [ 6.6000,  2.5000,  8.1000,  3.7000, 13.0000,  6.7000, 14.7000,  5.2000,\n","          5.4000, -2.2000,  1.4000, -3.2000,  3.4000, -1.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  7.9000,   4.3000],\n","        [  2.0000, -10.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 0.9000, -4.7000,  1.9000, -1.9000,  0.7000, -6.3000, -1.6000, -6.6000,\n","         -2.9000, -6.8000, -3.4000, -8.7000, -2.9000, -8.6000],\n","        [12.8000,  2.7000, 16.2000,  1.8000,  5.9000, -2.0000,  3.4000, -3.0000,\n","         10.2000,  2.9000,  6.1000,  0.3000,  0.3000, -4.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-2.4000, -9.1000],\n","        [ 0.3000, -6.8000]], dtype=torch.float64)\n","input:\n","tensor([[26.2000, 16.7000, 27.7000, 16.3000, 27.5000, 19.3000, 27.6000, 16.6000,\n","         28.3000, 17.6000, 26.4000, 17.7000, 25.8000, 20.9000],\n","        [11.7000,  5.2000,  6.9000, -3.6000,  3.2000, -4.4000,  4.2000, -3.9000,\n","          8.4000, -1.8000,  6.4000, -1.1000,  5.5000, -2.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.9000, 19.8000],\n","        [17.9000,  4.1000]], dtype=torch.float64)\n","input:\n","tensor([[-0.3000, -7.5000,  4.2000, -6.4000,  7.7000, -3.7000,  7.1000, -1.8000,\n","          3.8000,  1.5000, 10.9000,  2.6000, 13.1000,  1.0000],\n","        [18.8000,  9.0000, 15.1000,  5.8000, 12.3000,  5.8000, 12.5000,  7.6000,\n","         14.2000, 10.5000, 14.8000, 11.2000, 16.9000, 11.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.5000,  0.8000],\n","        [21.1000, 10.6000]], dtype=torch.float64)\n","input:\n","tensor([[29.3000, 19.9000, 25.3000, 16.5000, 25.6000, 14.5000, 29.9000, 18.7000,\n","         29.3000, 21.2000, 29.4000, 22.7000, 29.4000, 20.8000],\n","        [15.5000,  1.7000, 12.8000,  2.7000,  8.9000,  2.3000, 11.3000,  6.2000,\n","          7.2000,  5.4000,  7.2000,  4.5000,  7.0000,  3.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.9000, 19.6000],\n","        [12.1000,  4.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.5000,  4.8000, 12.3000,  7.6000, 13.7000,  7.8000, 12.7000,  6.5000,\n","         10.6000,  4.5000,  5.6000,  0.8000,  4.2000,  0.6000],\n","        [22.1000, 11.8000, 21.4000, 14.0000, 20.5000, 11.8000, 23.8000, 12.8000,\n","         21.5000, 12.4000, 24.2000, 12.1000, 22.2000, 15.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.3000, -0.9000],\n","        [22.9000, 14.5000]], dtype=torch.float64)\n","input:\n","tensor([[27.9000, 15.6000, 25.9000, 18.4000, 26.0000, 15.3000, 24.0000, 14.5000,\n","         18.9000, 11.5000, 17.8000, 10.6000, 17.3000, 10.9000],\n","        [ 0.2000, -9.7000,  6.6000, -4.6000, 13.4000,  3.6000, 10.3000,  1.7000,\n","          7.1000,  3.7000,  4.4000,  1.0000, 16.9000,  3.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[22.1000, 12.9000],\n","        [16.6000,  8.2000]], dtype=torch.float64)\n","input:\n","tensor([[20.5000, 15.0000, 23.6000, 15.5000, 25.0000, 14.9000, 26.2000, 13.1000,\n","         24.0000, 12.1000, 18.4000, 10.6000, 20.9000, 11.7000],\n","        [19.2000, 15.2000, 21.1000, 16.7000, 26.1000, 16.2000, 23.3000, 16.3000,\n","         25.6000, 16.2000, 27.5000, 18.4000, 27.1000, 13.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.0000, 11.3000],\n","        [22.0000, 10.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 25.4000,  17.1000,  28.6000,  17.3000,  32.1000,  20.5000,  24.4000,\n","          17.3000,  25.2000,  14.8000,  21.6000,  15.2000,  25.5000,  14.4000],\n","        [ -0.6000,  -5.6000,  -4.6000, -14.0000,  -0.3000, -14.6000,   3.8000,\n","          -1.5000,  -1.5000,  -9.4000,  -4.2000, -10.9000,  -4.1000, -11.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 30.4000,  17.1000],\n","        [ -7.7000, -12.7000]], dtype=torch.float64)\n","input:\n","tensor([[25.6000, 15.2000, 28.8000, 15.2000, 30.5000, 16.8000, 31.8000, 18.6000,\n","         31.7000, 19.1000, 26.7000, 14.9000, 26.0000, 15.9000],\n","        [22.4000, 12.3000, 21.5000,  8.4000, 16.2000,  7.2000, 14.9000,  7.7000,\n","         11.9000,  4.6000, 12.6000,  5.1000, 13.8000,  3.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.9000, 15.0000],\n","        [14.5000,  6.8000]], dtype=torch.float64)\n","input:\n","tensor([[13.1000,  6.2000, 11.3000,  8.3000, 15.1000,  9.0000, 12.0000, 10.6000,\n","         11.3000,  9.6000, 15.4000, 10.1000, 15.7000,  8.2000],\n","        [ 7.5000,  0.0000,  6.0000, -1.0000,  9.3000,  1.5000, 12.6000,  4.6000,\n","         16.3000,  7.6000, 20.6000,  8.9000, 23.3000,  9.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.5000,  6.3000],\n","        [15.4000,  7.2000]], dtype=torch.float64)\n","input:\n","tensor([[22.5000, 14.1000, 17.5000, 13.9000, 20.8000, 12.1000, 20.0000, 10.9000,\n","         21.8000, 14.1000, 24.0000, 16.1000, 20.0000, 16.7000],\n","        [30.8000, 21.2000, 30.9000, 18.2000, 27.7000, 17.8000, 28.1000, 17.0000,\n","         27.3000, 15.8000, 25.9000, 16.6000, 23.8000, 15.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[23.2000, 14.9000],\n","        [23.6000, 13.9000]], dtype=torch.float64)\n","input:\n","tensor([[26.0000, 15.9000, 23.9000, 15.0000, 28.0000, 15.3000, 28.5000, 16.9000,\n","         32.5000, 18.5000, 33.2000, 21.1000, 24.0000, 16.4000],\n","        [20.0000, 11.6000, 21.7000, 10.9000, 17.5000, 10.7000, 23.5000, 11.1000,\n","         25.3000, 12.1000, 30.1000, 16.2000, 26.0000, 18.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[26.7000, 15.5000],\n","        [16.8000, 13.9000]], dtype=torch.float64)\n","input:\n","tensor([[ -3.6000, -12.5000,   2.0000,  -7.8000,   3.3000,  -0.3000,   2.6000,\n","          -1.4000,   3.0000,   0.4000,   4.2000,   0.5000,   2.1000,   0.5000],\n","        [ 32.9000,  21.2000,  33.6000,  19.4000,  31.1000,  19.5000,  30.4000,\n","          17.2000,  28.2000,  19.2000,  34.5000,  20.3000,  26.8000,  21.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.0000, -0.5000],\n","        [36.0000, 21.7000]], dtype=torch.float64)\n","input:\n","tensor([[24.1000, 17.2000, 24.5000, 15.9000, 26.9000, 15.3000, 24.6000, 20.3000,\n","         28.1000, 19.5000, 27.7000, 21.3000, 29.4000, 21.0000],\n","        [24.3000, 18.3000, 26.5000, 17.9000, 28.8000, 19.8000, 25.6000, 18.4000,\n","         21.9000, 14.5000, 20.4000, 11.8000, 21.7000, 10.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.1000, 21.2000],\n","        [24.6000, 11.3000]], dtype=torch.float64)\n","input:\n","tensor([[21.4000, 13.7000, 19.5000, 14.6000, 22.6000, 12.3000, 25.7000, 14.5000,\n","         21.3000, 10.5000, 16.9000, 15.7000, 17.1000, 13.2000],\n","        [19.8000,  9.6000, 20.5000, 12.0000, 25.5000, 14.7000, 24.4000, 17.3000,\n","         27.2000, 16.3000, 25.5000, 15.3000, 22.5000, 12.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[19.6000, 14.3000],\n","        [26.2000, 13.6000]], dtype=torch.float64)\n","input:\n","tensor([[ 20.3000,   9.1000,  14.4000,   5.3000,  13.9000,   3.4000,  16.8000,\n","           6.1000,  18.8000,   8.5000,  22.5000,  11.3000,  16.2000,   8.3000],\n","        [ -2.0000,  -6.1000,  -2.3000,  -8.2000,  -2.3000,  -9.0000,  -2.5000,\n","         -13.4000,   6.5000,  -2.5000,   3.5000,  -2.9000,  -0.7000,  -7.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 19.6000,   5.8000],\n","        [ -7.2000, -15.8000]], dtype=torch.float64)\n","input:\n","tensor([[26.4000, 19.1000, 31.2000, 20.6000, 32.7000, 21.0000, 28.3000, 19.8000,\n","         27.8000, 16.9000, 21.9000, 15.3000, 27.0000, 15.3000],\n","        [21.4000, 12.7000, 22.1000, 12.5000, 18.9000,  9.9000, 16.7000, 10.9000,\n","         22.0000, 11.6000, 18.7000,  8.5000, 11.1000,  3.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[31.2000, 18.7000],\n","        [10.0000,  1.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 12.3000,   2.9000,  13.3000,   1.3000,   6.0000,  -0.2000,   0.1000,\n","          -5.0000,  -4.9000, -13.2000,  -2.3000, -13.0000,   1.9000,  -3.3000],\n","        [ 28.2000,  18.0000,  22.5000,  15.3000,  15.5000,  12.0000,  17.4000,\n","          13.5000,  21.2000,  15.0000,  19.0000,  11.9000,  16.4000,   7.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-1.4000, -8.8000],\n","        [12.3000,  6.6000]], dtype=torch.float64)\n","input:\n","tensor([[14.8000,  9.1000, 12.8000,  5.6000,  9.9000,  3.2000, 11.1000,  2.6000,\n","         15.7000,  8.0000, 14.5000,  5.8000, 20.0000,  9.1000],\n","        [ 5.6000,  0.8000,  4.2000,  0.6000,  9.3000, -0.9000, 18.3000,  7.8000,\n","         10.9000,  1.9000,  6.2000,  0.4000, 15.0000,  5.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[16.8000, 10.0000],\n","        [18.0000,  9.3000]], dtype=torch.float64)\n","input:\n","tensor([[28.2000, 11.9000, 21.8000, 11.3000, 22.2000, 14.1000, 26.4000, 16.6000,\n","         28.2000, 18.6000, 25.9000, 20.0000, 26.7000, 19.8000],\n","        [23.6000, 18.1000, 26.0000, 16.9000, 22.2000, 14.8000, 25.8000, 13.2000,\n","         28.5000, 15.0000, 25.1000, 18.8000, 25.1000, 19.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[30.9000, 20.9000],\n","        [28.7000, 19.0000]], dtype=torch.float64)\n","input:\n","tensor([[ 24.4000,  14.5000,  28.9000,  15.6000,  30.5000,  17.2000,  34.2000,\n","          21.3000,  33.0000,  23.1000,  33.2000,  22.9000,  34.1000,  24.6000],\n","        [  5.4000,  -2.2000,   1.4000,  -3.2000,   3.4000,  -1.4000,   2.0000,\n","         -10.3000,   1.9000, -10.4000,   8.3000,   1.9000,   7.9000,  -7.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 26.5000,  19.8000],\n","        [ -5.1000, -11.1000]], dtype=torch.float64)\n","input:\n","tensor([[24.9000, 13.2000, 19.7000, 11.4000, 16.3000, 11.3000, 11.7000,  6.0000,\n","          8.8000,  4.2000, 13.9000,  4.7000, 10.6000,  5.9000],\n","        [ 8.1000,  1.9000, 12.3000,  6.5000, 11.1000,  4.7000, 15.5000,  6.9000,\n","         10.4000,  2.3000,  3.7000, -0.1000,  3.9000, -0.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 8.5000,  4.0000],\n","        [ 4.3000, -2.1000]], dtype=torch.float64)\n","input:\n","tensor([[ 32.7000,  21.4000,  27.8000,  18.0000,  25.9000,  15.3000,  24.9000,\n","          16.8000,  20.7000,  15.0000,  26.4000,  14.1000,  25.3000,  16.4000],\n","        [  3.0000,  -1.6000,   3.0000,  -3.2000,   2.5000,  -3.9000,   2.7000,\n","         -10.0000,  -2.8000, -11.9000,  -2.1000,  -9.6000,  -2.1000,  -8.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[29.4000, 18.2000],\n","        [ 2.4000, -6.8000]], dtype=torch.float64)\n","input:\n","tensor([[23.1000, 17.9000, 24.8000, 17.9000, 22.5000, 18.6000, 23.1000, 17.2000,\n","         26.9000, 17.2000, 26.2000, 19.5000, 22.4000, 15.6000],\n","        [ 9.8000,  4.0000,  9.2000,  4.1000, 10.2000,  5.2000, 10.1000,  3.8000,\n","         13.7000,  5.6000, 11.8000,  1.4000,  4.3000, -0.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[25.5000, 15.3000],\n","        [ 3.2000, -0.7000]], dtype=torch.float64)\n","input:\n","tensor([[ 1.8000, -1.0000,  8.2000,  1.7000,  8.5000,  1.8000, 13.6000,  6.7000,\n","         12.3000,  8.8000, 12.9000,  6.8000,  7.9000,  4.3000],\n","        [10.1000, -1.6000,  0.3000, -5.6000,  3.7000, -3.4000,  6.6000,  3.7000,\n","          9.5000,  3.0000, 12.1000,  1.9000, 15.2000,  3.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 6.4000,  4.4000],\n","        [18.3000,  7.3000]], dtype=torch.float64)\n","input:\n","tensor([[26.2000, 20.8000, 28.5000, 21.4000, 27.4000, 21.8000, 28.9000, 20.9000,\n","         30.7000, 23.3000, 29.6000, 20.6000, 27.2000, 17.8000],\n","        [-1.8000, -9.7000, -0.7000, -9.3000,  3.8000, -1.4000,  7.1000,  1.3000,\n","         13.4000,  6.9000,  8.1000, -5.6000, -5.5000, -9.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.4000, 19.7000],\n","        [-4.6000, -9.3000]], dtype=torch.float64)\n","input:\n","tensor([[12.6000,  6.0000,  8.1000,  5.9000,  6.7000,  5.1000, 15.0000,  6.2000,\n","         12.6000,  8.0000, 11.8000,  7.7000, 14.5000,  5.9000],\n","        [24.6000, 11.7000, 19.1000, 12.8000, 22.5000, 12.6000, 24.9000, 11.6000,\n","         17.3000,  7.7000, 16.3000,  5.9000, 19.6000,  9.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.6000,  5.3000],\n","        [27.0000, 11.5000]], dtype=torch.float64)\n","input:\n","tensor([[27.4000, 17.6000, 31.5000, 19.2000, 33.8000, 21.4000, 34.5000, 24.3000,\n","         28.4000, 22.7000, 34.2000, 21.0000, 38.2000, 24.9000],\n","        [ 7.0000,  1.9000,  6.6000,  2.5000,  8.1000,  3.7000, 13.0000,  6.7000,\n","         14.7000,  5.2000,  5.4000, -2.2000,  1.4000, -3.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[32.5000, 22.7000],\n","        [ 3.4000, -1.4000]], dtype=torch.float64)\n","input:\n","tensor([[27.0000, 20.4000, 25.0000, 20.4000, 28.9000, 19.8000, 26.8000, 21.3000,\n","         29.5000, 20.5000, 25.2000, 20.7000, 31.6000, 18.3000],\n","        [27.9000, 21.5000, 26.7000, 22.1000, 27.1000, 20.2000, 26.7000, 20.5000,\n","         29.7000, 22.7000, 27.8000, 19.7000, 28.2000, 17.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[24.8000, 16.5000],\n","        [24.2000, 17.4000]], dtype=torch.float64)\n","input:\n","tensor([[ 10.4000,   2.3000,   3.7000,  -0.1000,   3.9000,  -0.6000,   4.3000,\n","          -2.1000,   6.0000,   0.2000,  12.0000,   5.3000,   5.9000,   1.8000],\n","        [  0.8000,  -2.7000,   2.7000,  -0.4000,   2.1000,  -5.9000,  -2.3000,\n","         -10.0000,   5.9000,  -4.0000,  14.4000,   3.2000,  11.3000,  -6.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  1.8000,  -5.8000],\n","        [ -6.1000, -10.3000]], dtype=torch.float64)\n","input:\n","tensor([[ 9.0000,  5.4000, 14.5000,  6.8000, 14.5000,  7.8000, 20.3000,  9.3000,\n","         23.5000, 13.0000, 13.8000,  9.8000, 17.6000,  8.8000],\n","        [ 8.5000,  4.0000,  6.2000,  0.9000,  6.6000,  1.0000, 10.7000,  1.1000,\n","         19.8000, 10.7000, 12.0000,  2.8000,  9.5000,  2.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.4000, 12.3000],\n","        [17.9000,  7.0000]], dtype=torch.float64)\n","input:\n","tensor([[27.5000, 18.4000, 27.1000, 13.4000, 22.0000, 10.6000, 16.7000,  9.2000,\n","         17.2000,  7.2000, 17.8000,  9.9000, 19.5000, 10.7000],\n","        [22.6000, 13.8000, 27.6000, 14.7000, 33.0000, 19.7000, 26.4000, 19.0000,\n","         27.1000, 18.7000, 27.5000, 19.4000, 24.3000, 18.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[18.5000, 14.7000],\n","        [26.5000, 17.9000]], dtype=torch.float64)\n","input:\n","tensor([[  4.5000,   3.3000,   5.3000,   2.1000,   5.9000,   0.0000,   0.7000,\n","          -4.2000,   0.1000,  -5.0000,  -0.2000,  -4.7000,   3.1000,  -1.6000],\n","        [ -2.0000, -11.2000,  -7.3000, -13.1000,  -4.5000, -11.3000,  -0.7000,\n","         -11.8000,   1.1000,  -3.9000,  -0.8000, -13.7000,  -1.9000, -13.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[  2.1000,   0.1500],\n","        [ -1.7000, -13.9000]], dtype=torch.float64)\n","input:\n","tensor([[25.3000, 10.0000, 12.1000,  1.9000,  8.9000,  0.6000, 20.6000,  5.8000,\n","         19.4000,  5.7000,  8.6000,  4.4000,  9.4000,  4.3000],\n","        [29.4000, 21.0000, 29.1000, 21.2000, 24.5000, 20.8000, 24.5000, 20.4000,\n","         24.8000, 16.7000, 21.8000, 15.3000, 26.5000, 13.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 7.7000,  2.4000],\n","        [18.0000, 10.7000]], dtype=torch.float64)\n","input:\n","tensor([[  4.3000,  -0.6000,   1.4000,  -4.7000,  -4.3000,  -8.8000,  -5.2000,\n","         -10.4000,  -8.2000, -14.2000,  -8.3000, -16.0000,  -6.9000, -17.7000],\n","        [ 27.1000,  13.8000,  20.8000,  10.4000,  23.0000,  10.8000,  18.0000,\n","          12.1000,  27.9000,  12.6000,  26.8000,  15.9000,  27.3000,  16.1000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -0.7000, -10.2000],\n","        [ 34.2000,  20.1000]], dtype=torch.float64)\n","input:\n","tensor([[10.2333,  5.6000, 10.8000,  5.1000, 15.8000,  7.6000, 15.3000,  7.7000,\n","          9.0000,  1.7000,  4.7000, -1.0000,  5.9000, -0.3000],\n","        [ 3.9000, -0.6000,  4.3000, -2.1000,  6.0000,  0.2000, 12.0000,  5.3000,\n","          5.9000,  1.8000,  1.8000, -5.8000, -3.6000, -8.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[13.3000,  3.6000],\n","        [ 2.4000, -5.4000]], dtype=torch.float64)\n","input:\n","tensor([[ -9.0000, -14.3000,  -4.3000, -14.7000,  -1.1000,  -5.1000,   4.0000,\n","          -7.0000,  -7.0000, -17.0000,  -7.1000, -12.7000,  -7.4000, -13.3000],\n","        [ -2.6000,  -3.9000,  -0.4000,  -6.8000,   1.5000,  -4.0000,  -1.1000,\n","          -7.2000,  -1.1000,  -6.1000,  -0.7000,  -7.6000,   0.3000,  -2.0000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -3.0000, -10.7000],\n","        [  3.1000,  -0.7000]], dtype=torch.float64)\n","input:\n","tensor([[11.5000,  5.2000, 11.3000,  4.6000, 10.7000,  5.8000, 11.4000,  5.3000,\n","          7.4000,  1.4000,  7.5000,  0.1000,  7.4000,  1.2000],\n","        [18.9000,  9.9000, 16.7000, 10.9000, 22.0000, 11.6000, 18.7000,  8.5000,\n","         11.1000,  3.2000, 10.0000,  1.1000, 11.0000,  0.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 9.2000, -0.5000],\n","        [11.9000,  3.5000]], dtype=torch.float64)\n","input:\n","tensor([[ 6.9000, -1.8000,  2.8000, -5.3000,  3.1000, -1.2000,  8.1000,  2.0000,\n","         10.1000,  4.4000, 12.0000,  2.4000, 12.9000,  3.1000],\n","        [10.4000,  2.0000,  8.2000,  1.7000,  7.9000,  1.5000, 12.7000,  3.1000,\n","         10.7000,  1.1000, 11.7000,  5.2000,  6.9000, -3.6000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[11.3000,  4.7000],\n","        [ 3.2000, -4.4000]], dtype=torch.float64)\n","input:\n","tensor([[20.6000, 10.7000, 20.2000,  8.7000, 18.1000,  8.2000, 21.5000,  9.9000,\n","         24.1000, 11.6000, 25.5000, 13.4000, 25.3000, 13.8000],\n","        [22.1000, 13.6000, 23.4000, 13.9000, 24.3000, 18.4000, 20.8000, 15.8000,\n","         30.8000, 16.6000, 21.7000, 15.3000, 17.4000, 10.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[21.1000, 14.4000],\n","        [16.7000, 10.5000]], dtype=torch.float64)\n","input:\n","tensor([[23.0000, 14.9000, 27.4000, 13.5000, 23.7000, 13.3000, 18.6000, 14.9000,\n","         22.3000, 15.2000, 19.0000, 15.7000, 24.8000, 15.8000],\n","        [25.5000, 14.7000, 24.4000, 17.3000, 27.2000, 16.3000, 25.5000, 15.3000,\n","         22.5000, 12.2000, 26.2000, 13.6000, 29.9000, 17.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.2000, 17.6000],\n","        [22.5000, 14.1000]], dtype=torch.float64)\n","input:\n","tensor([[ -6.8000, -12.4000,  -9.1000, -12.4000,  -3.7000,  -9.3000,  -1.3000,\n","          -5.2000,  -1.5000, -17.8000,  -7.7000, -21.5000,  -5.7000, -19.7000],\n","        [ 22.8000,  17.5000,  24.2000,  15.4000,  22.8000,  14.0000,  24.2000,\n","          12.6000,  24.4000,  15.7000,  21.2000,  15.1000,  22.0000,  13.8000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[-19.2000, -25.1000],\n","        [ 23.3000,  15.6000]], dtype=torch.float64)\n","input:\n","tensor([[10.9000,  1.9000,  6.2000,  0.4000, 15.0000,  5.4000, 18.0000,  9.3000,\n","         17.9000,  8.9000, 17.6000,  9.0000, 15.3000, 11.1000],\n","        [23.6000, 14.8000, 25.1000, 15.1000, 27.5000, 17.1000, 25.8000, 17.4000,\n","         26.8000, 19.7000, 26.2000, 18.5000, 24.2000, 17.5000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[12.4000,  4.7000],\n","        [26.0000, 16.8000]], dtype=torch.float64)\n","input:\n","tensor([[10.0000,  1.1000, 11.0000,  0.4000, 11.9000,  3.5000,  9.3000,  6.1000,\n","         15.9000,  8.0000, 14.6000,  6.2000, 17.0000,  6.5000],\n","        [15.2000,  2.9000, 13.2000,  6.5000, 18.4000,  6.2000, 15.2000,  3.7000,\n","         16.3000,  6.0000, 19.7000,  7.6000,  9.7000,  5.2000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[15.1000,  7.0000],\n","        [19.3000,  7.5000]], dtype=torch.float64)\n","input:\n","tensor([[ -4.9000,  -9.1000,  -9.0000, -14.3000,  -4.3000, -14.7000,  -1.1000,\n","          -5.1000,   4.0000,  -7.0000,  -7.0000, -17.0000,  -7.1000, -12.7000],\n","        [  6.7000,   1.8000,   6.9000,   2.1000,   2.2000,  -6.5000,   2.7000,\n","          -6.3000,   6.0000,   1.8000,   4.4000,   2.1000,   5.0000,   0.7000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -7.4000, -13.3000],\n","        [  2.0000, -10.2000]], dtype=torch.float64)\n","input:\n","tensor([[ -2.6000, -12.3000,   4.5000,  -3.7000,   6.8000,   2.9000,   9.3000,\n","         -11.1000,  -6.6000, -15.3000,  -3.7000, -10.9000,  -8.8000, -13.9000],\n","        [ 23.0000,  10.8000,  18.0000,  12.1000,  27.9000,  12.6000,  26.8000,\n","          15.9000,  27.3000,  16.1000,  34.2000,  20.1000,  27.7000,  13.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ -4.2000, -14.8000],\n","        [ 19.6000,  13.0000]], dtype=torch.float64)\n","input:\n","tensor([[13.4000,  6.3000, 11.2000,  8.1000,  8.9000,  6.7000, 15.8000,  8.2000,\n","         12.3000,  7.5000, 19.9000,  6.7000, 17.0000, 10.2000],\n","        [23.1000, 13.2000, 23.3000, 15.4000, 24.3000, 13.4000, 23.9000, 14.7000,\n","         23.2000, 15.9000, 19.3000, 14.3000, 18.1000, 13.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[10.7000,  7.9000],\n","        [23.5000, 13.7000]], dtype=torch.float64)\n","input:\n","tensor([[  4.3000,  -1.3000,   2.8000,  -2.5000,   3.4000,  -5.7000,  -4.3000,\n","          -8.9000,  -1.9000,  -9.5000,   1.1000,  -8.4000,  -3.0000, -10.6000],\n","        [ 30.7000,  21.9000,  33.5000,  22.0000,  27.9000,  19.5000,  28.2000,\n","          18.0000,  28.0000,  19.6000,  26.9000,  20.0000,  27.5000,  19.9000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[ 4.8000, -7.2000],\n","        [28.2000, 18.6000]], dtype=torch.float64)\n","input:\n","tensor([[15.9000, 10.0000, 27.3000, 15.9000, 28.9000, 19.0000, 29.0000, 18.1000,\n","         26.9000, 17.7000, 22.8000, 10.1000, 18.5000,  8.2000],\n","        [23.1000, 13.8000, 23.5000, 14.9000, 22.8000, 15.1000, 24.9000, 14.4000,\n","         27.4000, 15.8000, 29.0000, 19.0000, 27.7000, 19.4000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[20.3000,  8.9000],\n","        [25.9000, 19.4000]], dtype=torch.float64)\n","input:\n","tensor([[29.0000, 19.3000, 30.0000, 20.5000, 29.7000, 21.0000, 32.0000, 23.7000,\n","         29.4000, 22.7000, 26.2000, 19.0000, 29.5000, 21.4000],\n","        [10.4000,  6.5000, 10.8000,  6.1000, 10.8000,  5.5000, 21.9000,  8.0000,\n","         15.1000,  9.1000, 20.0000,  9.5000, 20.5000, 11.3000]],\n","       dtype=torch.float64)\n","label:\n","tensor([[27.0000, 20.4000],\n","        [19.7000, 13.5000]], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W1fUoKpTGqhg","colab_type":"text"},"source":["# RNN TRAINING"]},{"cell_type":"code","metadata":{"id":"0UsnHGtx-C7T","colab_type":"code","colab":{}},"source":["import os \n","from torch.utils.data.sampler import SubsetRandomSampler \n","from torchvision import datasets, models, transforms \n","import torch.optim as optim\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import time \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F \n","import torch.optim \n","import torchvision\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms \n","use_cuda = True\n","\n","#we prolly need cuda? to speed things up?"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XI2FLi3MH0WB","colab_type":"text"},"source":["### Helper functions"]},{"cell_type":"code","metadata":{"id":"ONCyrYs_WWrJ","colab_type":"code","colab":{}},"source":["def get_model_name(name, batch_size, learning_rate, epoch):\n","    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n","\n","    Args:\n","        config: Configuration object containing the hyperparameters\n","    Returns:\n","        path: A string with the hyperparameter name and value concatenated\n","    \"\"\"\n","    path = \"/content/gdrive/My Drive/APS360 Team/milestone 2/Checkpoints/weatherANNmodel_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n","                                                   batch_size,\n","                                                   learning_rate,\n","                                                   epoch)\n","    return path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CNR8AhHEG1GW","colab_type":"code","colab":{}},"source":["# not sure if this is needed\n","\n","def normalize_label(labels):\n","    \"\"\"\n","    Given a tensor containing 2 possible values, normalize this to 0/1\n","\n","    Args:\n","        labels: a 1D tensor containing two possible scalar values\n","    Returns:\n","        A tensor normalize to 0/1 value\n","    \"\"\"\n","    max_val = torch.max(labels)\n","    min_val = torch.min(labels)\n","    norm_labels = (labels - min_val)/(max_val - min_val)\n","    return norm_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vN8kmhoYWmkX","colab_type":"code","colab":{}},"source":["def plot_training_curve(path):\n","    \"\"\" Plots the training curve for a model run, given the csv files\n","    containing the train/validation error/loss.\n","\n","    Args:\n","        path: The base path of the csv files produced during training\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n","    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n","    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n","    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n","    plt.title(\"Train vs Validation Error\")\n","    n = len(train_err) # number of epochs\n","    plt.plot(range(1,n+1), train_err, label=\"Train\")\n","    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Error\")\n","    plt.legend(loc='best')\n","    plt.show()\n","    plt.title(\"Train vs Validation Loss\")\n","    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n","    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend(loc='best')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tFwGlaGWYPfF","colab_type":"text"},"source":["### Visualization of data"]},{"cell_type":"code","metadata":{"id":"3OC-YCWJYTGc","colab_type":"code","colab":{}},"source":["# laterrrrrrr"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HNtkFHU4H2ki","colab_type":"text"},"source":["### Architecture"]},{"cell_type":"code","metadata":{"id":"1S3PSjCvKYZQ","colab_type":"code","colab":{}},"source":["import logging\n","import datetime\n","\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt\n","import matplotlib\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvZ6ZzICYdkP","colab_type":"code","colab":{}},"source":["class weatherRNN(nn.Module):\n","\n","    def __init__(self, hidden_size = 10, input_size = 2, output_size = 2, n_layers = 1): #,dropout=DROPOUT\n","        super(weatherRNN, self).__init__()\n","        self.name = \"weatherRNN\"\n","        self.rnn = nn.RNN(input_size, hidden_size, n_layers, batch_first=True) # there is RNN, GRU, LSTM\n","        self.decoder = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, inp,  hidden = None):\n","        if(hidden == None):\n","          out, _ = self.rnn(inp)\n","        else:\n","          out, _ = self.rnn(inp, hidden)\n","        out = self.decoder(out[:, -1, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fASHMJdunwJo","colab_type":"code","colab":{}},"source":["# # hmmmm -> should seqlen be the number of inputs we put in? tbh a lil confused\n","# # input size will always be 14, output size will always be 2 \n","# # not sure what n_layers does but thats fine\n","# # dont think we utilize dropout either\n","# class weatherRNN(nn.Module):\n","\n","#     def __init__(self, input_size = 14, hidden_size = 30, output_size = 2, n_layers = 1): #,dropout=DROPOUT\n","#         super(weatherRNN, self).__init__()\n","#         self.input_size = input_size\n","#         self.hidden_size = hidden_size\n","#         self.output_size = output_size\n","#         self.n_layers = n_layers\n","\n","#         #self.encoder = nn.Embedding(input_size, hidden_size) # has nothing to do with \"word embeddings\" -> just indicate non linearity\n","#         # this is a drop out layer to prevent overfitting - we can get rid of it if we wanted to\n","#         #self.m = nn.Sequential(nn.ReLU(), nn.Dropout(p=0.2), nn.ReLU())\n","#         # encoder - converting back\n","#         self.rnn = nn.RNN(input_size, hidden_size, n_layers, batch_first=True) # there is RNN, GRU, LSTM\n","#         self.decoder = nn.Linear(hidden_size, output_size)\n","\n","#     def forward(self, inp,  hidden=None):\n","#         # Look up the embedding\n","#         # inp = self.emb(inp)\n","#         # inp = self.encoder(inp)\n","\n","#         # Set an initial hidden state and cell state\n","#         # h0 = num_layers * num_directions, batch, hidden_size\n","#         # NOT BI DIRECTIONAL: so num_directions = 1\n","#         # batch == size of the input\n","#         # hidden_size == predefined hidden size\n","#         print(inp.size())\n","#         print(self.n_layers)\n","#         print(len(inp))\n","#         print(self.hidden_size)\n","        \n","#         #h0 = torch.zeros((self.n_layers)*1, inp.size(0), self.hidden_size)\n","#         # h0 = torch.zeros((self.n_layers)*1, len(inp), self.hidden_size)\n","        \n","#         # print(h0.size())\n","\n","#         # Forward propagate the rnn\n","#         out, _ = self.rnn(inp, hidden)\n","#         # Pass the output of the last time step to the classifier\n","#         output = self.decoder(output)\n","#         return out\n","#         # don't need the hidden state yet"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aelxiMuMH67H","colab_type":"text"},"source":["### Training"]},{"cell_type":"code","metadata":{"id":"roN8PIZHq6KQ","colab_type":"code","colab":{}},"source":["import os \n","from torch.utils.data.sampler import SubsetRandomSampler \n","from torchvision import datasets, models, transforms \n","import torch.optim as optim\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import time \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F \n","import torch.optim \n","import torchvision\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JsECm8ErxlPu","colab_type":"code","colab":{}},"source":["# Error defined as prediction being off more than 5°C\n","def compute_error(outputs, labels):\n","  err = 0.0\n","  number_items = 0\n","  for j, out in enumerate(outputs, 0):\n","      err += (abs(labels[j][0] - out[0]) > 5)\n","      err += (abs(labels[j][1] - out[1]) > 5)\n","      number_items += 2\n","\n","  return err, number_items"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRWr7XFXrO9S","colab_type":"code","colab":{}},"source":["# Error defined as mean difference of prediction and reallity\n","def compute_error(outputs, labels):\n","  err = 0.0\n","  number_items = 0\n","  for j, out in enumerate(outputs, 0):\n","      err += abs(labels[j][0] - out[0])\n","      err += abs(labels[j][1] - out[1])\n","      number_items += 2\n","\n","  return err, number_items"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgTTXXfYHS9C","colab_type":"code","colab":{}},"source":["def get_accuracy(net, loader, criterion):\n","\n","    total_loss = 0.0\n","    total_err = 0.0\n","    number_items = 0\n","\n","    for i, data in enumerate(loader, 0):\n","      inputs, labels = data\n","      inputs = inputs.view(inputs.shape[0], int(inputs.shape[1]/2), 2) #########\n","      #############################################\n","      #To Enable GPU Usage\n","      if use_cuda and torch.cuda.is_available():\n","        inputs = inputs.cuda()\n","        labels = labels.cuda()\n","      #############################################\n","      outputs = net(inputs.float())\n","      loss = criterion(outputs, labels.float()) \n","      total_loss += loss.item()\n","      \n","      cur_err, cur_num = compute_error(outputs, labels)\n","      total_err += cur_err\n","      number_items += cur_num\n","    err = float(total_err) / number_items\n","    loss = float(total_loss) / (i + 1)\n","    return err, loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBaJ-UAdHIZE","colab_type":"code","colab":{}},"source":["use_cuda = True\n","def train_rnn_network(net, trainingSet, validationSet, num_epochs, batch_size, learning_rate):\n","    criterion = nn.MSELoss() #criterion = nn.CrossEntropyLoss() We are doing regression not classification\n","    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","\n","    train_loader = torch.utils.data.DataLoader(trainingSet, batch_size=batch_size, \n","                                            num_workers=1, shuffle=True)\n","    val_loader = torch.utils.data.DataLoader(validationSet, batch_size=batch_size, \n","                                            num_workers=1, shuffle=True)\n","\n","     # Set up some numpy arrays to store the training/test loss/erruracy\n","    train_err = np.zeros(num_epochs)\n","    train_loss = np.zeros(num_epochs)\n","    val_err = np.zeros(num_epochs)\n","    val_loss = np.zeros(num_epochs)\n","    ########################################################################\n","    # Train the network\n","    # Loop over the data iterator and sample a new batch of training data\n","    # Get the output from the network, and optimize our loss function.\n","    start_time = time.time()\n","    print (\"Training Started...\")\n","    for epoch in range(num_epochs):  # loop over the dataset multiple times\n","        total_train_loss = 0.0\n","        total_train_err = 0.0\n","        number_items = 0\n","        for i, data in enumerate(train_loader, 0): # Itterate through each batch\n","            #print(\"Training\", i, \"out of\", len(train_loader))\n","            # Get the inputs\n","            inputs, labels = data\n","            inputs = inputs.view(inputs.shape[0], int(inputs.shape[1]/2), 2) ########### batch_size, number of mini RNNs, input to each mini RNN\n","\n","            #############################################\n","            #To Enable GPU Usage\n","            if use_cuda and torch.cuda.is_available():\n","              inputs = inputs.cuda()\n","              labels = labels.cuda()\n","            #############################################\n","            \n","              \n","            outputs = net(inputs.float())             # forward pass\n","            loss = criterion(outputs, labels.float()) # compute the total loss\n","            loss.backward()               # backward pass (compute parameter updates)\n","            optimizer.step()              # make the updates for each parameter\n","            optimizer.zero_grad()         # a clean up step for PyTorch\n","\n","            # Calculate the statistics\n","            total_train_loss += loss.item()\n","\n","            cur_err, cur_num = compute_error(outputs, labels)\n","            total_train_err += cur_err\n","            number_items += cur_num\n","             \n","\n","        train_err[epoch] = float(total_train_err) / number_items\n","        train_loss[epoch] = float(total_train_loss) / (i+1)\n","        val_err[epoch], val_loss[epoch] = get_accuracy(net, val_loader, criterion)\n","        \n","        print((\"Epoch {}: Train err: {}, Train loss: {} |\"\n","              + \"Validation err: {}, Validation loss: {}\"\n","                ).format(\n","                    epoch + 1,\n","                    train_err[epoch],\n","                    train_loss[epoch],\n","                    val_err[epoch],\n","                    val_loss[epoch]))\n","        # Save the current model (checkpoint) to a file\n","        model_path = get_model_name(net.name, batch_size, learning_rate, epoch + 1)\n","        #print(model_path) #for debugging the path smh\n","        #torch.save(net.state_dict(), model_path)\n","    print('Finished Training')\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n","\n","    # Write the train/test loss/err into CSV file for plotting later\n","    \n","    epochs = np.arange(1, num_epochs + 1)\n","    np.savetxt(\"{}_train_err.csv\".format(model_path), train_err)\n","    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n","    np.savetxt(\"{}_val_err.csv\".format(model_path), val_err)\n","    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IMQxhixt3Hvd","colab_type":"code","outputId":"1ab149ef-0d84-4157-c4a5-85c42b398c2c","executionInfo":{"status":"ok","timestamp":1584440001384,"user_tz":240,"elapsed":412297,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":833}},"source":["weather_rnn = weatherRNN(hidden_size=10)\n","if use_cuda:\n","  weather_rnn = weather_rnn.cuda()\n","train_rnn_network(weather_rnn, trainingSet=trainingSet, validationSet=validationSet, batch_size=40, learning_rate=0.004, num_epochs=45)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train err: 10.565822458156598, Train loss: 173.43346421614936 |Validation err: 9.203603341982777, Validation loss: 138.42288368626646\n","Epoch 2: Train err: 8.292866024714796, Train loss: 112.61832390660825 |Validation err: 7.510839763753643, Validation loss: 94.76374314960681\n","Epoch 3: Train err: 6.782585699764736, Train loss: 77.05108033055845 |Validation err: 6.208488131760728, Validation loss: 68.06394456562244\n","Epoch 4: Train err: 5.678963011516299, Train loss: 54.351784291474715 |Validation err: 5.31032731653414, Validation loss: 46.845725511249746\n","Epoch 5: Train err: 4.850625502605458, Train loss: 39.70856689370197 |Validation err: 4.577280796019367, Validation loss: 33.96857080961529\n","Epoch 6: Train err: 4.223751433624725, Train loss: 30.10147109238998 |Validation err: 4.015419841560145, Validation loss: 26.067018860264827\n","Epoch 7: Train err: 3.738049936467026, Train loss: 23.551917470019795 |Validation err: 3.6226304521286963, Validation loss: 21.236365870425576\n","Epoch 8: Train err: 3.400608422695325, Train loss: 19.416989554529604 |Validation err: 3.318842819051405, Validation loss: 17.91053581237793\n","Epoch 9: Train err: 3.1669910730026736, Train loss: 16.679868698120117 |Validation err: 3.130799529554109, Validation loss: 15.542833980761076\n","Epoch 10: Train err: 2.999622088390635, Train loss: 14.868517865305362 |Validation err: 3.011072656411957, Validation loss: 14.209171345359401\n","Epoch 11: Train err: 2.8786083345690905, Train loss: 13.695280583008476 |Validation err: 2.8824960897270024, Validation loss: 13.248722678736636\n","Epoch 12: Train err: 2.819150134568504, Train loss: 13.078123429547185 |Validation err: 2.815584627369572, Validation loss: 13.67182069075735\n","Epoch 13: Train err: 2.731108410950988, Train loss: 12.29638359339341 |Validation err: 2.7070893274083456, Validation loss: 11.778171639693412\n","Epoch 14: Train err: 2.6748061291422536, Train loss: 11.799183741859768 |Validation err: 2.714764758176439, Validation loss: 11.489283360933003\n","Epoch 15: Train err: 2.659735649932583, Train loss: 11.707625834838204 |Validation err: 2.633584496251116, Validation loss: 11.362217426300049\n","Epoch 16: Train err: 2.60248298114692, Train loss: 11.281910118849382 |Validation err: 2.6172933001845817, Validation loss: 11.092273335707816\n","Epoch 17: Train err: 2.5830341131475953, Train loss: 11.106684223465297 |Validation err: 2.586358490683836, Validation loss: 11.140597845378675\n","Epoch 18: Train err: 2.56348708945189, Train loss: 10.967401229816934 |Validation err: 2.5727903989698, Validation loss: 11.024584720009251\n","Epoch 19: Train err: 2.5528660907848235, Train loss: 10.871196207792863 |Validation err: 2.557607594153034, Validation loss: 10.585601932124087\n","Epoch 20: Train err: 2.537979558282435, Train loss: 10.912188141242318 |Validation err: 2.55022498403842, Validation loss: 10.800825721339175\n","Epoch 21: Train err: 2.517282657792001, Train loss: 10.679663513017738 |Validation err: 2.5419933147230362, Validation loss: 10.410443004808927\n","Epoch 22: Train err: 2.5082100393186217, Train loss: 10.835458796957266 |Validation err: 2.539892611076558, Validation loss: 10.417907890520597\n","Epoch 23: Train err: 2.500839403032451, Train loss: 10.549214186875716 |Validation err: 2.494457207084966, Validation loss: 10.063395374699644\n","Epoch 24: Train err: 2.4782459152657057, Train loss: 10.373929821926614 |Validation err: 2.5079398239384387, Validation loss: 10.493904364736457\n","Epoch 25: Train err: 2.478613622654703, Train loss: 10.401157622751983 |Validation err: 2.500007539850163, Validation loss: 10.079876447978773\n","Epoch 26: Train err: 2.463842134916612, Train loss: 10.20942144808562 |Validation err: 2.485998932920386, Validation loss: 9.9489635166369\n","Epoch 27: Train err: 2.4538916019934334, Train loss: 10.287399675535118 |Validation err: 2.5162418239619004, Validation loss: 10.089989750008835\n","Epoch 28: Train err: 2.4602969497267866, Train loss: 10.314075889794722 |Validation err: 2.4894630540730818, Validation loss: 11.070430253681383\n","Epoch 29: Train err: 2.445318798511583, Train loss: 10.26988787236421 |Validation err: 2.473280933848335, Validation loss: 10.124962580831427\n","Epoch 30: Train err: 2.449204524172836, Train loss: 10.190914071124533 |Validation err: 2.4861858909088324, Validation loss: 10.353187460648385\n","Epoch 31: Train err: 2.4495921314585525, Train loss: 10.141827303430308 |Validation err: 2.464837458885007, Validation loss: 9.943404574143258\n","Epoch 32: Train err: 2.4274464691575153, Train loss: 10.053313991297847 |Validation err: 2.455948132180354, Validation loss: 10.075884919417533\n","Epoch 33: Train err: 2.4352731917126342, Train loss: 10.091587040735329 |Validation err: 2.4863751763583553, Validation loss: 10.671756142064146\n","Epoch 34: Train err: 2.426472761640713, Train loss: 9.983048604882281 |Validation err: 2.469525544350188, Validation loss: 11.166110440304404\n","Epoch 35: Train err: 2.4289975788545783, Train loss: 10.091712863548942 |Validation err: 2.45604147796754, Validation loss: 9.894406619824862\n","Epoch 36: Train err: 2.4244037901778657, Train loss: 10.029562716898711 |Validation err: 2.477832638189615, Validation loss: 9.93839336696424\n","Epoch 37: Train err: 2.4247035446267704, Train loss: 10.072666023088539 |Validation err: 2.4742096868238455, Validation loss: 10.125272399500796\n","Epoch 38: Train err: 2.424800966350094, Train loss: 9.967558648275292 |Validation err: 2.4930910759488243, Validation loss: 10.856608516291567\n","Epoch 39: Train err: 2.4144350262591403, Train loss: 9.980175334474314 |Validation err: 2.45932731693821, Validation loss: 10.07632549185502\n","Epoch 40: Train err: 2.428096893027597, Train loss: 10.005427370900692 |Validation err: 2.4588440336242368, Validation loss: 9.727017252068771\n","Epoch 41: Train err: 2.414261679740956, Train loss: 9.923196885896767 |Validation err: 2.4972240494315994, Validation loss: 10.379049326244154\n","Epoch 42: Train err: 2.4292705934252923, Train loss: 10.026046804759813 |Validation err: 2.4469595518706857, Validation loss: 9.914366772300319\n","Epoch 43: Train err: 2.4154644725538073, Train loss: 10.06231261336285 |Validation err: 2.441562492268159, Validation loss: 9.90934389515927\n","Epoch 44: Train err: 2.407549172521052, Train loss: 9.866281872210296 |Validation err: 2.4854125305000343, Validation loss: 10.516827533119603\n","Epoch 45: Train err: 2.437517732579358, Train loss: 10.16577923297882 |Validation err: 2.444200211378659, Validation loss: 9.71458689790023\n","Finished Training\n","Total time elapsed: 356.05 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zny0LpUfUruX","colab_type":"code","outputId":"4131da53-c035-471d-9652-c2b476776bc9","executionInfo":{"status":"ok","timestamp":1584440002140,"user_tz":240,"elapsed":413043,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["model_path = get_model_name(\"weatherRNN\", batch_size=40, learning_rate=0.004, epoch=45)\n","\n","plot_training_curve(model_path)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEgfhYKIiPRRKIiISB+FgoiI9Pl/Isb6BmPvFTgAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dui5IqT59_z9","colab_type":"code","outputId":"11f4c212-d204-494c-b167-52e84198d1f2","executionInfo":{"status":"ok","timestamp":1584440352862,"user_tz":240,"elapsed":763756,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":833}},"source":["weather_rnn = weatherRNN(hidden_size=10)\n","if use_cuda:\n","  weather_rnn = weather_rnn.cuda()\n","train_rnn_network(weather_rnn, trainingSet=trainingSet, validationSet=validationSet, batch_size=30, learning_rate=0.002, num_epochs=45)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train err: 10.771596886132487, Train loss: 178.10545330360287 |Validation err: 9.738159499409125, Validation loss: 148.85680572509764\n","Epoch 2: Train err: 9.077857154801901, Train loss: 132.244987581597 |Validation err: 8.403198283366645, Validation loss: 115.23415802001954\n","Epoch 3: Train err: 7.842953391781857, Train loss: 101.17680321365107 |Validation err: 7.348178398015589, Validation loss: 91.53627304077149\n","Epoch 4: Train err: 6.864189434598356, Train loss: 78.52755640373856 |Validation err: 6.481080801712857, Validation loss: 70.67967620849609\n","Epoch 5: Train err: 6.073102431349945, Train loss: 61.84879216991487 |Validation err: 5.770605785767566, Validation loss: 55.94275955200195\n","Epoch 6: Train err: 5.415275850809238, Train loss: 49.457139624923954 |Validation err: 5.188243495511151, Validation loss: 44.98489494323731\n","Epoch 7: Train err: 4.866677581486601, Train loss: 39.92591488947634 |Validation err: 4.659173428586354, Validation loss: 35.45926622390747\n","Epoch 8: Train err: 4.417139773222032, Train loss: 32.86655340038362 |Validation err: 4.276805276011145, Validation loss: 30.10931999206543\n","Epoch 9: Train err: 4.0352406886829755, Train loss: 27.428528035273317 |Validation err: 3.9341421147929525, Validation loss: 25.870152130126954\n","Epoch 10: Train err: 3.7309998318642883, Train loss: 23.345093750562825 |Validation err: 3.6680300250587616, Validation loss: 22.0502840423584\n","Epoch 11: Train err: 3.4762512365628204, Train loss: 20.19604423397877 |Validation err: 3.4397194570525547, Validation loss: 19.49840549468994\n","Epoch 12: Train err: 3.2866463519424394, Train loss: 17.963467214928297 |Validation err: 3.2642236276918317, Validation loss: 16.82259895324707\n","Epoch 13: Train err: 3.1264682628458202, Train loss: 16.203047224732696 |Validation err: 3.156347836580843, Validation loss: 15.616010227203368\n","Epoch 14: Train err: 3.007836349896198, Train loss: 14.941719868144052 |Validation err: 3.019856672168273, Validation loss: 14.27670066833496\n","Epoch 15: Train err: 2.905459410767381, Train loss: 13.953599378710887 |Validation err: 2.909583425455897, Validation loss: 13.444804573059082\n","Epoch 16: Train err: 2.8347449254980894, Train loss: 13.253201328340124 |Validation err: 2.8501632387872218, Validation loss: 12.866896762847901\n","Epoch 17: Train err: 2.77524067492688, Train loss: 12.69603006175307 |Validation err: 2.7970788912571973, Validation loss: 12.296248664855957\n","Epoch 18: Train err: 2.719743090230427, Train loss: 12.256714523815718 |Validation err: 2.7386222393928232, Validation loss: 12.091998558044434\n","Epoch 19: Train err: 2.692331807383737, Train loss: 11.942344477919281 |Validation err: 2.713200661258359, Validation loss: 12.070601234436035\n","Epoch 20: Train err: 2.656313502294289, Train loss: 11.66363015722056 |Validation err: 2.7057706208067485, Validation loss: 11.688063793182373\n","Epoch 21: Train err: 2.6306819458581847, Train loss: 11.455822823477574 |Validation err: 2.6562953625147436, Validation loss: 11.341052188873292\n","Epoch 22: Train err: 2.6096009400818803, Train loss: 11.270879612594355 |Validation err: 2.6321679241209877, Validation loss: 11.370488376617432\n","Epoch 23: Train err: 2.5904225869852517, Train loss: 11.12861825599045 |Validation err: 2.6108285806815483, Validation loss: 10.99609354019165\n","Epoch 24: Train err: 2.5692047505638973, Train loss: 10.99909188708321 |Validation err: 2.5833946959798704, Validation loss: 10.876074466705322\n","Epoch 25: Train err: 2.550863201132334, Train loss: 10.878541887783614 |Validation err: 2.5937265987218168, Validation loss: 10.745735368728639\n","Epoch 26: Train err: 2.531133619243201, Train loss: 10.772099713810155 |Validation err: 2.5617397116839804, Validation loss: 10.680044574737549\n","Epoch 27: Train err: 2.5269049784937296, Train loss: 10.671003736433436 |Validation err: 2.5351026002412134, Validation loss: 10.462324447631836\n","Epoch 28: Train err: 2.501050165000247, Train loss: 10.549519179297276 |Validation err: 2.533491544450907, Validation loss: 10.551937427520752\n","Epoch 29: Train err: 2.4945108670626195, Train loss: 10.477484351298848 |Validation err: 2.5041257480285637, Validation loss: 10.072113194465636\n","Epoch 30: Train err: 2.4908633356350265, Train loss: 10.459571623411335 |Validation err: 2.4917506703889662, Validation loss: 10.148214530944824\n","Epoch 31: Train err: 2.4838350828091955, Train loss: 10.430086366465835 |Validation err: 2.510960947357053, Validation loss: 10.280889339447022\n","Epoch 32: Train err: 2.4730681032143997, Train loss: 10.335871239177516 |Validation err: 2.4783831504150813, Validation loss: 10.064184741973877\n","Epoch 33: Train err: 2.4687951664560375, Train loss: 10.348235419539154 |Validation err: 2.4771858812477685, Validation loss: 10.024020175933838\n","Epoch 34: Train err: 2.455740097180366, Train loss: 10.184945681056039 |Validation err: 2.481793697760258, Validation loss: 10.0241455078125\n","Epoch 35: Train err: 2.4503069791296417, Train loss: 10.148757098151036 |Validation err: 2.4559915681542646, Validation loss: 9.899529247283935\n","Epoch 36: Train err: 2.4487171596619453, Train loss: 10.229981242633256 |Validation err: 2.460210241604752, Validation loss: 10.43610496520996\n","Epoch 37: Train err: 2.4358696668468234, Train loss: 10.109428151709135 |Validation err: 2.4684155649773922, Validation loss: 10.370111865997314\n","Epoch 38: Train err: 2.448238935146783, Train loss: 10.188822804904374 |Validation err: 2.4622448959071384, Validation loss: 9.972763919830323\n","Epoch 39: Train err: 2.4369282362011644, Train loss: 10.088935406481633 |Validation err: 2.480023572152526, Validation loss: 10.046484622955322\n","Epoch 40: Train err: 2.4333116443989526, Train loss: 10.066300220176823 |Validation err: 2.483574920516236, Validation loss: 10.439211978912354\n","Epoch 41: Train err: 2.4392490244463216, Train loss: 10.102042972064408 |Validation err: 2.467744505688473, Validation loss: 9.813535804748534\n","Epoch 42: Train err: 2.429881206199507, Train loss: 10.063160188862534 |Validation err: 2.4539344709265234, Validation loss: 10.74157859802246\n","Epoch 43: Train err: 2.434062619829095, Train loss: 10.097307455344279 |Validation err: 2.447486876355936, Validation loss: 10.144449043273926\n","Epoch 44: Train err: 2.4394432944780866, Train loss: 10.1008695618051 |Validation err: 2.4523804534630265, Validation loss: 9.988766937255859\n","Epoch 45: Train err: 2.408366133600969, Train loss: 9.953394440353893 |Validation err: 2.4812121163210383, Validation loss: 10.064599742889405\n","Finished Training\n","Total time elapsed: 348.02 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E_LEhPi94nbD","colab_type":"code","outputId":"7bd7bf12-9e94-46ce-dd37-b8ef7ecb59ee","executionInfo":{"status":"ok","timestamp":1584440353151,"user_tz":240,"elapsed":764036,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["model_path = get_model_name(\"weatherRNN\", batch_size=30, learning_rate=0.002, epoch=45)\n","\n","plot_training_curve(model_path)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"8qO-SYVnH8um","colab_type":"text"},"source":["### Tuning"]},{"cell_type":"code","metadata":{"id":"VPYOB0CJH_BQ","colab_type":"code","outputId":"5ae29559-57b0-4a27-8ae1-330de521b855","executionInfo":{"status":"ok","timestamp":1584440673178,"user_tz":240,"elapsed":1084048,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":748}},"source":["weather_rnn = weatherRNN(hidden_size=20)\n","if use_cuda:\n","  weather_rnn = weather_rnn.cuda()\n","train_rnn_network(weather_rnn, trainingSet=trainingSet, validationSet=validationSet, batch_size=30, learning_rate=0.0001, num_epochs=40)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train err: 12.621230393921772, Train loss: 233.84865701394003 |Validation err: 12.321008706625777, Validation loss: 228.49370544433594\n","Epoch 2: Train err: 12.317096496601568, Train loss: 224.40606014064102 |Validation err: 11.992912295368987, Validation loss: 224.35908752441406\n","Epoch 3: Train err: 11.956084213081809, Train loss: 212.58286785688557 |Validation err: 11.6315644889498, Validation loss: 206.28106872558592\n","Epoch 4: Train err: 11.572250790276641, Train loss: 200.52317247234407 |Validation err: 11.260996061365118, Validation loss: 199.32449768066405\n","Epoch 5: Train err: 11.238808595299396, Train loss: 189.50173449907146 |Validation err: 10.983461115782422, Validation loss: 189.02835144042967\n","Epoch 6: Train err: 10.9894696862387, Train loss: 182.3958553877033 |Validation err: 10.764372698471675, Validation loss: 174.1953508758545\n","Epoch 7: Train err: 10.774152153740497, Train loss: 176.61333659437835 |Validation err: 10.56698230030114, Validation loss: 171.37401611328124\n","Epoch 8: Train err: 10.5768239845885, Train loss: 171.28198889435313 |Validation err: 10.384047247682055, Validation loss: 173.0158850097656\n","Epoch 9: Train err: 10.389874677956756, Train loss: 166.45809292402424 |Validation err: 10.212552648136942, Validation loss: 159.9677035522461\n","Epoch 10: Train err: 10.212572353133888, Train loss: 161.3414646836578 |Validation err: 10.046856911407259, Validation loss: 164.23077606201173\n","Epoch 11: Train err: 10.042766629769533, Train loss: 156.92223301871877 |Validation err: 9.889403895928654, Validation loss: 158.72390380859375\n","Epoch 12: Train err: 9.879924143871236, Train loss: 152.48250623609198 |Validation err: 9.740197478479002, Validation loss: 149.87723724365233\n","Epoch 13: Train err: 9.721467049568847, Train loss: 148.10558256555777 |Validation err: 9.596129425119399, Validation loss: 148.70768981933594\n","Epoch 14: Train err: 9.570984981973098, Train loss: 144.12528291295786 |Validation err: 9.455328941305025, Validation loss: 144.31129028320314\n","Epoch 15: Train err: 9.423570494386672, Train loss: 140.30235590700244 |Validation err: 9.320665027349568, Validation loss: 146.66926391601564\n","Epoch 16: Train err: 9.280710881547435, Train loss: 136.35767589631627 |Validation err: 9.18900509564461, Validation loss: 132.38465133666992\n","Epoch 17: Train err: 9.141022257702819, Train loss: 132.82834337578444 |Validation err: 9.059116877886476, Validation loss: 134.63569702148436\n","Epoch 18: Train err: 9.004716657061643, Train loss: 129.42706805369892 |Validation err: 8.932227464226868, Validation loss: 126.2570751953125\n","Epoch 19: Train err: 8.87094754923985, Train loss: 125.92300377517451 |Validation err: 8.807277382029422, Validation loss: 131.6916064453125\n","Epoch 20: Train err: 8.74104167550447, Train loss: 122.63908161100794 |Validation err: 8.684816973999574, Validation loss: 119.1464306640625\n","Epoch 21: Train err: 8.613416624244907, Train loss: 119.26105549296395 |Validation err: 8.56568741565918, Validation loss: 115.88687618255615\n","Epoch 22: Train err: 8.487170555154053, Train loss: 116.00668238030106 |Validation err: 8.447257767414177, Validation loss: 114.27890014648438\n","Epoch 23: Train err: 8.363420694064242, Train loss: 113.03592400472672 |Validation err: 8.331777344819258, Validation loss: 111.06511749267578\n","Epoch 24: Train err: 8.241422911810709, Train loss: 110.05274509992756 |Validation err: 8.218356123199761, Validation loss: 107.14720603942871\n","Epoch 25: Train err: 8.122628013746843, Train loss: 107.26911688632653 |Validation err: 8.106092217198754, Validation loss: 113.97439758300781\n","Epoch 26: Train err: 8.005391580686059, Train loss: 104.25869185025574 |Validation err: 7.994635976110051, Validation loss: 109.46926422119141\n","Epoch 27: Train err: 7.88952456622962, Train loss: 101.52017161885246 |Validation err: 7.885312712915953, Validation loss: 101.94287811279297\n","Epoch 28: Train err: 7.776095414429479, Train loss: 98.95811987704919 |Validation err: 7.776806884410469, Validation loss: 100.40441558837891\n","Epoch 29: Train err: 7.663525007595879, Train loss: 96.3532440623299 |Validation err: 7.667400395431211, Validation loss: 98.96646728515626\n","Epoch 30: Train err: 7.554177728136719, Train loss: 93.72011547401303 |Validation err: 7.561283615140829, Validation loss: 94.92276336669921\n","Epoch 31: Train err: 7.445661980108665, Train loss: 91.11474590614193 |Validation err: 7.454978731877452, Validation loss: 93.70267974853516\n","Epoch 32: Train err: 7.33808517881081, Train loss: 88.63239941831495 |Validation err: 7.349438177568537, Validation loss: 90.30400329589844\n","Epoch 33: Train err: 7.232405797352281, Train loss: 86.54956820753755 |Validation err: 7.247407494616253, Validation loss: 84.31138631820679\n","Epoch 34: Train err: 7.130296749799007, Train loss: 84.13298234783235 |Validation err: 7.145998619474149, Validation loss: 82.17872951507569\n","Epoch 35: Train err: 7.025831560598649, Train loss: 81.75310854051934 |Validation err: 7.044522978738466, Validation loss: 82.35927337646484\n","Epoch 36: Train err: 6.92647341470658, Train loss: 79.50615288781339 |Validation err: 6.946498660378437, Validation loss: 79.9755174255371\n","Epoch 37: Train err: 6.827347434060687, Train loss: 77.34768289034484 |Validation err: 6.8484207393161, Validation loss: 81.64380493164063\n","Epoch 38: Train err: 6.728657754425768, Train loss: 75.16909433583744 |Validation err: 6.752728104987085, Validation loss: 73.87082733154297\n","Epoch 39: Train err: 6.633414972782907, Train loss: 73.17447806186364 |Validation err: 6.657351128359225, Validation loss: 75.81009002685546\n","Epoch 40: Train err: 6.538659465839495, Train loss: 71.15389123510141 |Validation err: 6.564298162194046, Validation loss: 74.61017807006836\n","Finished Training\n","Total time elapsed: 317.97 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zvShZcbhBzcL","colab_type":"code","outputId":"c5fd98f1-ebb7-4e39-94ff-575e5566e312","executionInfo":{"status":"ok","timestamp":1584440673544,"user_tz":240,"elapsed":1084391,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["model_path = get_model_name(\"weatherRNN\", batch_size=30, learning_rate=0.0001, epoch=40)\n","\n","plot_training_curve(model_path)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRoNfKaXczP8DUH6KDswRzQgAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktSYFCRJzRF8G4sA0bvGxgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"ZVibyrczB0t7","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"D26_lBEKBzgK","colab_type":"code","outputId":"92b38cb5-a703-4bf3-f1f4-6300b3273052","executionInfo":{"status":"ok","timestamp":1584440981190,"user_tz":240,"elapsed":1392022,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":748}},"source":["weather_rnn = weatherRNN(hidden_size=25)\n","if use_cuda:\n","  weather_rnn = weather_rnn.cuda()\n","train_rnn_network(weather_rnn, trainingSet=trainingSet, validationSet=validationSet, batch_size=40, learning_rate=0.0001, num_epochs=40)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train err: 12.305442094830036, Train loss: 223.20819672294286 |Validation err: 12.002246112978955, Validation loss: 220.8968794973273\n","Epoch 2: Train err: 11.983035717575772, Train loss: 213.3191602955694 |Validation err: 11.671530092599317, Validation loss: 215.20281500565378\n","Epoch 3: Train err: 11.63001923527051, Train loss: 202.1333465576172 |Validation err: 11.337770260792137, Validation loss: 198.144247356214\n","Epoch 4: Train err: 11.307121889202666, Train loss: 191.7890047819718 |Validation err: 11.050326461173892, Validation loss: 186.67385984721938\n","Epoch 5: Train err: 11.014993646404761, Train loss: 183.65308446469516 |Validation err: 10.753285805148673, Validation loss: 173.2311816968416\n","Epoch 6: Train err: 10.709775063390493, Train loss: 175.37551365727964 |Validation err: 10.50483137391655, Validation loss: 166.86974174097963\n","Epoch 7: Train err: 10.487041555140605, Train loss: 168.1243661797565 |Validation err: 10.312967209537877, Validation loss: 167.91879553543893\n","Epoch 8: Train err: 10.297087838712754, Train loss: 163.76336230402407 |Validation err: 10.140306938268886, Validation loss: 168.44736119320518\n","Epoch 9: Train err: 10.123394066252605, Train loss: 159.240770008253 |Validation err: 9.979361688341548, Validation loss: 156.1051663850483\n","Epoch 10: Train err: 9.959374478177358, Train loss: 154.35146223980448 |Validation err: 9.826403774719886, Validation loss: 152.51286797774466\n","Epoch 11: Train err: 9.803037962296017, Train loss: 150.52613722759745 |Validation err: 9.68173933785053, Validation loss: 149.1854203876696\n","Epoch 12: Train err: 9.652529991117321, Train loss: 146.4699535369873 |Validation err: 9.541444987532675, Validation loss: 146.53440375077096\n","Epoch 13: Train err: 9.50739510250464, Train loss: 142.7101063106371 |Validation err: 9.404489858827732, Validation loss: 144.81232894094367\n","Epoch 14: Train err: 9.36492504406806, Train loss: 140.5070678047512 |Validation err: 9.270673001644667, Validation loss: 142.03943352950247\n","Epoch 15: Train err: 9.224952167238236, Train loss: 135.11285358926526 |Validation err: 9.13930027040899, Validation loss: 130.94528218319542\n","Epoch 16: Train err: 9.09015125251593, Train loss: 131.54914557415506 |Validation err: 9.010803308986633, Validation loss: 128.5677022432026\n","Epoch 17: Train err: 8.957864776090071, Train loss: 128.91095476565152 |Validation err: 8.885004380378579, Validation loss: 125.29003464548211\n","Epoch 18: Train err: 8.828323638323212, Train loss: 125.38072735330333 |Validation err: 8.761810887558838, Validation loss: 123.28104400634766\n","Epoch 19: Train err: 8.700778277965624, Train loss: 122.06850300664487 |Validation err: 8.640576812093702, Validation loss: 126.87721734297902\n","Epoch 20: Train err: 8.576143887353725, Train loss: 118.09981603207795 |Validation err: 8.521868238150352, Validation loss: 118.79372004458779\n","Epoch 21: Train err: 8.454698771041777, Train loss: 115.63438548212466 |Validation err: 8.406195702244666, Validation loss: 125.07167253996197\n","Epoch 22: Train err: 8.334469425895552, Train loss: 113.52974501900052 |Validation err: 8.291799921262108, Validation loss: 113.6533267372533\n","Epoch 23: Train err: 8.217023026838861, Train loss: 110.23962559907332 |Validation err: 8.180256298079799, Validation loss: 108.92997581080387\n","Epoch 24: Train err: 8.102659712227657, Train loss: 107.86720698812734 |Validation err: 8.071317134269437, Validation loss: 108.73448140997635\n","Epoch 25: Train err: 7.988809446549045, Train loss: 105.41539084393045 |Validation err: 7.9612381802552346, Validation loss: 101.33164556402909\n","Epoch 26: Train err: 7.877284739039855, Train loss: 101.70377308389415 |Validation err: 7.853039305255251, Validation loss: 101.89808193006013\n","Epoch 27: Train err: 7.7678996013692005, Train loss: 99.00744732566501 |Validation err: 7.748810597377756, Validation loss: 98.43726107948704\n","Epoch 28: Train err: 7.661307996933031, Train loss: 96.71302127838135 |Validation err: 7.643981474616345, Validation loss: 93.74182279486405\n","Epoch 29: Train err: 7.55706828363079, Train loss: 94.52630586209504 |Validation err: 7.541624972457128, Validation loss: 93.83506674515574\n","Epoch 30: Train err: 7.453116546820322, Train loss: 92.5604076385498 |Validation err: 7.438032044933011, Validation loss: 90.49427835564865\n","Epoch 31: Train err: 7.351585214121191, Train loss: 89.56117173899774 |Validation err: 7.339529003071009, Validation loss: 92.32021492405941\n","Epoch 32: Train err: 7.251899845370113, Train loss: 87.81399648085885 |Validation err: 7.23862802392879, Validation loss: 84.7840832158139\n","Epoch 33: Train err: 7.151645376846131, Train loss: 85.36906843600066 |Validation err: 7.143105648701205, Validation loss: 90.36831885889957\n","Epoch 34: Train err: 7.055618781621968, Train loss: 83.52780976502791 |Validation err: 7.047433080135705, Validation loss: 87.59715391460217\n","Epoch 35: Train err: 6.959105879037724, Train loss: 81.3928043116694 |Validation err: 6.952316459881485, Validation loss: 80.64302203529759\n","Epoch 36: Train err: 6.865806846678445, Train loss: 78.70385414621104 |Validation err: 6.859712015535491, Validation loss: 81.0429368270071\n","Epoch 37: Train err: 6.770821628602817, Train loss: 77.43972911005434 |Validation err: 6.76710012121072, Validation loss: 78.95460590563323\n","Epoch 38: Train err: 6.68046627648442, Train loss: 74.71576079078342 |Validation err: 6.675782984569359, Validation loss: 75.18121920133892\n","Epoch 39: Train err: 6.588014057859938, Train loss: 72.74700554557468 |Validation err: 6.586839077268234, Validation loss: 75.8996666356137\n","Epoch 40: Train err: 6.499952380084869, Train loss: 71.4527815943179 |Validation err: 6.499015970552858, Validation loss: 70.31706478721217\n","Finished Training\n","Total time elapsed: 305.46 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WvpPPF6LBzkL","colab_type":"code","outputId":"6c85d269-f00d-4885-d1ea-e1b8ac545755","executionInfo":{"status":"ok","timestamp":1584440981458,"user_tz":240,"elapsed":1392280,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["model_path = get_model_name(\"weatherRNN\", batch_size=40, learning_rate=0.0001, epoch=40)\n","\n","plot_training_curve(model_path)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nOzdd3QV1fbA8e9OD4QWCAESIID0GrrS\nmwIiCKKCKCAqT6zYRX22n+2JXZ8+wYIogoiAqGChCdJrgNBLgFASWkIgJKSc3x8zxCuEEEJu5ibZ\nn7Xuytwzbd9ZcPc9Z86cI8YYlFJKKQAvpwNQSinlOTQpKKWUyqJJQSmlVBZNCkoppbJoUlBKKZVF\nk4JSSqksmhSUxxCROSIyzOk48kJEJojIK/ZyBxHZlptt83iuUyJSM6/7K5UTTQrqithfUOdemSJy\nxuX9kMs5ljGmlzHmK3fFmhMRGSQiMSIi55X7iEi8iPTJ7bGMMYuNMXXzKa6FInL3eccPMsbszo/j\nn3euGBHpnt/HVYWLJgV1RewvqCBjTBCwD7jBpWzSue1ExMe5KHNlJlAW6HReeU/AAL8WeERKOUCT\ngnILEeksIrEi8pSIHAa+FJFyIvKziBwRkRP2crjLPlm/ikVkuIj8JSJv2dvuEZFeFznXUyIy7byy\n90XkA5dj7RaRJPs4F9RgjDEpwFRg6HmrhgLfGmPSReR7ETksIokiskhEGub02V3eR4rIWvv83wEB\nLusuek1E5FWgA/CRXfP6yC43InKVvVxGRCba++8VkedExOtyr2FORMRfRN4TkYP26z0R8bfXVbBj\nThCR4yKy2OX8T4nIAftzbxORbpd7blXwNCkod6oEBAPVgZFY/96+tN9XA84AH+WwfxtgG1ABeBP4\n/PzmHdsUoLeIlAIQEW/gFuBbESkJfAD0MsaUAq4B1l/kfF8BA0Uk0D5OGeAGuxxgDlAbqAisBSZl\ndxBXIuKHVQv5GutafA/c5LLJRa+JMeZZYDHwgF3zeiCbU3wIlAFqYtVyhgJ3uqzP7TXMybNAW6AZ\n0BRoDTxnr3sMiAVCgFDgGcCISF3gAaCVfd2vA2Iu87zKAZoUlDtlAi8YY1KNMWeMMceMMT8YY5KN\nMUnAq1zYXONqrzFmvDEmA+uLuTLWF88/GGP2Yn1J97eLugLJxpjlLnE0EpFAY8whY0x0diczxiwB\n4lyOcwuw3Riz3l7/hTEmyRiTCrwINLUTR07aAr7Ae8aYNGPMNGCVyzkv95pksZPfIGCMHVcM8DZw\nh8tmubqGlzAEeNkYE2+MOQK85HKONPuY1e3Pt9hYA6plAP5AAxHxNcbEGGN2XeZ5lQM0KSh3OmI3\nywAgIiVE5FO7meMksAgoa3+5ZefwuQVjTLK9GHSRbb8FBtvLt9nvMcacBm4F7gUOicgvIlIvh5gn\n8ncT0h32e0TEW0TeEJFdduwx9jYVcjgWQBXggPnnyJN7zy3k4Zq4qoCVcPa6lO0FwlzeX841zOkz\nnH+OKvbyWGAn8LvdRPe0fa6dwGis5BkvIlNEpArK42lSUO50/hC8jwF1gTbGmNJAR7v8cpszsvM9\n0Nluj++PnRQAjDG/GWN6YP2i3QqMz+E4XwPdRORqrF/555qIbgP6Ad2xmmsichn7ISDsvCabai7L\nl7omOQ1jfBTrl3r184594BIxXa6D2ZzjIIBdQ3nMGFMT6As8eu7egTHmW2NMe3tfA/wnn+NSbqBJ\nQRWkUlht5gkiEgy8kF8Htps1FmK1z+8xxmwBEJFQEeln31tIBU5hNSdd7DgxwF/AZOAPY8y5X9ql\n7P2PASWA13IZ2jIgHXhIRHxFZABWm/w5l7omcVj3C7KLNQPr5virIlJKRKoDjwLf5DK27PiKSIDL\nywfrWjwnIiEiUgF4/tw5RKSPiFxlJ71ErGajTBGpKyJd7RvSKfZnvOh1V55Dk4IqSO8BgVi/cJeT\n/908v8X6Jf+tS5kX1hflQeA4Vnv9qEsc5yusX7cTXcomYjWbHAA2Y8V/ScaYs8AAYLh9/luB6S6b\nXOqavI918/vEud5U53kQOA3sxkpm3wJf5Ca2i5iN9QV+7vUi8AqwGtgAbMS6f3Pu4bvawFysZLsM\n+NgYswDrfsIb9uc6jHVzfswVxKUKiOgkO0oppc7RmoJSSqksmhSUUkpl0aSglFIqiyYFpZRSWTx9\nkLIcVahQwURERDgdhlJKFSpr1qw5aowJyW5doU4KERERrF692ukwlFKqUBGRvRdbp81HSimlsmhS\nUEoplUWTglJKqSyF+p6CUqroSEtLIzY2lpSUlEtvrHIlICCA8PBwfH19c72PJgWllEeIjY2lVKlS\nREREcPnzAKnzGWM4duwYsbGx1KhRI9f7afORUsojpKSkUL58eU0I+UREKF++/GXXvDQpKKU8hiaE\n/JWX61ksk0LsiWRenBVNWoYO766UUq6KZVLYfPAkE5bG8OWSPU6HopTyEMeOHaNZs2Y0a9aMSpUq\nERYWlvX+7NmzOe67evVqHnrooQKK1L3cdqNZRKpiTUwSijUV3zhjzPsiMha4ATgL7ALuNMYk2PuM\nAe7Cmr3pIWPMb+6IrUeDULrVq8h7c3fQp0kVqpQNdMdplFKFSPny5Vm/fj0AL774IkFBQTz++ONZ\n69PT0/Hxyf4rs2XLlrRs2bJA4nQ3d9YU0oHHjDENsOa6vV9EGgB/AI2MMU2A7dizMdnrBgENgZ7A\nx7mcvPyyyemjvFf6W3xNKv/382Z3nEIpVQQMHz6ce++9lzZt2vDkk0+ycuVKrr76aiIjI7nmmmvY\ntm0bAAsXLqRPnz6AlVBGjBhB586dqVmzJh98kN2EeZ7LbTUFY8whrEnLMcYkicgWIMwY87vLZsuB\ngfZyP2CKMSYV2CMiO7Hmsl2W78Ht/YtSG77kl+Aortt0Hwu2VaVL3Yr5fhqlVN689FM0mw+ezNdj\nNqhSmhduaHjZ+8XGxrJ06VK8vb05efIkixcvxsfHh7lz5/LMM8/www8/XLDP1q1bWbBgAUlJSdSt\nW5dRo0Zd1rMCTiqQ5xREJAKIBFact2oE8J29HMY/572NtcvOP9ZIYCRAtWrV8hZQw/6QmUHY9JFM\nK/EGj8/04+pHryfA1y0VE6VUIXbzzTfj7W19NyQmJjJs2DB27NiBiJCWlpbtPtdffz3+/v74+/tT\nsWJF4uLiCA8PL8iw88ztSUFEgoAfgNHGmJMu5c9iNTFNupzjGWPGAeMAWrZsmfcJphsPRHxLUHfq\nMN4+/Qxf/V6Bf11/TZ4Pp5TKP3n5Re8uJUuWzFr+97//TZcuXZgxYwYxMTF07tw52338/f2zlr29\nvUlPT3d3mPnGrb2PRMQXKyFMMsZMdykfDvQBhhhjzn2xHwCquuwebpe5T73eeN3+PTW8j3DdyjvZ\nv3ubW0+nlCrcEhMTCQuzGjAmTJjgbDBu4rakINZTE58DW4wx77iU9wSeBPoaY5JddpkFDBIRfxGp\nAdQGVrorviw1O3P61mkEk0SJSb0xR7a7/ZRKqcLpySefZMyYMURGRhaqX/+XQ/7+oZ7PBxZpDywG\nNgLnnhJ7BvgA8AeO2WXLjTH32vs8i3WfIR2ruWlOTudo2bKlya9Jdn789VeuWXYPpQN88B/+I1Ru\nki/HVUrlzpYtW6hfv77TYRQ52V1XEVljjMm2D607ex/9BWT3jPXsHPZ5FXjVXTHlpM+11zFqy5v8\nX+KzVJxwPTJkGlRr40QoSinlmGL5RHN2vL2EUTf15KbU5zlOafj2ZjibfOkdlVKqCNGk4CKyWjk6\ntm7Bw6eGQUoibM+x9UoppYocTQrnefK6umzzb8Ixr/KYjd87HY5SShUoTQrnKVvCj8d7NWD62TaY\n7XMh+bjTISmlVIHRpJCNgS2qsq5sD7xMGunRM50ORymlCowmhWx4ewkDevVmZ2YVji39xulwlFIF\noEuXLvz22z8HZn7vvfcYNWpUttt37tyZc13ie/fuTUJCwgXbvPjii7z11ls5nnfmzJls3vz3wJzP\nP/88c+fOvdzw840mhYvo1iCU1aW7EXpiDWeO7nU6HKWUmw0ePJgpU6b8o2zKlCkMHjz4kvvOnj2b\nsmXL5um85yeFl19+me7du+fpWPlBk8JFiAgNr7sLgLU/j3c4GqWUuw0cOJBffvkla0KdmJgYDh48\nyOTJk2nZsiUNGzbkhRdeyHbfiIgIjh49CsCrr75KnTp1aN++fdbQ2gDjx4+nVatWNG3alJtuuonk\n5GSWLl3KrFmzeOKJJ2jWrBm7du1i+PDhTJs2DYB58+YRGRlJ48aNGTFiBKmpqVnne+GFF2jevDmN\nGzdm69at+XYdCmSU1MKqceNIdv9cnwp7ZnHs1L8pH+R/6Z2UUlduztNweGP+HrNSY+j1xkVXBwcH\n07p1a+bMmUO/fv2YMmUKt9xyC8888wzBwcFkZGTQrVs3NmzYQJMm2Y94sGbNGqZMmcL69etJT0+n\nefPmtGjRAoABAwZwzz33APDcc8/x+eef8+CDD9K3b1/69OnDwIED/3GslJQUhg8fzrx586hTpw5D\nhw7lk08+YfTo0QBUqFCBtWvX8vHHH/PWW2/x2Wef5cdV0prCpZRqdRt1ZS/fzXbLJHBKKQ/i2oR0\nrulo6tSpNG/enMjISKKjo//R1HO+xYsX079/f0qUKEHp0qXp27dv1rpNmzbRoUMHGjduzKRJk4iO\njs4xlm3btlGjRg3q1KkDwLBhw1i0aFHW+gEDBgDQokULYmJi8vqRL6A1hUsIaTuIjL9eRDZOY3/3\n7lQNLuF0SEoVfTn8onenfv368cgjj7B27VqSk5MJDg7mrbfeYtWqVZQrV47hw4eTkpKSp2MPHz6c\nmTNn0rRpUyZMmMDChQuvKNZzw3Pn99DcWlO4lKCKpFfvSF+vJbz9W/612ymlPE9QUBBdunRhxIgR\nDB48mJMnT1KyZEnKlClDXFwcc+bkPMpBx44dmTlzJmfOnCEpKYmffvopa11SUhKVK1cmLS2NSZP+\nnkamVKlSJCUlXXCsunXrEhMTw86dOwH4+uuv6dSpUz590ovTpJAL/s0HESZH2b9hIZsOJDodjlLK\njQYPHkxUVBSDBw+madOmREZGUq9ePW677TbatWuX477Nmzfn1ltvpWnTpvTq1YtWrVplrfu///s/\n2rRpQ7t27ahXr15W+aBBgxg7diyRkZHs2rUrqzwgIIAvv/ySm2++mcaNG+Pl5cW9996b/x/4PG4b\nOrsg5OfQ2TlKTcKMrc3U9I78XPUxvr5LR09VKr/p0NnucblDZ2tNITf8SyF1e9HXdwXLdhzmrx1H\nnY5IKaXcQpNCbjW5hcC0BG4stY3//LqVzMzCW8NSSqmL0aSQW7W6QWA5Hqq4no0HEvll4yGnI1Kq\nyCnMzdmeKC/X051zNFcVkQUisllEokXkYbs8WET+EJEd9t9ydrmIyAcislNENohIc3fFlic+ftDg\nRqrGL6BZqA//+XUrKWkZTkelVJEREBDAsWPHNDHkE2MMx44dIyAg4LL2c+dzCunAY8aYtSJSClgj\nIn8Aw4F5xpg3RORp4GngKaAXUNt+tQE+sf96jia3IGu+5M1GB7h2XiifLd7NA11rOx2VUkVCeHg4\nsbGxHDlyxOlQioyAgADCw8Mvax93ztF8CDhkLyeJyBYgDOgHdLY3+wpYiJUU+gETjfUzYbmIlBWR\nyvZxPEPVtlA6nDrxc+jZ8Gn+u2AXN7UIp3KZQKcjU6rQ8/X1pUaNGk6HUewVyD0FEYkAIoEVQKjL\nF/1hINReDgP2u+wWa5edf6yRIrJaRFYX+C8KLy9oPBB2zuPfXULINIbXZ+sDbUqposPtSUFEgoAf\ngNHGmJOu6+xawWU1IBpjxhljWhpjWoaEhORjpLnU+GYwGYQd/I1/dazJrKiDrIrR2dmUUkWDW5OC\niPhiJYRJxpjpdnGciFS211cG4u3yA0BVl93D7TLPUqkRVGwAaycyqlMtqpQJ4IUfo8nQLqpKqSLA\nnb2PBPgc2GKMecdl1SxgmL08DPjRpXyo3QupLZDoUfcTXF39ABzeQOCu2YzpXZ/Nh07y3ar9l95P\nKaU8nDtrCu2AO4CuIrLefvUG3gB6iMgOoLv9HmA2sBvYCYwH7nNjbFemya1QoQ7Mf4U+jSrSukYw\nY3/bSmJymtORKaXUFXFbUjDG/GWMEWNME2NMM/s12xhzzBjTzRhT2xjT3Rhz3N7eGGPuN8bUMsY0\nNsYUwKBGeeTtA12fg6PbkA3f8eINDUk8k8a7c7c7HZlSSl0RfaI5r+r3hcrNYOEbNKjoz21tqvH1\n8r1sj7twCFyllCosNCnklQh0ex4S98GaCTzWoy5B/j689FO0PpGplCq0NClciVpdIaIDLBpLOZ+z\nPNqjDkt2HuO36DinI1NKqTzRpHAlRKDbC3D6CKz4H0PaVKNuaCle+WWzjouklCqUNClcqaqtoG5v\nWPIBPqkJvNC3AbEnzvDxgp1OR6aUUpdNk0J+6PocpJ6EJe9zTa0KDGgexkcLdrJ89zGnI1NKqcui\nSSE/hDa0hr9Y8SkkHeblfo2IKF+Sh6es49ipVKejU0qpXNOkkF+6jIHMNFg0liB/Hz68LZITyWk8\n9n2UztKmlCo0NCnkl+Ca0HworJkAx/fQsEoZ/t2nAQu3HWH84t1OR6eUUrmiSSE/dXwSvHxh4esA\n3N6mGr0bV2Lsb9tYs/eEw8EppdSlaVLIT6UrQ5uRsGEqxEUjIrw+oAmVywbw0OR1OjaSUsrjaVLI\nb+1Gg38pWDQWgDKBvnw0uDnxSSk8MS1Kn3ZWSnk0TQr5rUQwtBgOm3+EE3sBaFq1LE/1rMfvm+P4\nammMo+EppVRONCm4Q5t7Qbxgxf+yiu5qX4Nu9Sry2uytbIxNdDA4pZS6OE0K7lAmDBoOgLUT4UwC\nACLCWzc3pXyQHw9MXktSit5fUEp5Hk0K7nLNA3D2FKz9KquoXEk/PhwcSeyJMzw3c5PeX1BKeRxN\nCu5Suak1guqKTyHj71pBy4hgHulemx/XH2TamlgHA1RKqQu5c47mL0QkXkQ2uZQ1E5Hl9tScq0Wk\ntV0uIvKBiOwUkQ0i0txdcRWoax6EkwcgesY/ikd1voq2NYN5/sdodh055VBwSil1IXfWFCYAPc8r\nexN4yRjTDHjefg/QC6htv0YCn7gxroJzVQ9rLuelH4JLU5G3l/DerZEE+Hrx4LfrSE3XYbaVUp7B\nnXM0LwKOn18MlLaXywAH7eV+wER7nublQFkRqeyu2AqMlxdcfT8c3gAxi/+xqlKZAN66uSmbD53k\njTlbHQpQKaX+qaDvKYwGxorIfuAtYIxdHgbsd9ku1i67gIiMtJueVh85csStweaLJoOgRAVY+tEF\nq7rVD2X4NRF8uSSGeVt0tjallPMKOimMAh4xxlQFHgE+v9wDGGPGGWNaGmNahoSE5HuA+c43AFrf\nAzt+gyPbLlg9pnc9GlQuzePfR3E4McWBAJVS6m8FnRSGAdPt5e+B1vbyAaCqy3bhdlnR0Opu8AmA\nZf+9YJW/jzcf3hZJSlomj3y3ngwdZlsp5aCCTgoHgU72cldgh708Cxhq90JqCyQaYw4VcGzuU7IC\nNB0EUVPg1IVNXrVCgnipX0OW7T7GJwt1Gk+llHPc2SV1MrAMqCsisSJyF3AP8LaIRAGvYfU0ApgN\n7AZ2AuOB+9wVl2Pa3g8ZqbDqs2xX39winL5Nq/Du3B2s2Xv+/XmllCoYUpifqm3ZsqVZvXq102Hk\n3re3QuwqeCQafAMvWJ2UkkbvDxaTmQm/PNSesiX8HAhSKVXUicgaY0zL7NbpE80F6er7IfmY1YyU\njVIBvnw4uDlHklK5b9Ja0jIyCzhApVRxp0mhIEV0gEpNrBvOmdl/4TerWpY3bmrM0l3HeHFWtI6P\npJQqUJoUCpKINfTFsR0QNfmimw1oHs69nWoxacU+Ji7bW4ABKqWKO00KBa1hf6jeDn56CLbNuehm\nT15Xl+71Q3n5580s3lEIHtJTShUJmhQKmrcvDJ4ClRrD1GGwe2G2m3l5Ce8NakbtikHcN2ktO+N1\n4DyllPtpUnBCQGm4fTqUrwWTb4P9K7PdLMjfh8+GtcTfx4u7v1pFQvLZAg5UKVXcaFJwSolguGMm\nlAqFbwbCoahsNwsvV4JP72jBwYQU7ZGklHI7TQpOKhUKQ38E/1Lwdf9sx0YCaFE9mNcHWD2SXvop\nuoCDVEoVJz5OB1Dsla0Gw2bBFz1h4o0wYg6Ui7hgs5tahLM9PolP/9xN/WAvhjQKtIbMOH0ETsfD\n6aPW8ql4qHY1tL234D+LUqrQ0yeaPUVcNEy4HvxLw4hfoXQVSD1l1R7ioyF+CyYumpP7NlAm40T2\nxwgoC14+kJIAD66FctUL9jMopQqFnJ5o1pqCpwhtCLf/AF/1hfHdwMcPTsT8vd4nEKlYj5INe/HH\n0TL8GmMoEVyZkb3aULVqdWvOBh8/OHkQ3m8Kf70LN7zn2MdRShVOmhQ8SVgLGPI9zH8FgipCsyFQ\nsQFUrA/laoCXFz5AD0A2x/HEtCimTUnkhRvSubWVLwJWDSPydlj7NXR8HMqEO/uZlFKFijYfFWJx\nJ1N4dOp6luw8Ru/GlXi9fxPKlPCFhH3wQSS0HAG9xzodplLKw+iAeEVUaOkAvh7Rhqd61uP36Dh6\nf7CYVTHHrZvXTQfDmq8g6bDTYSqlChFNCoWcl5cwqnMtpo26Bh9v4dZPl/He3O1ktHsUMtNh6YdO\nh6iUKkQ0KRQRzaqW5ZeHOnBjszDem7uD26fHc6b+AFj9hdVdVSmlckGTQhES5O/DO7c2Y+zAJqzb\nf4Lbt7XHpJ2BZR85HZpSqpBw53ScX4hIvIhsOq/8QRHZKiLRIvKmS/kYEdkpIttE5Dp3xVUc3Nyy\nKrMeaE9iyRr8lNGWs0s/JeO0TvGplLo0d9YUJgA9XQtEpAvQD2hqjGkIvGWXNwAGAQ3tfT4WEW83\nxlbk1QktxawH2rGt9r/wy0xm5ifPEX8yxemwlFIezm1JwRizCDj/5+ko4A1jTKq9Tbxd3g+YYoxJ\nNcbsAXYCrd0VW3FRws+HJ4b2J7ZSd3okzeDm93/lrx16f0EpdXEFfU+hDtBBRFaIyJ8i0souDwP2\nu2wXa5ddQERGishqEVl95IhOPpMb4f2ep7QkM9znd+74YgXvz91BZmbhfT5FKeU+BZ0UfIBgoC3w\nBDBVRORyDmCMGWeMaWmMaRkSEuKOGIueyk2hTk+Ge81mUONyvDt3O6MmreFUarrTkSmlPExBJ4VY\nYLqxrAQygQrAAaCqy3bhdpnKLx2fRM6c4LVqK/l3nwb8sTmOAR8vYe+x005HppTyIAWdFGYCXQBE\npA7gBxwFZgGDRMRfRGoAtYHspyNTeRPeAmp1Q5Z9xF2tQ5k4og1xJ1Pp+9ESvc+glMrizi6pk4Fl\nQF0RiRWRu4AvgJp2N9UpwDC71hANTAU2A78C9xtjMtwVW7HV6UlrzoU/nqd9RBCzHmhHpdIBDP1i\nBZ8t3k1hHgdLKZU/dEC84uanh2HNBGvU1V7/4XT1bjw2NYpfow8zIDKM1wY0JsBXewMrVZTpgHjq\nbze8b00B6u0H395CyR+G8HGvcjzaow7T1x3glk+Xsf94stNRKqUcokmhOKrZGe79C659BWL+wuuT\ntjwkU/lscAN2HznNte8uYvyi3aRnZDodqVKqgGlSKK58/OCaB+GB1dCgHyx6k+7zb2DRDUm0qxXM\nq7O30O+/S9gYm+h0pEqpApSrpCAiJUXEy16uIyJ9RcTXvaGpAlG6Mtw0HobPBv/SBP98F+N5iUm9\n/YhPSqXff//ilZ83k3xWn2lQqjjIbU1hERAgImHA78AdWGMbqaIioh38axH0fguJ30K7+QNZUvtb\n7m3my2d/7aHHO4tYsC3+0sdRShVquU0KYoxJBgYAHxtjbsYavE4VJd4+0PoeeGg9dHgMv+2/8OT2\nISxrsYAQ3zPc+eUqHpy8jmOnUp2OVCnlJrlOCiJyNTAE+MUu036LRVVAaej2PDy4BhoNpHL0Z8xI\nu4+J9Vcxf9M+rn13Eb9uOuR0lEopN8htUhgNjAFmGGOiRaQmsMB9YSmPUCYc+n8C9y5GqkTScc+7\nrAt+jrsD5vLoN0t5aPI6Tpw+63SUSql8dNkPr9k3nIOMMSfdE1Lu6cNrBWznXFjwGhxYQ4pPKSam\nduJHvz6MvqkrPRqEOh2dUiqXrvjhNRH5VkRKi0hJYBOwWUSeyM8gVSFwVXe4Zz7c9QcBdbtzj88c\nZmXcR+rkobz/5TckJqc5HaFS6grlqqYgIuuNMc1EZAjQHHgaWGOMaeLuAHOiNQWHJewnY8WnpK38\nkoCMU2yS2kibkTTsOBBKBDsdnVLqIvJjmAtf+7mEG4FZxpg0oPAOmqTyR9mqeF/3CgFPbuPg1S9T\nTk7RcPkTZL5Zi7PjusOfY+HgOsjUJ6OVKixyW1N4CHgKiAKuB6oB3xhjOrg3vJxpTcGzpKalMfOn\nWRxZ/zOdJYpGsstaUTLEano69wos62ygShVzOdUU8jxKqoj4GGMcfcxVk4Jn2n3kFM/N3MT2Xbu5\nPWQnd1bcSZmDi+DMCfAtAc2HQtv7oFx1p0NVqli64qQgImWAF4COdtGfwMvGGEcHxtGk4LmMMcxc\nf4BXft5Cwpk07m5XjUfqJxEQNRE2TgVjoGF/aPeQNV2oUqrA5EdS+AGr19FXdtEdQFNjzIB8izIP\nNCl4voTks7wxZytTVu0nrGwgT/Wqx3VV0/FfPQ5WT4CzSdaordc8BLW6wuVN2a2UyoP8SArrjTHN\nLlVW0DQpFB6rYo7zzPSN7Ig/RZlAX65vUplbGpaiadwMZMX/4NRhCG0M178N1do4Ha5SRVp+9D46\nIyLtXQ7YDjhziZN+ISLx9tSb5697TESMiFSw34uIfCAiO0Vkg4g0z2VcqpBoFRHMr6M7MnFEa7rU\nDWHG2gPc+EU0nZc348MmP3C029vWPYfpd0O6jq2klFN8crndvcBE+94CwAlg2CX2mQB8BEx0LRSR\nqsC1wD6X4l5AbfvVBvjE/quKEG8voWOdEDrWCeFUajq/bjrMjHWxvLNgL2+byoyodC/PJzwHqz6D\nq+93OlyliqVcJQVjTBTQVGFebeMAAB0GSURBVERK2+9PishoYEMO+ywSkYhsVr0LPAn86FLWD5ho\nrLas5SJSVkQqG2N01LUiKsjfh4EtwhnYIpxDiWeYue4gU1aVoEtmY1rP/w/+zYZo11WlHHBZM68Z\nY066jHn06OWeTET6AQfsJOMqDNjv8j7WLsvuGCNFZLWIrD5y5MjlhqA8UOUygYzqXIvZD3Xg9yr3\n4Z+WyOpJL5DX7tJKqby7kuk4L6ubiIiUAJ4Bnr+Cc2KMGWeMaWmMaRkSEnIlh1IepqS/D8/fM4g1\nZXrQaP8k3pw6T+eJVqqAXUlSuNyfcbWAGkCUiMQA4cBaEakEHACqumwbbpepYsbX24vmw9/Cxwtq\nbPyAe79Zy5mzGU6HpVSxkWNSEJEkETmZzSsJqHI5JzLGbDTGVDTGRBhjIrCaiJobYw4Ds4Chdi+k\ntkCi3k8ovqRcBD5t/8VAn8XEblvFkM+W67wNShWQHJOCMaaUMaZ0Nq9Sxpgcb1KLyGRgGVBXRGJF\n5K4cNp8N7AZ2AuOB+y7zc6iipsNjePmXYmK1OWw6eJKb/reU/ceTnY5KqSLvSpqPcmSMGWyMqWyM\n8TXGhBtjPj9vfYQx5qi9bIwx9xtjahljGhtj9Im04q5EMHR4lIqH/+TH6w1Hk1K56ZOlLN99zOnI\nlCrS3JYUlLpibf4FpcOov/FNpt3bFn9fLwaNW86Dk9dxKDHHZyeVUnmkSUF5Lt9A6PIsHFxHnaNz\n+X10Jx7uVpvfow/T9a0/+e+CnaSm601opfKTJgXl2ZoOgooNYd7LBHpl8EiPOsx9tBMd61Rg7G/b\nuO7dRczfGud0lEoVGZoUlGfz8oYeL8GJGFjzJQBVg0vw6R0t+fqu1nh7CSMmrGbEhFXEHD3tbKxK\nFQGaFJTnu6o7RHSAP/8DKX9P4dGhdghzHu7Is73rs3LPcXq8+yePTY0i+qCj03woVajleeY1T6BD\nZxcjB9bC+K7WeEhNB1uzt1Wsn7U6/mQK/12wk+/XxJJ8NoM2NYIZ0b4G3euH4u2lczQo5cot03F6\nAk0KxczepbByHGz5GTLTILw1tBhmzeDmVxKAxDNpTF21nwlLYziQcIaqwYEMuzqCW1pVpXSAr8Mf\nQCnPoElBFS2nj0LUZFg7EY5uB//S0HggNB8GVax5n9IzMvljcxxfLolhZcxxSvp5c2urajzY9SrK\nlfRz+AMo5SxNCqpoMgb2LYe1X0H0DEhPgTo9ofuL/2ha2hibyBdL9jAr6iBB/j48fm0dBreuho+3\n3lJTxZMmBVX0nUmA1Z/DX+/B2VPQ7Dbo/AyU+XsE9m2Hk3jpp2iW7jpGvUqleOGGhlxdq7yDQSvl\nDE0KqvhIPg6L3oJV40G8oO0oaP8IBFiTBhpj+HXTYV75ZQsHEs5wfePKPHN9fcLKBl78mLv/hD/+\nDdWuhl7/KaAPopT7aFJQxc+JvTD/Fdg4FQLLQccnoNXd4OMPwJmzGXy6aBefLNyFCIzqdBX/6lST\nAF/vv4+RGAu/P2c1TfmVgrNJ0P9T64E6pQoxTQqq+DoUBX+8ALsXQKkq0GgANBwAYc1BhNgTybw+\neyu/bDxEWNlAHru2Djc2qoDXio9h0VgwmdD+UWvO6Ek3W8cbuRBC6uQ+hqQ4q2mr7X06xajyCJoU\nlNo1H5Z/ArsWWN1Zy1SDBn2t7qxhLVi6+xivzd5C8KHFvBbwDeGZB6BeH7juNShX3TrGyYPwv/YQ\nVAnumWeNzXQpp4/BhOvhyBa4+gG47lX3fk6lckGTglLnnDkB2+ZA9EwrUWSmQZmq0KAf5kQMsvVn\n9kll/p06FK7qzpje9ahXqfTf+++YC5Nusrq/9v3gEudKgK9usLrNVom0HsB7aC2UCXfvZ1TqEnJK\nCtonTxUvgeWsnklDpsITO+HGT6BiA1jxKbJrPnR7gYpPrqV9z0Gs23eCXu8v5onvozicmGLtX7s7\ntBttdYPdOO3i50lNgkkDIX4L3DoJBowDjDVUh1IeTGsKSsHfYyrZvZQAEpLP8t8FO/lq6V68vKyb\n0aM618JPMqwmobhoGPknVLjqn8c6m2wlhH3L4ZaJUL+PVT7naeuJ7PtXQIXaBfTBlLqQIzUFEflC\nROJFZJNL2VgR2SoiG0RkhoiUdVk3RkR2isg2EbnOXXEpla2AMv9ICABlS/jx7PUNmPdYJ7rVD+Xd\nudvp+9FfbDyUDAO/AG9f+H44pKX8vVNaCky5zRqSY8C4vxMCQIfHwCfA6hWllIdyZ/PRBKDneWV/\nAI2MMU2A7cAYABFpAAwCGtr7fCwi3ijlAaoGl+C/tzVn/NCWHD99lhs/XsKby05x9oZPIG4j/DbG\n2jAjzUoSuxdAv4+soTdcBYVYvZg2z4SD6wv8cyiVG+6co3kRcPy8st+NMen22+XAuTtu/YApxphU\nY8weYCfQ2l2xKZUXPRqE8scjnRgQGcbHC3fR+9cSxDUaCau/gA3fww93w/Y50PstiLw9+4Nc8wAE\nBsO8lws2eKVyyckbzSOAOfZyGLDfZV2sXXYBERkpIqtFZPWRI0fcHKJS/1SmhC9jb27KVyNak5ya\nToc17Ykt2Qim323VAK59BVrfc/EDBJSBDo/CrnmwZ3HBBa5ULjmSFETkWSAdmHS5+xpjxhljWhpj\nWoaEhOR/cErlQqc6Ifz2SEdubl2TW4/dwz6pwuYGo0ltfd+ld251t/Ug3byXrEH9lPIgPgV9QhEZ\nDvQBupm/uz4dAKq6bBZulynlsUoF+PJq/8YsbVKZ4TMi2L32NOW3zeeWVlW5rXU1qgaXyH5H30Do\n/DT89JD1zES93gUbuFI5cGuXVBGJAH42xjSy3/cE3gE6GWOOuGzXEPgW6z5CFWAeUNsYk5HT8bVL\nqvIUmZmGv3Ye5Zvle5m7JQ6DVZsY0qY6XetVvHD2t4x0+LgNePnCqCXWXNRKFZCcuqS6raYgIpOB\nzkAFEYkFXsDqbeQP/CEiAMuNMfcaY6JFZCqwGatZ6f5LJQSlPImXl9CxTggd64RwKPEMU1buZ8qq\nfdwzcTVVygQwqHU1+keG/V178PaBLs/CtDth4/c6yJ7yGPrwmlJukpaRybwt8UxasZfFO44C0Lxa\nWfo2rcL1TaoQUtIXxne2ht54YA346IxwqmDo2EdKOWz/8WR+2nCQWesPsvVwEl4C7a6qwN2V99Bp\n5b+g11hoM9LpMFUxoUlBKQ+yPS6JWesPMivqIPuOn+Y7v1do4HuIowO+p0ZDfTxHuZ8mBaU8kDGG\nqNhEli1bzE2bHyTIJDOz6lN0ufk+KpfJxbDcSuWRJgWlPFxC3H5Ofn071U6tZ2JmT+Lb/puRXetS\nOsDX6dBUEaRDZyvl4cqGVqXaI3NJajaSoV6/0mn5ndz0n+l88dcezqZnOh2eKkY0KSjlKbx9KXXj\nWLjpc1r47WeqPM2cX6bT/Z0/+WFNLClp2ktbuZ8mBaU8TeOBeI1cQNmy5fgu4DUGm1947Pv1tHlt\nHi/Oimbr4ZNOR6iKML2noJSnSkmEmffB1p85FdyIvaklOZCUyRnjS8mSJaleMZiISuXx9Q+E+n2h\nSjOnI1aFhN5oVqqwysyE5R/DttmQnkJ66hlOJ58i9Uwy3pmpBJBGoJzF+AXhPXK+zuimckWTglJF\njDGGtfsSmLJyH2s2bGSq1xhSvEuzottUerasS0n/Ah/rUhUijox9pJRyHxGhRfVytKhejqQbGrB0\nfgm6rbyb4F9Hcc3vY+jXvCq3talGvUqlnQ5VFTJaU1CqiDCrvkB+eYT55Qdzb1w/zqZn0rJ6OYa0\nrcb1javg56P9SpRFn1NQqhiQViOg5V10PTaZtf0SeO76+hw7fZZHvoui5/uLWLrrqNMhqkJAk4JS\nRUnPN6B6O4J+G83dNROY/1gnPhvakrSMTG4bv4JHvlvPkaRUp6NUHkyTglJFiY8f3DIRSlaEKUOQ\nU/F0bxDK76M78UCXq/h5w0G6vb2Qb5bvJTOz8DYdK/fRpKBUUVOyAgyaBCkJMPUOSE8l0M+bx6+r\ny5yHO9CgSmmem7mJ/p8sZdOBRKejVR7GbUlBRL4QkXgR2eRSFiwif4jIDvtvObtcROQDEdkpIhtE\npLm74lKqWKjcBG78GPavgF8eg4w0OHmQq9J3MrlTItPb7uTao1+z5n93s+7DwSRsW+x0xMpDuK33\nkYh0BE4BE13maH4TOG6MeUNEngbKGWOeEpHewINAb6AN8L4xps2lzqG9j5S6hPmvwKKxF119xjuI\ntPRMSksy68t0p0zf16hRq24BBqic4MhzCsaYRSIScV5xP6x5mwG+AhYCT9nlE42VoZaLSFkRqWyM\nOeSu+JQqFjo/AyVDrCk/gypCUKj9qgglKxLoG8ChA3Gs/vFVron7FjOxPTPL3krFnk9xdb1w7LnU\nVTFS0A+vhbp80R8GQu3lMGC/y3axdpkmBaWuhJcXtPlXjpvUDAul5n0fkHDwYeKnP8WNR7/m4JRf\neLPkndTqeic3NKuCv493AQWsnObYjWa7VnDZbVciMlJEVovI6iNHjrghMqWKp7JValHngWmkDp1N\nQNlKPJX8NjVn3cjI18fx+pwt7Iw/5XSIqgAUdFKIE5HKAPbfeLv8AFDVZbtwu+wCxphxxpiWxpiW\nISEhbg1WqeLIv2Y7gh9egun3XxqWSOTLjDH4LXmHHu8soP/HS5i8ch9JKWlOh6ncpKCTwixgmL08\nDPjRpXyo3QupLZCo9xOUcpCXFxJ5O/6PrMOr8UAe85nKwvBxmDMJjJm+kVavzuWR79azdNdRfd6h\niHFn76PJWDeVKwBxwAvATGAqUA3YC9xijDku1t2sj4CeQDJwpzHmkt2KtPeRUgXAGFg5Hn4bgykT\nzrZOn/D1nlLMijpIUko6YWUD6R8ZRv/mYdQKCXI6WpULOnS2UurK7V8JU4daPZn6vEdKw1v4Lfow\nP6w9wF87jpBpoEl4GfpHhnFD0ypUCPJ3OmJ1EZoUlFL541Q8TBsBMYuh5QhrrCUff+JPpjAr6iDT\n1x5g86GTeHsJneqEcGNkGD3qhxLop72XPIkmBaVU/slIh/kvw5L3oUpzuOF98CsJmemQmU7MkSQW\nbjnEX9sPkXDqDAd8qtG8Xi16NqpEl3oVCdIJgBynSUEplf+2/AQzRsHZpBw3S/UK5HNu5IPka8n0\nCaRTnRB6NapEt/qhlAn0LaBglStNCkop9zixF/YuAS8f8PK2//r8/d4YWDMBtv7M2RKVmB1yF2MP\nNePAyTR8vYV2V1VgSJvqdK9f8cKnp88mQ/xmqzbipWN35idNCkopZ+1dBr8/CwfWYEIbsbPZU3x/\noja/bDjEgYQzNKxSmoe71aZH1Uxk+2+w/VfYvRDSU6DdaOjxktOfoEjRpKCUcp4xED0d5r4ICfvg\nqu6kdX2RBVsOE7v8B1qkrqCp125r07LVkbq94PQR2PQDDPwSGg1wNv4ixJEB8ZRS6h9EoNFNUK+P\n9dzDojfxHdeeawGDcLx8E8afvoPvkxrhZeozumodrq0bjFdiLPx4P1SoA5Ua5f58q7+AvUuh9b+g\naiu3fayiRmsKSilnJB+37jeUDIE610FQRdIzMvlpw0E+nLeT3UdPU69SKQbV92VI1DB8/AKQkQuh\nRHDOxzUGFr4Of/7HureRmQ7VroF2D0Ht6/T+BNp8pJQqZDIyDT9FHeTzv/aw8UAikbKD7/z/j5ig\nSPb0/Ip2tUOz79qamQlznoRV4yHyDrj2FVj/LSz/GBL3Q4W6VnJofDP4FN+H6zQpKKUKrbiTKfy5\n7QhnV37J7Ufe5n/pN/C2uY3WNYLpWi+UG5tVoXyQP6SfhZmjYNM0uOYh6PGy1WQF1sxz0TNgyQcQ\ntxGCKkHbUdYDeAGlnf2ADtCkoJQqEjJmjcZ77ZfMrPV/fHy0KdvjTuHn7cUNDcry7+TXKXvgT+j+\nIrR/JPsDGAO75sPSD6zeTSH14a7fIKBMAX4K52lSUEoVDeln4asb4PAGuOt3tksE05dEc+2Gh2hm\ntvNe4H2U63APAyLDKVPiEg/G7ZgLk2+F6u1gyDTw8SuQj+AJckoKesdFKVV4+PjBLROtX/ZThlBH\nYnk67jEivXazvMXb/Fnqel76aTOtX5vL499HsSrmOBkXG9q7dnfo+yHs+RN+Hm3VIpTWFJRShVDs\naviyl9WzyCcQBn0DtboCsOlAIpNW7OPH9QdIPptBhSA/utarSPf6obSvXYESfufdoF7wOvz5BnR5\nFjo96cCHKXjafKSUKnqipsCisdD/Uwi/8PstKSWNBduOMHdzHAu2xZOUko6/jxftr6pA9wahdKtX\nkYqlA6wawsxREDUZ+o+Dprc68GEKliYFpVSxlpaRyao9x/ljSxx/bI4j9sQZAFpWL0e/ZlXo3aA8\n5WcMhn3L4Y4ZUKODwxG7lyYFpZSyGWPYHneKPzYf5qeoQ2yLS8LHS7i2VgBvJDxOqbSjyF1/QEhd\np0N1G49LCiLyCHA3YICNwJ1AZWAKUB5YA9xhjDmb03E0KSilrtTWwyeZue4gP0UdRBL3McPvebz8\nAtl8/XTaNq6Pr3fR64/jUUlBRMKAv4AGxpgzIjIVmA30BqYbY6aIyP+AKGPMJzkdS5OCUiq/ZGYa\nVu89weql87hzx/1sywxjnP+d9KsXRMdqvgSmJ0FKApxJsP6mJUNEB2jYH4IqOh3+ZfHEpLAcaAqc\nBGYCHwKTgErGmHQRuRp40RhzXU7H0qSglHKHtM0/4zP1doRsvh/9y0BgGUAgYS+IF9ToaA32V/8G\nCCxX4PFeLo8aJdUYc0BE3gL2AWeA37GaixKMMen2ZrFAWHb7i8hIYCRAtWrV3B+wUqrY8W3QB0Yt\ngVPx7EzyYcrGk8zYcppEE8i1tatwV/uatKheDuK3WEN7b5wGsx6Enx+Fq7pD44FQpyf4Bzn9US6b\nEzWFcsAPwK1AAvA9MA2rZnCVvU1VYI4xJsdxcrWmoJQqKIcTU/hqWQyTlu/lZEo6TauWpXOdEJpV\nLUuTsNKUP7nZShCbpkPSQfArBV2fg9b3WLPQeRBPaz66GehpjLnLfj8UuBq4GW0+Ukp5uNOp6fyw\nNpbJK/ez9fDJrAehw8sF0jS8LE3DS9HObyd1t4/DZ898qBIJfd6DKs2cDdyFpyWFNsAXQCus5qMJ\nwGqgI/CDy43mDcaYj3M6liYFpZSTTqWms+lAIhtiE4jan0hUbELWMxB+PsILNbZx69H/4pNyDNqM\ngi7PeESTkkclBQAReQmr+SgdWIfVPTUMq0tqsF12uzEmNafjaFJQSnmao6dS2RCbwNwt8fywJhb/\n9CTeq/AjXU/9jCkdjvQeC/V653yQjHSryenc0N/5zOOSQn7RpKCU8mTHTqXyzfJ9TFwWQ/XkTbxT\n4ksiMvaSWbcPXh0esWafS9xvv2Ihwf6bdBDCW8GgyVCyfL7HpUlBKaUclJKWwYx1B/hi0Xa6nfie\n0b7TCcDl2VwvHygdBmWrQZlwKFEeVn1mvb9jhlWWjzQpKKWUB8jMNCzYFs/0+cswB9Zw2AQTFBpB\n2yYNuK5xGLVCXO43xCyByYPAvzQMnQkVaudbHJoUlFLKw+w/nsyvmw4ze9Mh1u1LAKBuaCl6Na5E\nr0aVqRMahBzeAN/cBCYTbp+ebz2YNCkopZQHO5R4hl83HWbOpsOsijmOMVClTADNqpWlY/mT9N94\nP35picjgKfkygqsmBaWUKiTik1L4PTqOFXuOs37/CfYfP0Mox/na73UivOKZUv1lAhrdQJuawVQv\nXzJP59CkoJRShdTRU6lE7U9g6+4YekY9SPWzO3jq7EgqdBjOmF7183RMjxr7SCmlVO5VCPKnW/1Q\nutUPhe7zMVOG8Pae/3EiIBzIW1LISdEbKFwppYoq/yBkyFRoNJBy4fXccgqtKSilVGHi4w8DP3fb\n4bWmoJRSKosmBaWUUlk0KSillMqiSUEppVQWTQpKKaWyaFJQSimVRZOCUkqpLJoUlFJKZSnUYx+J\nyBFgbw6bVACOFlA4l0tjyxuNLW80trwpqrFVN8aEZLeiUCeFSxGR1Rcb9MlpGlveaGx5o7HlTXGM\nTZuPlFJKZdGkoJRSKktRTwrjnA4gBxpb3mhseaOx5U2xi61I31NQSil1eYp6TUEppdRl0KSglFIq\nS5FMCiLSU0S2ichOEXna6XhciUiMiGwUkfUi4ugE0yLyhYjEi8gml7JgEflDRHbYf8t5UGwvisgB\n+9qtF5HeDsVWVUQWiMhmEYkWkYftcsevXQ6xOX7tRCRARFaKSJQd20t2eQ0RWWH/f/1ORPw8KLYJ\nIrLH5bo1K+jYXGL0FpF1IvKz/d49180YU6RegDewC6gJ+AFRQAOn43KJLwao4HQcdiwdgebAJpey\nN4Gn7eWngf94UGwvAo97wHWrDDS3l0sB24EGnnDtcojN8WsHCBBkL/sCK4C2wFRgkF3+P2CUB8U2\nARjo9L85O65HgW+Bn+33brluRbGm0BrYaYzZbYw5C0wB+jkck0cyxiwCjp9X3A/4yl7+CrixQIOy\nXSQ2j2CMOWSMWWsvJwFbgDA84NrlEJvjjOWU/dbXfhmgKzDNLnfqul0sNo8gIuHA9cBn9nvBTdet\nKCaFMGC/y/tYPOQ/hc0Av4vIGhEZ6XQw2Qg1xhyylw8DoU4Gk40HRGSD3bzkSNOWKxGJACKxfll6\n1LU7LzbwgGtnN4GsB+KBP7Bq9QnGmHR7E8f+v54fmzHm3HV71b5u74qIvxOxAe8BTwKZ9vvyuOm6\nFcWk4OnaG2OaA72A+0Wko9MBXYyx6qUe82sJ+ASoBTQDDgFvOxmMiAQBPwCjjTEnXdc5fe2yic0j\nrp0xJsMY0wwIx6rV13MijuycH5uINALGYMXYCggGnirouESkDxBvjFlTEOcriknhAFDV5X24XeYR\njDEH7L/xwAys/xieJE5EKgPYf+MdjieLMSbO/o+bCYzHwWsnIr5YX7qTjDHT7WKPuHbZxeZJ186O\nJwFYAFwNlBURH3uV4/9fXWLraTfHGWNMKvAlzly3dkBfEYnBag7vCryPm65bUUwKq4Da9p15P2AQ\nMMvhmAAQkZIiUurcMnAtsCnnvQrcLGCYvTwM+NHBWP7h3BeurT8OXTu7PfdzYIsx5h2XVY5fu4vF\n5gnXTkRCRKSsvRwI9MC657EAGGhv5tR1yy62rS5JXrDa7Av8uhljxhhjwo0xEVjfZ/ONMUNw13Vz\n+o66O15Ab6xeF7uAZ52OxyWumli9oaKAaKdjAyZjNSWkYbVJ3oXVVjkP2AHMBYI9KLavgY3ABqwv\n4MoOxdYeq2loA7DefvX2hGuXQ2yOXzugCbDOjmET8LxdXhNYCewEvgf8PSi2+fZ12wR8g91DyakX\n0Jm/ex+55brpMBdKKaWyFMXmI6WUUnmkSUEppVQWTQpKKaWyaFJQSimVRZOCUkqpLJoUlMqBiGS4\njJC5XvJx1F0RiXAdBVYpT+Bz6U2UKtbOGGvoA6WKBa0pKJUHYs2L8aZYc2OsFJGr7PIIEZlvD6A2\nT0Sq2eWhIjLDHq8/SkSusQ/lLSLj7TH8f7efplXKMZoUlMpZ4HnNR7e6rEs0xjQGPsIaxRLgQ+Ar\nY0wTYBLwgV3+AfCnMaYp1jwR0XZ5beC/xpiGQAJwk5s/j1I50iealcqBiJwyxgRlUx4DdDXG7LYH\noDtsjCkvIkexhpBIs8sPGWMqiMgRINxYA6udO0YE1hDNte33TwG+xphX3P/JlMqe1hSUyjtzkeXL\nkeqynIHe51MO06SgVN7d6vJ3mb28FGskS4AhwGJ7eR4wCrImcylTUEEqdTn0V4lSOQu0Z+M651dj\nzLluqeVEZAPWr/3BdtmDwJci8gRwBLjTLn8YGCcid2HVCEZhjQKrlEfRewpK5YF9T6GlMeao07H8\nfzt2TAMAAIAwzL9rvingbE0sAE/uIwBiKQAQSwGAiAIAEQUAIgoARBQAyAD0Qgt6F8I0QQAAAABJ\nRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"gnfqd6wJB2Gj","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"nUd_DOpYB2VN","colab_type":"code","outputId":"086597cb-f197-4bef-a915-dcbafec7cf18","executionInfo":{"status":"ok","timestamp":1584441291435,"user_tz":240,"elapsed":1702246,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":748}},"source":["weather_rnn = weatherRNN(hidden_size=10)\n","if use_cuda:\n","  weather_rnn = weather_rnn.cuda()\n","train_rnn_network(weather_rnn, trainingSet=trainingSet, validationSet=validationSet, batch_size=30, learning_rate=0.00001, num_epochs=40)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train err: 12.84313996771659, Train loss: 244.00336456298828 |Validation err: 12.681625146200258, Validation loss: 250.3946960449219\n","Epoch 2: Train err: 12.822276109737283, Train loss: 243.1318263069528 |Validation err: 12.660973659281582, Validation loss: 245.84412536621093\n","Epoch 3: Train err: 12.801375846964808, Train loss: 242.12325180553998 |Validation err: 12.640089412774149, Validation loss: 241.65402893066405\n","Epoch 4: Train err: 12.780206497882306, Train loss: 241.26654165299212 |Validation err: 12.618908716730667, Validation loss: 238.8134295654297\n","Epoch 5: Train err: 12.75883051130106, Train loss: 240.9914364423908 |Validation err: 12.59755278869033, Validation loss: 241.70113647460937\n","Epoch 6: Train err: 12.737151765282855, Train loss: 240.23470368932504 |Validation err: 12.575854895122644, Validation loss: 235.24393768310546\n","Epoch 7: Train err: 12.71511613192482, Train loss: 239.7193757354236 |Validation err: 12.553858534078708, Validation loss: 243.9561474609375\n","Epoch 8: Train err: 12.692726727607761, Train loss: 238.14239739590005 |Validation err: 12.531420059863446, Validation loss: 234.31012451171875\n","Epoch 9: Train err: 12.67012850062669, Train loss: 237.85862519311124 |Validation err: 12.508755313328765, Validation loss: 233.84297729492187\n","Epoch 10: Train err: 12.646988710345504, Train loss: 236.65214976326365 |Validation err: 12.485754085873173, Validation loss: 234.07316467285156\n","Epoch 11: Train err: 12.62369587202709, Train loss: 235.94439565939982 |Validation err: 12.46230309894141, Validation loss: 235.04451721191407\n","Epoch 12: Train err: 12.59997760707631, Train loss: 235.17858261358543 |Validation err: 12.438658134462917, Validation loss: 243.38357421875\n","Epoch 13: Train err: 12.575969157690821, Train loss: 234.3478168425013 |Validation err: 12.414468796970644, Validation loss: 227.28078735351562\n","Epoch 14: Train err: 12.55162969505776, Train loss: 233.7070785272317 |Validation err: 12.389990886166837, Validation loss: 232.2147412109375\n","Epoch 15: Train err: 12.526915664727671, Train loss: 232.51986269090997 |Validation err: 12.36518944964846, Validation loss: 226.48255615234376\n","Epoch 16: Train err: 12.501999333087149, Train loss: 232.032606281218 |Validation err: 12.340178228972317, Validation loss: 225.94355529785156\n","Epoch 17: Train err: 12.476763871983982, Train loss: 231.09801145459784 |Validation err: 12.314817420004658, Validation loss: 229.08678588867187\n","Epoch 18: Train err: 12.451512030250884, Train loss: 230.10335778408364 |Validation err: 12.289247181673208, Validation loss: 230.50625244140625\n","Epoch 19: Train err: 12.42584787109961, Train loss: 228.96190880947427 |Validation err: 12.263520904658986, Validation loss: 230.8345703125\n","Epoch 20: Train err: 12.400126502142346, Train loss: 228.40124624283587 |Validation err: 12.237720590879103, Validation loss: 222.93728332519532\n","Epoch 21: Train err: 12.374319976480825, Train loss: 227.4991358772653 |Validation err: 12.212026064375538, Validation loss: 224.21617614746094\n","Epoch 22: Train err: 12.348700969905002, Train loss: 226.29841151002978 |Validation err: 12.186422470173145, Validation loss: 223.66603576660157\n","Epoch 23: Train err: 12.323154085843973, Train loss: 225.38386998411085 |Validation err: 12.16129570858177, Validation loss: 225.2122674560547\n","Epoch 24: Train err: 12.297834229283227, Train loss: 224.73744864541976 |Validation err: 12.136527257152082, Validation loss: 220.20645568847655\n","Epoch 25: Train err: 12.272866770437327, Train loss: 223.57347982437884 |Validation err: 12.112040680127775, Validation loss: 224.1710009765625\n","Epoch 26: Train err: 12.248241354641323, Train loss: 223.01700079245646 |Validation err: 12.088198993459086, Validation loss: 222.29984924316406\n","Epoch 27: Train err: 12.224076181476091, Train loss: 222.17357510426007 |Validation err: 12.064877618515132, Validation loss: 225.52161315917968\n","Epoch 28: Train err: 12.200580107175337, Train loss: 221.59062188570616 |Validation err: 12.042228511381985, Validation loss: 225.67856323242188\n","Epoch 29: Train err: 12.177442472234306, Train loss: 220.82403964683658 |Validation err: 12.020144685831715, Validation loss: 217.97042846679688\n","Epoch 30: Train err: 12.154994211560782, Train loss: 219.93984472556193 |Validation err: 11.998496786673211, Validation loss: 220.58570495605468\n","Epoch 31: Train err: 12.133019912344876, Train loss: 219.23798301571705 |Validation err: 11.977606019613441, Validation loss: 218.9548504638672\n","Epoch 32: Train err: 12.111599112277029, Train loss: 218.41832245373334 |Validation err: 11.957229945865587, Validation loss: 224.37070739746093\n","Epoch 33: Train err: 12.090679531725907, Train loss: 217.99915551357583 |Validation err: 11.93747351736276, Validation loss: 217.94175231933593\n","Epoch 34: Train err: 12.07034209794587, Train loss: 217.29655594122215 |Validation err: 11.918072485623886, Validation loss: 218.414501953125\n","Epoch 35: Train err: 12.050283441172272, Train loss: 216.26267073584384 |Validation err: 11.899198615298268, Validation loss: 214.9758087158203\n","Epoch 36: Train err: 12.030793560960385, Train loss: 216.13275190259588 |Validation err: 11.880816036588763, Validation loss: 215.2059619140625\n","Epoch 37: Train err: 12.011578002819268, Train loss: 215.23669352296923 |Validation err: 11.862619840889849, Validation loss: 212.2450848388672\n","Epoch 38: Train err: 11.992691224760689, Train loss: 214.5373525775847 |Validation err: 11.844809972876124, Validation loss: 210.83170471191406\n","Epoch 39: Train err: 11.97422171482608, Train loss: 214.00407328371142 |Validation err: 11.827490225025707, Validation loss: 217.177705078125\n","Epoch 40: Train err: 11.95602500054222, Train loss: 213.50782675821273 |Validation err: 11.810335293359136, Validation loss: 219.36385803222657\n","Finished Training\n","Total time elapsed: 306.77 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gB86UgLHB2PU","colab_type":"code","outputId":"58f843a7-616d-47f9-bba9-e934b6c0280c","executionInfo":{"status":"ok","timestamp":1584441291745,"user_tz":240,"elapsed":1702546,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["model_path = get_model_name(\"weatherRNN\", batch_size=30, learning_rate=0.00001, epoch=40)\n","\n","plot_training_curve(model_path)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvwMvQtMcljDXIwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"nOiFpwkODC9w","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"vrYrSfaUDDJE","colab_type":"code","outputId":"54d8910e-0d57-4778-b025-92111f6f2ae1","executionInfo":{"status":"ok","timestamp":1584441603404,"user_tz":240,"elapsed":2014193,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":748}},"source":["weather_rnn = weatherRNN(hidden_size=10)\n","if use_cuda:\n","  weather_rnn = weather_rnn.cuda()\n","train_rnn_network(weather_rnn, trainingSet=trainingSet, validationSet=validationSet, batch_size=25, learning_rate=0.006, num_epochs=40)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train err: 9.396107883712412, Train loss: 142.75508227413647 |Validation err: 7.210285365956617, Validation loss: 87.42395493079876\n","Epoch 2: Train err: 5.8796130021988064, Train loss: 59.06368215116736 |Validation err: 4.895723806838937, Validation loss: 40.99123882425243\n","Epoch 3: Train err: 4.182848606845929, Train loss: 29.794079558490075 |Validation err: 3.7989868729441, Validation loss: 23.167483428428913\n","Epoch 4: Train err: 3.3384405569792404, Train loss: 18.656849459426045 |Validation err: 3.116550557527635, Validation loss: 15.745145699073529\n","Epoch 5: Train err: 2.9561770371707197, Train loss: 14.376304476228478 |Validation err: 2.872501667175715, Validation loss: 13.252048278677053\n","Epoch 6: Train err: 2.786112187123534, Train loss: 12.789355803842414 |Validation err: 2.712626399926296, Validation loss: 12.05244546101011\n","Epoch 7: Train err: 2.695195256655602, Train loss: 11.956403663713639 |Validation err: 2.6333707945145672, Validation loss: 11.354962595577899\n","Epoch 8: Train err: 2.6241596123579978, Train loss: 11.470327220550955 |Validation err: 2.5960037941919487, Validation loss: 11.214630324265052\n","Epoch 9: Train err: 2.6264613975122124, Train loss: 11.493540809579091 |Validation err: 2.593409369183114, Validation loss: 11.197494342409332\n","Epoch 10: Train err: 2.584905911048863, Train loss: 11.16705543374362 |Validation err: 2.559101875177887, Validation loss: 10.94334181423845\n","Epoch 11: Train err: 2.549316545794513, Train loss: 10.939199447631836 |Validation err: 2.5648192571324104, Validation loss: 10.94791788890444\n","Epoch 12: Train err: 2.5663833587119305, Train loss: 11.071474179829636 |Validation err: 2.6126027526367417, Validation loss: 11.07649222735701\n","Epoch 13: Train err: 2.546323530628534, Train loss: 10.965525173161128 |Validation err: 2.522690091291403, Validation loss: 10.694747316426245\n","Epoch 14: Train err: 2.5262312815200922, Train loss: 10.78459696247153 |Validation err: 2.585050761298465, Validation loss: 10.937451461265827\n","Epoch 15: Train err: 2.5308266107398234, Train loss: 10.771279583238575 |Validation err: 2.510059442125526, Validation loss: 10.566541244243753\n","Epoch 16: Train err: 2.5106577439420645, Train loss: 10.705968317920215 |Validation err: 2.5446644341220166, Validation loss: 11.21607441737734\n","Epoch 17: Train err: 2.506635355137454, Train loss: 10.583566374974708 |Validation err: 2.5351334241196106, Validation loss: 10.867405513237262\n","Epoch 18: Train err: 2.512299781216523, Train loss: 10.656251205156927 |Validation err: 2.5910226085868615, Validation loss: 11.088049576200287\n","Epoch 19: Train err: 2.5027945575755086, Train loss: 10.621402413877723 |Validation err: 2.4933451410590806, Validation loss: 10.488931031062686\n","Epoch 20: Train err: 2.4974107669043497, Train loss: 10.535705047110989 |Validation err: 2.494854485389548, Validation loss: 10.586649417877197\n","Epoch 21: Train err: 2.4838848595172136, Train loss: 10.494442946290317 |Validation err: 2.5103642098883867, Validation loss: 10.645126375658759\n","Epoch 22: Train err: 2.484832166112696, Train loss: 10.494167886368215 |Validation err: 2.4941210788919825, Validation loss: 10.53879085080377\n","Epoch 23: Train err: 2.4846169876287227, Train loss: 10.451423435995023 |Validation err: 2.563397810271172, Validation loss: 11.118348549152243\n","Epoch 24: Train err: 2.4973727172510682, Train loss: 10.583821853546247 |Validation err: 2.539356512320432, Validation loss: 10.828879553696204\n","Epoch 25: Train err: 2.478112456741444, Train loss: 10.426249683719792 |Validation err: 2.513292169243908, Validation loss: 10.500694044705096\n","Epoch 26: Train err: 2.4736789758649755, Train loss: 10.4411377776159 |Validation err: 2.473343140681035, Validation loss: 10.269013421288852\n","Epoch 27: Train err: 2.506558028546029, Train loss: 10.638115340716219 |Validation err: 2.526037875381193, Validation loss: 10.474943703618543\n","Epoch 28: Train err: 2.4643743916792897, Train loss: 10.311944775385399 |Validation err: 2.4962739031660552, Validation loss: 10.473335134571997\n","Epoch 29: Train err: 2.468726510915161, Train loss: 10.408771547552657 |Validation err: 2.461055763140698, Validation loss: 10.247346812281116\n","Epoch 30: Train err: 2.4799981918968603, Train loss: 10.440389499272385 |Validation err: 2.5545930432525856, Validation loss: 10.834653114450388\n","Epoch 31: Train err: 2.4723774025101917, Train loss: 10.39921408156826 |Validation err: 2.577341786338855, Validation loss: 11.057211349750387\n","Epoch 32: Train err: 2.4792284142815197, Train loss: 10.423429675298195 |Validation err: 2.490305088461132, Validation loss: 10.380325416038776\n","Epoch 33: Train err: 2.490024348318818, Train loss: 10.458249650589407 |Validation err: 2.4844379519470943, Validation loss: 10.389805382695691\n","Epoch 34: Train err: 2.458908055878292, Train loss: 10.287517142622438 |Validation err: 2.492661495532183, Validation loss: 10.401700200705692\n","Epoch 35: Train err: 2.4668757885629113, Train loss: 10.327133106858764 |Validation err: 2.524456440444748, Validation loss: 10.546857652993038\n","Epoch 36: Train err: 2.4549723962474115, Train loss: 10.249796929424756 |Validation err: 2.4836922045098078, Validation loss: 10.28219331544021\n","Epoch 37: Train err: 2.453897277093723, Train loss: 10.204331757271127 |Validation err: 2.4666550537692404, Validation loss: 10.264093925212991\n","Epoch 38: Train err: 2.461264911187994, Train loss: 10.27741717312434 |Validation err: 2.5231310236489737, Validation loss: 10.28807942620639\n","Epoch 39: Train err: 2.4612544786499058, Train loss: 10.272389722197023 |Validation err: 2.433597330955824, Validation loss: 10.063801305047397\n","Epoch 40: Train err: 2.4509035002192947, Train loss: 10.253422985338185 |Validation err: 2.4963011899106835, Validation loss: 10.523389553201609\n","Finished Training\n","Total time elapsed: 309.25 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ycKqr8QMDDQD","colab_type":"code","outputId":"88856b87-948a-47a1-fc24-81aeb4b8b2ee","executionInfo":{"status":"ok","timestamp":1584441603622,"user_tz":240,"elapsed":2014401,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["model_path = get_model_name(\"weatherRNN\", batch_size=25, learning_rate=0.006, epoch=40)\n","\n","plot_training_curve(model_path)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"5w3UwG1AFCII","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"Ua0qwtlJFBYX","colab_type":"code","outputId":"1bc96cf4-8d87-49bd-e32a-1c8d78db9b07","executionInfo":{"status":"ok","timestamp":1584441952877,"user_tz":240,"elapsed":2363646,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":833}},"source":["weather_rnn = weatherRNN(hidden_size=5)\n","if use_cuda:\n","  weather_rnn = weather_rnn.cuda()\n","train_rnn_network(weather_rnn, trainingSet=trainingSet, validationSet=validationSet, batch_size=30, learning_rate=0.0002, num_epochs=45)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Started...\n","Epoch 1: Train err: 12.384276035219198, Train loss: 225.3358034227715 |Validation err: 12.168988148019634, Validation loss: 221.07257385253905\n","Epoch 2: Train err: 12.24065109561359, Train loss: 221.0562421454758 |Validation err: 12.037936521306076, Validation loss: 216.96219512939453\n","Epoch 3: Train err: 12.102681059877886, Train loss: 216.455524256972 |Validation err: 11.89983512385752, Validation loss: 220.77790466308593\n","Epoch 4: Train err: 11.921280085156484, Train loss: 211.10821026661358 |Validation err: 11.671160431007854, Validation loss: 208.7751708984375\n","Epoch 5: Train err: 11.697689540070055, Train loss: 204.3495916147701 |Validation err: 11.49398254115253, Validation loss: 202.54460327148436\n","Epoch 6: Train err: 11.541162351091781, Train loss: 200.03221743224097 |Validation err: 11.365428599105169, Validation loss: 197.2383303833008\n","Epoch 7: Train err: 11.41154845413352, Train loss: 196.09083663440143 |Validation err: 11.246897341281219, Validation loss: 193.78367065429688\n","Epoch 8: Train err: 11.290862259661406, Train loss: 193.35774643694768 |Validation err: 11.134018564764549, Validation loss: 189.79922393798827\n","Epoch 9: Train err: 11.173780447179038, Train loss: 190.03177067490876 |Validation err: 11.024934239268825, Validation loss: 186.870673828125\n","Epoch 10: Train err: 11.062480019001073, Train loss: 187.17852307929368 |Validation err: 10.919390323699385, Validation loss: 186.27704772949218\n","Epoch 11: Train err: 10.954101559706539, Train loss: 184.27702894367155 |Validation err: 10.81659888645034, Validation loss: 178.64308319091796\n","Epoch 12: Train err: 10.849277916588434, Train loss: 181.27341379884814 |Validation err: 10.71625001483686, Validation loss: 177.9280386352539\n","Epoch 13: Train err: 10.747576279042967, Train loss: 178.47311732808097 |Validation err: 10.619678632415567, Validation loss: 172.58770988464354\n","Epoch 14: Train err: 10.648640605795453, Train loss: 175.855604328093 |Validation err: 10.52526719523924, Validation loss: 176.56796447753905\n","Epoch 15: Train err: 10.552593805352602, Train loss: 173.22387589001264 |Validation err: 10.433559923516324, Validation loss: 174.81876953125\n","Epoch 16: Train err: 10.458761146154973, Train loss: 170.60159045360126 |Validation err: 10.343829447378644, Validation loss: 171.0468637084961\n","Epoch 17: Train err: 10.366727388430707, Train loss: 168.17741550383022 |Validation err: 10.25643414582674, Validation loss: 165.4276321411133\n","Epoch 18: Train err: 10.276341706492692, Train loss: 165.3179847216997 |Validation err: 10.17078735711471, Validation loss: 164.40928955078124\n","Epoch 19: Train err: 10.187711218493982, Train loss: 162.86033117575724 |Validation err: 10.08675242633713, Validation loss: 164.15035278320312\n","Epoch 20: Train err: 10.10036902416516, Train loss: 160.4955705736504 |Validation err: 10.003838561289784, Validation loss: 160.2010656738281\n","Epoch 21: Train err: 10.014348082983327, Train loss: 157.98690845927254 |Validation err: 9.922167279236376, Validation loss: 162.5842300415039\n","Epoch 22: Train err: 9.929718225899302, Train loss: 155.69814863361296 |Validation err: 9.841346935727946, Validation loss: 154.54989227294922\n","Epoch 23: Train err: 9.846600373209885, Train loss: 153.37113977651126 |Validation err: 9.761322425643849, Validation loss: 154.45268951416017\n","Epoch 24: Train err: 9.764214777043653, Train loss: 151.09849973584784 |Validation err: 9.682306466980181, Validation loss: 146.49629051208495\n","Epoch 25: Train err: 9.682801532246748, Train loss: 148.56635840994412 |Validation err: 9.604078728669577, Validation loss: 153.17696014404297\n","Epoch 26: Train err: 9.601909782906688, Train loss: 146.6391327654729 |Validation err: 9.527639838812014, Validation loss: 147.5415362548828\n","Epoch 27: Train err: 9.522326435962027, Train loss: 144.3328918081815 |Validation err: 9.450979532111813, Validation loss: 140.0076009750366\n","Epoch 28: Train err: 9.443547830645665, Train loss: 142.36605315911964 |Validation err: 9.375690950158551, Validation loss: 138.99762832641602\n","Epoch 29: Train err: 9.365017662915438, Train loss: 140.27587896878603 |Validation err: 9.30098114452875, Validation loss: 135.97693859100343\n","Epoch 30: Train err: 9.286583600432355, Train loss: 138.12172630184986 |Validation err: 9.227725624438392, Validation loss: 134.3361215209961\n","Epoch 31: Train err: 9.209730531540925, Train loss: 136.03704827730772 |Validation err: 9.154695454544873, Validation loss: 134.06334136962892\n","Epoch 32: Train err: 9.134303065464188, Train loss: 134.1197320281482 |Validation err: 9.084135509538948, Validation loss: 135.75469268798827\n","Epoch 33: Train err: 9.057916071585128, Train loss: 132.12950865948787 |Validation err: 9.01339156066646, Validation loss: 130.98799896240234\n","Epoch 34: Train err: 8.983473838992458, Train loss: 129.79802203569255 |Validation err: 8.943343721056053, Validation loss: 130.2186605834961\n","Epoch 35: Train err: 8.909278870225604, Train loss: 128.2052390927174 |Validation err: 8.87361665697843, Validation loss: 125.38268493652343\n","Epoch 36: Train err: 8.835066109396275, Train loss: 126.22782003684122 |Validation err: 8.804103702170721, Validation loss: 127.99977416992188\n","Epoch 37: Train err: 8.76217067217555, Train loss: 124.26973333515105 |Validation err: 8.73527869514987, Validation loss: 128.04183410644532\n","Epoch 38: Train err: 8.690227013727464, Train loss: 122.573145725688 |Validation err: 8.667250168438933, Validation loss: 121.23759429931641\n","Epoch 39: Train err: 8.618153751852807, Train loss: 120.46309943277328 |Validation err: 8.600377604761062, Validation loss: 120.22385528564453\n","Epoch 40: Train err: 8.547382051210377, Train loss: 118.75856574636991 |Validation err: 8.533679953407123, Validation loss: 119.87818511962891\n","Epoch 41: Train err: 8.476902196264108, Train loss: 116.85954478529634 |Validation err: 8.467599110365079, Validation loss: 121.51057342529298\n","Epoch 42: Train err: 8.407071875350464, Train loss: 115.36207202223481 |Validation err: 8.401892759085195, Validation loss: 118.97334991455078\n","Epoch 43: Train err: 8.337962943239488, Train loss: 113.52196734068824 |Validation err: 8.336428633682626, Validation loss: 112.98275268554687\n","Epoch 44: Train err: 8.268567495510695, Train loss: 111.87807683475683 |Validation err: 8.270919228548166, Validation loss: 111.06848236083984\n","Epoch 45: Train err: 8.199884586921447, Train loss: 109.97241498603195 |Validation err: 8.206044629343978, Validation loss: 113.39754577636718\n","Finished Training\n","Total time elapsed: 347.11 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"62GfWVF3FBqZ","colab_type":"code","outputId":"9852748a-ab38-439e-d678-a75863ccd9f6","executionInfo":{"status":"ok","timestamp":1584441953232,"user_tz":240,"elapsed":2363991,"user":{"displayName":"Sahar Abdalla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UWwROWMf0NA3vKyfJu1cmdxPr_Cvob_R6yP9qA=s64","userId":"02368708129087296082"}},"colab":{"base_uri":"https://localhost:8080/","height":573}},"source":["model_path = get_model_name(\"weatherRNN\", batch_size=30, learning_rate=0.0002, epoch=45)\n","\n","plot_training_curve(model_path)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsBy4F9cHdm0AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"3XqT07zpH-Ur","colab_type":"text"},"source":["best model???\n","\n"]},{"cell_type":"code","metadata":{"id":"L_924oxqBy7W","colab_type":"code","colab":{}},"source":["class NEWweatherRNN(nn.Module):\n","\n","    def __init__(self, hidden_size = 10, input_size = 2, output_size = 2, n_layers = 1): #,dropout=DROPOUT\n","        super(NEWweatherRNN, self).__init__()\n","        self.name = \"NEWweatherRNN\"\n","        self.rnn = nn.RNN(input_size, hidden_size, n_layers, batch_first=True) # there is RNN, GRU, LSTM\n","        self.decoder = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, inp,  hidden = None):\n","        if(hidden == None):\n","          out, _ = self.rnn(inp)\n","        else:\n","          out, _ = self.rnn(inp, hidden)\n","        out = self.decoder(out[:, -1, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-XlvkpV9GUI","colab_type":"code","colab":{}},"source":["weather_rnn2 = NEWweatherRNN(hidden_size=10)\n","if use_cuda:\n","  weather_rnn2 = weather_rnn2.cuda()\n","train_rnn_network(weather_rnn2, trainingSet=trainingSet, validationSet=validationSet, batch_size=25, learning_rate=0.006, num_epochs=40)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_qWJiLr9H3t","colab_type":"code","colab":{}},"source":["model_path = get_model_name(\"NEWweatherRNN\", batch_size=30, learning_rate=0.0002, epoch=45)\n","\n","plot_training_curve(model_path)"],"execution_count":0,"outputs":[]}]}